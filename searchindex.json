{"categories":[{"title":"AI","uri":"https://www.ganymedenil.com/categories/AI/"},{"title":"Go","uri":"https://www.ganymedenil.com/categories/Go/"},{"title":"Laravel","uri":"https://www.ganymedenil.com/categories/Laravel/"},{"title":"PHP","uri":"https://www.ganymedenil.com/categories/PHP/"},{"title":"go基础库","uri":"https://www.ganymedenil.com/categories/go%E5%9F%BA%E7%A1%80%E5%BA%93/"},{"title":"php7","uri":"https://www.ganymedenil.com/categories/php7/"},{"title":"写给大忙人看的NGINX","uri":"https://www.ganymedenil.com/categories/%E5%86%99%E7%BB%99%E5%A4%A7%E5%BF%99%E4%BA%BA%E7%9C%8B%E7%9A%84NGINX/"},{"title":"写给大忙人看的技术书系类","uri":"https://www.ganymedenil.com/categories/%E5%86%99%E7%BB%99%E5%A4%A7%E5%BF%99%E4%BA%BA%E7%9C%8B%E7%9A%84%E6%8A%80%E6%9C%AF%E4%B9%A6%E7%B3%BB%E7%B1%BB/"},{"title":"前端","uri":"https://www.ganymedenil.com/categories/%E5%89%8D%E7%AB%AF/"},{"title":"区块链","uri":"https://www.ganymedenil.com/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"title":"开发","uri":"https://www.ganymedenil.com/categories/%E5%BC%80%E5%8F%91/"},{"title":"微服务","uri":"https://www.ganymedenil.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"title":"架构","uri":"https://www.ganymedenil.com/categories/%E6%9E%B6%E6%9E%84/"}],"posts":[{"content":"随着川普币（OFFICIAL TRUMP）的走红，SOL（SOLANA） 也重新回到大众视野。借此机会我将写一个关于SOL开发的专题教程以供参考，帮助大家理解 SOL 上的智能合约开发与代币铸造。\n本节我将从对称和不对称加密算法开始讲起，然后由浅入深到最后的如何使用自定义链上程序。\n警告 因本教程涉及资产交易，为了避免您的资金损失，该教程全程将在 DevNet上进行操作，如您需要在 MaiNet 上操作请务必谨慎。\n对称和非对称加密 “加密”指隐藏信息的研究。日常生活中你会遇到两种主要的加密类型：\n对称加密是指使用相同的密钥进行加密和解密。它已有数百年的历史，从古埃及人到伊丽莎白女王一世都在使用。\n对称加密算法有很多种，但今天最常见的是 AES 和 Chacha20。\n非对称加密 非对称加密，也称为“公钥加密”，诞生于 20 世纪 70 年代。在非对称加密中，参与者拥有一对密钥（或密钥对）。每个密钥对由一个私钥和一个公钥组成。非对称加密的工作方式与对称加密不同，并且可以完成不同的任务：\n**加密：**如果使用公钥加密，则只有来自同一密钥对的私钥才能用于读取它。\n**签名：**如果使用私钥加密，则可以使用来自同一密钥对的公钥来证明私钥持有者对其进行了签名。\n你甚至可以使用非对称加密来协商出一个用于对称加密的良好密钥！这称为密钥交换，你使用你的公钥和接收方的公钥来生成一个“会话”密钥。\n非对称加密算法有很多种，但今天最常见的是 ECC 或 RSA 的变体。\n非对称加密非常流行：\n你的银行卡内部有一个私钥，用于对交易进行签名。\n你的银行可以通过使用匹配的公钥检查交易来确认是你进行的交易。\n网站在其证书中包含一个公钥。你的浏览器将使用此公钥来加密它发送到网页的数据（如个人信息、登录详细信息和信用卡号）。\n网站拥有匹配的私钥，以便网站可以读取数据。\n你的电子护照由签发国进行签名，以确保护照不被伪造。\n电子护照闸门可以使用签发国的公钥来确认这一点。\n你手机上的消息应用程序使用密钥交换来生成会话密钥。\n简而言之，加密无处不在。Solana 以及其他区块链只是加密的众多用途之一。\nSolana 使用公钥作为地址 参与 Solana 网络的用户至少拥有一个密钥对。在 Solana 中：\n公钥被用作“地址”，指向 Solana 网络上的一个账户。即使是友好的名称——例如 example.sol ——也指向像 dDCQNnDmNbFVi8cQhKAgXhyhXeJ625tvwsunRyRc7c8 这样的地址。\n私钥用于验证对该密钥对的权限。如果您拥有某个地址的私钥，则您控制该地址内的代币。因此，顾名思义，您应该始终将私钥保密。\n生成密钥对 创建新目录，安装 TypeScript、Solana web3.js 和 esrun：\nmkdir generate-keypair cd generate-keypair npm init -y npm install typescript @solana/web3.js@1 esrun @solana-developers/helpers@2 新建一个文件名为generate-keypair.ts的文件\nimport { Keypair } from \u0026quot;@solana/web3.js\u0026quot;; const keypair = Keypair.generate(); console.log(`✅ Generated keypair!`); 运行npx esrun generate-keypair.ts。你应该看到以下文本：\n✅ Generated keypair! 每个Keypair都有一个publicKey和secretKey属性。更新文件：\nimport { Keypair } from \u0026quot;@solana/web3.js\u0026quot;; const keypair = Keypair.generate(); console.log(`The public key is: `, keypair.publicKey.toBase58()); console.log(`The secret key is: `, keypair.secretKey); console.log(`✅ Finished!`); 运行npx esrun generate-keypair.ts。你应该看到以下文本：\nThe public key is: CpuER4CRpfkLmXAdk3LDbh7urNqWyLL2gzyxoycmEeZc The secret key is: Uint8Array(64) [ (a long series of numbers) ] ✅ Finished! 不要在源代码中包含私钥\n由于密钥对可以从私钥重新生成，我们通常只存储私钥，并从私钥恢复密钥对。\n此外，由于私钥赋予了地址的控制权，我们不将私钥存储在源代码中。相反，我们：\n将私钥放入 .env 文件中 将 .env 添加到 .gitignore 中，这样 .env 文件就不会被提交。 从 .env 文件加载现有密钥对 为了确保您的私钥的安全，我们建议使用文件.env注入私钥：\n创建一个名为.env的新文件，其中包含您之前创建的私钥内容：\nSECRET_KEY=\u0026quot;[(a series of numbers)]\u0026quot; 然后我们可以从环境变量中加载密钥对。更新generate-keypair.ts：\nimport \u0026quot;dotenv/config\u0026quot;; import { getKeypairFromEnvironment } from \u0026quot;@solana-developers/helpers\u0026quot;; const keypair = getKeypairFromEnvironment(\u0026quot;SECRET_KEY\u0026quot;); console.log( `✅ Finished! We've loaded our secret key securely, using an env file!`, ); 运行npx esrun generate-keypair.ts。你应该看到以下结果：\n✅ Finished! We've loaded our secret key securely, using an env file! 从 Solana 网络读取数据 账户 Solana 上的所有数据都存储在账户中。账户可以存储：\nSOL 其他代币，如 USDC NFT 程序，就像我们在本课程中制作的电影评论程序！ 程序数据，就像上面程序的电影评论！ SOL SOL 是 Solana 的“原生代币”——这意味着 SOL 用于支付交易费用、账户租金和其他常见费用。SOL 有时用 ◎符号表示。每个 SOL 由 10 亿 Lamports 组成。\n就像金融应用程序通常以美分（美元）和便士（英镑）进行数学运算一样，Solana 应用程序通常以 Lamports 的形式转移、花费、存储和处理 SOL，仅在向用户显示时才转换为完整的 SOL。\n地址 地址唯一标识账户。地址通常显示为 base-58 编码的字符串，例如 dDCQNnDmNbFVi8cQhKAgXhyhXeJ625tvwsunRyRc7c8。Solana 上的大多数地址也是公钥。如上文所述，控制地址匹配私钥的人控制着该账户——例如，拥有私钥的人可以从该账户发送代币。\n操作 加载密钥对 我们将继续使用上文的公钥。\n创建一个名为check-balance.ts 的新文件，将\u0026lt;your public key\u0026gt;替换为您的公钥。\n脚本加载公钥，连接到 DevNet，并检查余额：\nimport { Connection, LAMPORTS_PER_SOL, PublicKey } from \u0026quot;@solana/web3.js\u0026quot;; const publicKey = new PublicKey(\u0026quot;\u0026lt;your public key\u0026gt;\u0026quot;); const connection = new Connection(\u0026quot;https://api.devnet.solana.com\u0026quot;, \u0026quot;confirmed\u0026quot;); const balanceInLamports = await connection.getBalance(publicKey); const balanceInSOL = balanceInLamports / LAMPORTS_PER_SOL; console.log( `💰 Finished! The balance for the wallet at address ${publicKey} is ${balanceInSOL}!`, ); 保存到文件中，并 npx esrun check-balance.ts 。你应该会看到类似的内容：\n💰 Finished! The balance for the wallet at address CpuER4CRpfkLmXAdk3LDbh7urNqWyLL2gzyxoycmEeZc is 0! 在 DevNet 上获取一些 SOL 在 Devnet 中，您可以获得免费的 SOL 用于开发。可以将 Devnet SOL 视为桌游用的钱币 - 它看起来有价值，但实际上没有价值。\n获取一些 Devnet SOL 并使用您的密钥对的公钥作为地址。\n选择您想要的任何数量的 SOL。\n检查您的余额 重新运行脚本。您应该会看到您的余额已更新：\n💰 Finished! The balance for the wallet at address CpuER4CRpfkLmXAdk3LDbh7urNqWyLL2gzyxoycmEeZc is 0.5! 查看任意地址的余额 您可以修改脚本以检查任何钱包的余额。\nimport { Connection, LAMPORTS_PER_SOL, PublicKey } from \u0026quot;@solana/web3.js\u0026quot;; const suppliedPublicKey = process.argv[2]; if (!suppliedPublicKey) { throw new Error(\u0026quot;Provide a public key to check the balance of!\u0026quot;); } const connection = new Connection(\u0026quot;https://api.devnet.solana.com\u0026quot;, \u0026quot;confirmed\u0026quot;); const publicKey = new PublicKey(suppliedPublicKey); const balanceInLamports = await connection.getBalance(publicKey); const balanceInSOL = balanceInLamports / LAMPORTS_PER_SOL; console.log( `✅ Finished! The balance for the wallet at address ${publicKey} is ${balanceInSOL}!`, ); % npx esrun check-balance.ts (some wallet address) ✅ Finished! The balance for the wallet at address CpuER4CRpfkLmXAdk3LDbh7urNqWyLL2gzyxoycmEeZc is 5! 在 Solana 网络上创建交易 交易是原子性的 任何对链上数据的修改都是通过发送给程序的交易来完成的。\nSolana 上的交易与其他地方的交易类似：它是原子性的。原子性意味着整个交易要么全部运行成功，要么全部失败。\n想象一下在线支付：\n你的账户余额被扣除 银行将资金转移给商家 这两件事都需要发生才能使交易成功。如果其中任何一个失败，都不应该发生任何事情，而不是支付给商家但不扣除你的账户，或者扣除账户但不支付给商家。\n原子性意味着要么交易发生——意味着所有单个步骤都成功——要么整个交易失败。\n交易包含指令 Solana 上交易中的步骤称为指令。\n每个指令包含：\n一个将被读取和/或写入的账户数组。这就是 Solana 快速的原因——影响不同账户的交易可以并行处理 要调用的程序的公钥 传递给被调用程序的数据，结构为字节数组 当一个交易运行时，一个或多个 Solana 程序将使用交易中包含的指令被调用。\n正如你所料，@solana/web3.js 提供了用于创建交易和指令的辅助函数。你可以使用构造函数 new Transaction() 创建一个新的交易。创建后，你可以使用 add() 方法向交易添加指令。\n其中一个辅助函数是 SystemProgram.transfer()，它为系统程序创建一个指令来转移一些 SOL：\nconst transaction = new Transaction(); const sendSolInstruction = SystemProgram.transfer({ fromPubkey: sender, toPubkey: recipient, lamports: LAMPORTS_PER_SOL * amount, }); transaction.add(sendSolInstruction); SystemProgram.transfer() 函数需要：\n发件人账户对应的公钥 收件人账户对应的公钥 要发送的 SOL 数量（以 lamports 为单位）。 SystemProgram.transfer() 返回用于将 SOL 从发件人发送到收件人的指令。\n此指令中使用的程序将是system程序（地址为 11111111111111111111111111111111），数据是要传输的 SOL 数量（以 Lamports 为单位），账户将基于发件人和收件人。\n然后，该指令可以添加到交易中。\n一旦添加了所有指令，就需要将交易发送到集群并进行确认：\nconst signature = sendAndConfirmTransaction(connection, transaction, [ senderKeypair, ]); sendAndConfirmTransaction() 函数接受以下参数：\n一个集群连接 一个交易 一个密钥对数组，作为交易的签名者 - 在本例中，我们只有一个签名者：发送者。 交易手续费 交易手续费是 Solana 经济的组成部分，作为对验证者网络处理交易所需的 CPU 和 GPU 资源的补偿。Solana 交易手续费是确定的。\n交易签名者数组中包含的第一个签名者负责支付交易手续费。如果该签名者的账户中没有足够的 SOL 来支付交易手续费，则交易将被丢弃，并出现类似以下错误：\n\u0026gt; Transaction simulation failed: Attempt to debit an account but found no record of a prior credit. 如果你遇到这个错误，那是因为你的密钥对是全新的，没有任何 SOL 来支付交易费用。让我们通过在设置连接后添加以下几行代码来解决这个问题：\nawait airdropIfRequired( connection, keypair.publicKey, 1 * LAMPORTS_PER_SOL, 0.5 * LAMPORTS_PER_SOL, ); 这会向你的账户存入 1 个 SOL，你可以用它来测试。这在主网（Mainnet）上行不通，因为在主网上 SOL 具有实际价值。但在本地和开发网（Devnet）上进行测试时，这非常方便。\n你也可以使用 Solana 命令行界面（CLI）命令 solana airdrop 1 来在你的账户中获得免费的测试 SOL，无论是在本地还是在开发网上进行测试。\nSolana 区块浏览器 所有在区块链上的交易都可以在 Solana 区块浏览器上公开查看。例如，你可以使用上面示例中 sendAndConfirmTransaction() 返回的签名，在 Solana 区块浏览器中搜索该签名，然后查看：\n何时发生 包含在哪个区块中 交易费用 以及更多！ 完整代码 创建一个名为transfer.ts的文件：\nimport { Connection, Transaction, SystemProgram, sendAndConfirmTransaction, PublicKey, } from \u0026quot;@solana/web3.js\u0026quot;; import \u0026quot;dotenv/config\u0026quot;; import { getKeypairFromEnvironment } from \u0026quot;@solana-developers/helpers\u0026quot;; const suppliedToPubkey = \u0026quot;CpuER4CRpfkLmXAdk3LDbh7urNqWyLL2gzyxoycmEeZc\u0026quot;; if (!suppliedToPubkey) { console.log(`Please provide a public key to send to`); process.exit(1); } const senderKeypair = getKeypairFromEnvironment(\u0026quot;SECRET_KEY\u0026quot;); console.log(`suppliedToPubkey: ${suppliedToPubkey}`); const toPubkey = new PublicKey(suppliedToPubkey); const connection = new Connection(\u0026quot;https://api.devnet.solana.com\u0026quot;, \u0026quot;confirmed\u0026quot;); console.log( `✅ Loaded our own keypair, the destination public key, and connected to Solana`, ); 运行脚本以确保它连接、加载密钥对并加载：\nnpx esrun transfer.ts 添加以下内容以完成交易并发送：\nconsole.log( `✅ Loaded our own keypair, the destination public key, and connected to Solana`, ); const transaction = new Transaction(); const LAMPORTS_TO_SEND = 5000; const sendSolInstruction = SystemProgram.transfer({ fromPubkey: senderKeypair.publicKey, toPubkey, lamports: LAMPORTS_TO_SEND, }); transaction.add(sendSolInstruction); const signature = await sendAndConfirmTransaction(connection, transaction, [ senderKeypair, ]); console.log( `💸 Finished! Sent ${LAMPORTS_TO_SEND} to the address ${toPubkey}. `, ); console.log(`Transaction signature is ${signature}!`); 执行脚本进行交易\nnpx esrun transfer.ts 使用自定义链上程序 在上文中，我们使用了来自 @solana/web3.js 的 SystemProgram.transfer() 函数，该函数会创建一个用于 System 程序来转移 SOL 的指令。\n然而，当与其他程序交互时，您需要手动创建指令。使用 @solana/web3.js，您可以使用 TransactionInstruction 构造函数来创建指令：\nconst instruction = new TransactionInstruction({ programId: PublicKey; keys: [ { pubkey: Pubkey, isSigner: boolean, isWritable: boolean, }, ], data?: Buffer; }); TransactionInstruction() 接受 3 个字段：\nprogramId 字段的含义非常明确：它是程序的公钥（也称为“地址”或“程序 ID”）。\nkeys 是一个账户数组，以及这些账户在交易期间将如何被使用。您需要了解您正在调用的程序的行为，并确保在数组中提供所有必要的账户。\npubkey - 账户的公钥 isSigner - 一个布尔值，表示该账户是否是交易的签名者 isWritable - 一个布尔值，表示该账户在交易执行期间是否会被写入 一个可选的 Buffer，包含要传递给程序的数据。我们现在将忽略 data 字段，但在以后的文章中会重新讨论它。\n创建指令后，我们将其添加到交易中，将交易发送到我们的 RPC 进行处理和确认，然后查看交易签名。\nconst transaction = new web3.Transaction().add(instruction); const signature = await web3.sendAndConfirmTransaction( connection, transaction, [payer], ); console.log(`✅ Success! Transaction signature is: ${signature}`); 编写 ping 计数器程序的交易 我们将创建一个脚本，用于 ping 一个链上程序，该程序每次被 ping 时都会递增一个计数器。该程序位于 Solana Devnet 上，地址为 ChT1B39WKLS8qUrkLvFDXMhEJ4F1XZzwUNHUt4AU9aVa。该程序将其数据存储在一个特定账户中，地址为 Ah9K7dQ8EHaZqcAsgBW8w37yN2eAy3koFmUn4x3CJtod。\n基础框架 # 我们将使用之前在“数据写入简介”中创建的相同的包和 .env 文件。\n将文件命名为 send-ping-transaction.ts：\nimport * as web3 from \u0026quot;@solana/web3.js\u0026quot;; import \u0026quot;dotenv/config\u0026quot;; import { getKeypairFromEnvironment, airdropIfRequired, } from \u0026quot;@solana-developers/helpers\u0026quot;; const payer = getKeypairFromEnvironment(\u0026quot;SECRET_KEY\u0026quot;); const connection = new web3.Connection(web3.clusterApiUrl(\u0026quot;devnet\u0026quot;)); const newBalance = await airdropIfRequired( connection, payer.publicKey, 1 * web3.LAMPORTS_PER_SOL, 0.5 * web3.LAMPORTS_PER_SOL, ); 这将连接到 Solana Devnet ，并在需要时请求一些测试用的 Lamports。\nPing 程序 现在让我们与 Ping 程序交互！为此，我们需要：\n创建一笔交易 创建一条指令 将指令添加到交易中 发送交易 记住，这里最具挑战性的部分是在指令中包含正确的信息。我们知道我们要调用的程序的地址。我们也知道该程序将数据写入一个单独的账户，我们也知道该账户的地址。让我们将这两个地址的字符串版本作为常量添加到文件的顶部：\nconst PING_PROGRAM_ADDRESS = \u0026quot;ChT1B39WKLS8qUrkLvFDXMhEJ4F1XZzwUNHUt4AU9aVa\u0026quot;; const PING_PROGRAM_DATA_ADDRESS = \u0026quot;Ah9K7dQ8EHaZqcAsgBW8w37yN2eAy3koFmUn4x3CJtod\u0026quot;; 现在让我们创建一个新的交易，然后初始化一个程序账户的公钥，以及另一个数据账户的公钥。\nconst transaction = new web3.Transaction(); const programId = new web3.PublicKey(PING_PROGRAM_ADDRESS); const pingProgramDataId = new web3.PublicKey(PING_PROGRAM_DATA_ADDRESS); 接下来，让我们创建指令。记住，指令需要包含 Ping 程序的公钥，还需要包含一个数组，其中包含所有将要读取或写入的账户。在这个示例程序中，只需要上面提到的数据账户。\nconst transaction = new web3.Transaction(); const programId = new web3.PublicKey(PING_PROGRAM_ADDRESS); const pingProgramDataId = new web3.PublicKey(PING_PROGRAM_DATA_ADDRESS); const instruction = new web3.TransactionInstruction({ keys: [ { pubkey: pingProgramDataId, isSigner: false, isWritable: true, }, ], programId, }); 接下来，让我们将这条指令添加到我们创建的交易中。然后，通过传入连接、交易和付款人来调用 sendAndConfirmTransaction()。最后，让我们记录该函数调用的结果，以便我们可以在 Solana Explorer 上查找它。\ntransaction.add(instruction); const signature = await web3.sendAndConfirmTransaction( connection, transaction, [payer], ); console.log(`✅ Transaction completed! Signature is ${signature}`); 运行 ping 客户端并检查 Solana 浏览器 现在使用以下命令运行代码：\nnpx esrun send-ping-transaction.ts 可能需要一两分钟，但你应该会在控制台中看到一个长字符串，如下所示：\n✅ Transaction completed! Signature is 4Kpb4EQ3RPBfqQDNZzKFc2MJo4F7vAajoaNQdLmsAhZ4UF9fvMUTaNmqERXQPu6oxjSSviL7sDbTLdy4Vrk7qXbS 复制交易签名。然后访问Devnet上的 Solana 浏览器。将签名粘贴到 Solana 浏览器顶部的搜索栏中（确保你已连接到开发网）并按回车键。你应该会看到有关交易的所有详细信息。如果你一直滚动到底部，那么你将看到程序日志，其中显示了程序被 ping 的次数，包括你的 ping。\n滚动浏览浏览器并查看你所看到的内容：\n账户输入将包括： 你的付款人地址 - 交易中扣除 5000 lamports ping 程序的程序地址 ping 程序的数据地址 指令部分将包含一条没有数据的指令 - ping 程序是一个非常简单的程序，因此它不需要任何数据。 程序指令日志显示 ping 程序的日志。 如果你希望将来更容易在 Solana 浏览器中查看交易，只需将你的 console.log 更改为以下内容：\nconsole.log( `You can view your transaction on Solana Explorer at:\\nhttps://explorer.solana.com/tx/${signature}?cluster=devnet`, ); 就这样，你就在 Solana 网络上调用程序并在链上写入数据了！\n","id":0,"section":"posts","summary":"\u003cp\u003e随着川普币（\u003ca href=\"https://solscan.io/token/6p6xgHyF7AeE6TZkSmFsko444wqoP15icUSqi2jfGiPN\"\u003eOFFICIAL TRUMP\u003c/a\u003e）的走红，SOL（\u003ca href=\"https://solana.com/zh\"\u003eSOLANA\u003c/a\u003e） 也重新回到大众视野。借此机会我将写一个关于SOL开发的专题教程以供参考，帮助大家理解 SOL 上的智能合约开发与代币铸造。\u003c/p\u003e\n\u003cp\u003e本节我将从对称和不对称加密算法开始讲起，然后由浅入深到最后的如何使用自定义链上程序。\u003c/p\u003e","tags":["SOL","Solana","web3"],"title":"Solana 链开发实战（一）","uri":"https://www.ganymedenil.com/2025/01/23/solana-tutorial-1.html","year":"2025"},{"content":"Gemma 是一个基于 Google DeepMind 的 Gemini1 研究和技术的轻量级、最先进的开放大型语言模型家族。本教程演示了如何使用 Google DeepMind 的 gemma 库来执行 Gemma 2B Instruct 模型的基本采样/推理，该库是用 JAX2（一个高性能数值计算库）、Flax3（基于 JAX 的神经网络库）、Orbax4（一个基于 JAX 的用于训练工具如检查点的库）和 SentencePiece5（一个分词器/合词器库）编写的。尽管在这个笔记本中没有直接使用 Flax，但 Flax 被用于创建 Gemma。\n设置 1. 设置 Kaggle 上的 Gemma 访问权限 要完成本教程，您首先需要按照 Gemma 设置6说明操作，这些说明将向您展示如何执行以下操作：\n在 kaggle.com7 上获取对 Gemma 的访问权限。 选择一个具有足够资源的 Colab 运行环境来运行 Gemma 模型。 生成并配置 Kaggle 用户名和 API 密钥。 完成 Gemma 设置后，继续进行下一部分，您将为您的 Colab 环境设置环境变量。\n2. 设置环境变量 为 KAGGLE_USERNAME 和 KAGGLE_KEY 设置环境变量。在出现“授权访问？”的提示时，同意提供密钥访问。\nfrom kaggle_secrets import UserSecretsClient user_secrets = UserSecretsClient() secret_value_0 = user_secrets.get_secret(\u0026quot;KAGGLE_KEY \u0026quot;) secret_value_1 = user_secrets.get_secret(\u0026quot;KAGGLE_USERNAME\u0026quot;) 3. 安装 gemma 库 本笔记本着重于使用免费的 Colab GPU。要启用硬件加速，请点击编辑 \u0026gt; 笔记本设置 \u0026gt; 选择 T4 GPU \u0026gt; 保存。\n接下来，您需要从 github.com/google-deepmind/gemma 安装 Google DeepMind 的 gemma 库。如果您遇到关于“pip 的依赖解析器”的错误，通常可以忽略它。\n注意：通过安装 gemma，您还将安装 flax、core jax、optax（基于 JAX 的梯度处理和优化库）、orbax 和 sentencepiece。\n!pip install -q git+https://github.com/google-deepmind/gemma.git 加载并准备 Gemma 模型 使用 kagglehub.model_download 加载 Gemma 模型，该函数需要三个参数：\nhandle：来自 Kaggle 的模型句柄 path：（可选字符串）本地路径 force_download：（可选布尔值）强制重新下载模型 注意：gemma-2b-it 模型的大小约为 3.7Gb。\nGEMMA_VARIANT = '2b-it' # @param ['2b', '2b-it'] {type:\u0026quot;string\u0026quot;} import kagglehub GEMMA_PATH = kagglehub.model_download(f'google/gemma/flax/{GEMMA_VARIANT}') print('GEMMA_PATH:', GEMMA_PATH) GEMMA_PATH: /kaggle/input/gemma/flax/2b-it/2 注意：上面输出的路径是模型权重和令牌器在本地保存的地方，之后我们还会需要。\n检查模型权重和分词器的位置，然后设置路径变量。分词器目录将位于您下载模型的主目录中，而模型权重将位于一个子目录中。例如：\n分词器的 tokenizer.model 文件将位于 /LOCAL/PATH/TO/gemma/flax/2b-it/2。 模型的检查点将位于 /LOCAL/PATH/TO/gemma/flax/2b-it/2/2b-it。 在进行下一步之前，请确保正确设置这些路径，以便您的代码能够正确访问和加载模型及其组件。\nCKPT_PATH = os.path.join(GEMMA_PATH, GEMMA_VARIANT) TOKENIZER_PATH = os.path.join(GEMMA_PATH, 'tokenizer.model') print('CKPT_PATH:', CKPT_PATH) print('TOKENIZER_PATH:', TOKENIZER_PATH) CKPT_PATH: /kaggle/input/gemma/flax/2b-it/2/2b-it TOKENIZER_PATH: /kaggle/input/gemma/flax/2b-it/2/tokenizer.model 执行抽样/推理 加载和格式化 Gemma 模型检查点，使用 gemma.params.load_and_format_params 方法：\nfrom gemma import params as params_lib params = params_lib.load_and_format_params(CKPT_PATH) 加载使用 sentencepiece.SentencePieceProcessor 构建的 Gemma 分词器：\nimport sentencepiece as spm vocab = spm.SentencePieceProcessor() vocab.Load(TOKENIZER_PATH) True 要从 Gemma 模型检查点自动加载正确的配置，请使用 gemma.transformer.TransformerConfig。cache_size 参数是 Gemma Transformer 缓存中的时间步数。之后，使用 gemma.transformer.Transformer（继承自 flax.linen.Module）实例化 Gemma 模型为 transformer。\n注意：由于当前 Gemma 版本中存在未使用的令牌，词汇量比输入嵌入的数量小。\nfrom gemma import transformer as transformer_lib transformer_config = transformer_lib.TransformerConfig.from_params( params=params, cache_size=1024 ) transformer = transformer_lib.Transformer(transformer_config) 创建一个采样器，使用 gemma.sampler.Sampler 在 Gemma 模型的检查点/权重和分词器之上：\nfrom gemma import sampler as sampler_lib sampler = sampler_lib.Sampler( transformer=transformer, vocab=vocab, params=params['transformer'], ) 在 input_batch 中编写一个提示，并执行推理。可以调整 total_generation_steps（生成响应时执行的步数 —— 本例中使用100以保存主机内存）。\n注意：如果内存不足，请点击 Runtime \u0026gt; Disconnect and delete runtime，然后选择 Runtime \u0026gt; Run all。\nprompt = [ \u0026quot;\\n# What is the meaning of life?\u0026quot;, ] reply = sampler(input_strings=prompt, total_generation_steps=100, ) for input_string, out_string in zip(prompt, reply.text): print(f\u0026quot;Prompt:\\n{input_string}\\nOutput:\\n{out_string}\u0026quot;) Prompt: # What is the meaning of life? Output: The question of what the meaning of life is one that has occupied the minds of philosophers, theologians, and individuals for centuries. There is no single, universally accepted answer, but there are many different perspectives on this complex and multifaceted question. **Some common perspectives on the meaning of life include:** * **Biological perspective:** From a biological standpoint, the meaning of life is to survive and reproduce. * **Existential perspective:** Existentialists believe that life is not inherently meaningful and that （可选）如果已完成笔记本并想尝试其他提示，运行此单元以释放内存。之后，可以在第三步再次实例化采样器，并在第四步自定义并运行提示。\ndel sampler 来源 本文翻译自 Gemma JAX inference https://www.kaggle.com/code/windmaple/gemma-jax-inference\nGoogle DeepMind 的 Gemini https://github.com/google-deepmind/gemma\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJAX https://jax.readthedocs.io/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nFlax https://flax.readthedocs.io/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOrbax https://orbax.readthedocs.io/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSentencePiece https://github.com/google/sentencepiece\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 设置 https://ai.google.dev/gemma/docs/setup\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nkaggle gemma 模型 https://www.kaggle.com/models/google/gemma/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":1,"section":"posts","summary":"\u003cp\u003eGemma 是一个基于 Google DeepMind 的 Gemini\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e 研究和技术的轻量级、最先进的开放大型语言模型家族。本教程演示了如何使用 Google DeepMind 的 gemma 库来执行 Gemma 2B Instruct 模型的基本采样/推理，该库是用 JAX\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e（一个高性能数值计算库）、Flax\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e（基于 JAX 的神经网络库）、Orbax\u003csup id=\"fnref:4\"\u003e\u003ca href=\"#fn:4\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e4\u003c/a\u003e\u003c/sup\u003e（一个基于 JAX 的用于训练工具如检查点的库）和 SentencePiece\u003csup id=\"fnref:5\"\u003e\u003ca href=\"#fn:5\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e5\u003c/a\u003e\u003c/sup\u003e（一个分词器/合词器库）编写的。尽管在这个笔记本中没有直接使用 Flax，但 Flax 被用于创建 Gemma。\u003c/p\u003e","tags":["gemma","JAX"],"title":"Gemma JAX 推理","uri":"https://www.ganymedenil.com/2024/04/20/Gemma-JAX-inference.html","year":"2024"},{"content":"Gemma 是一个轻量级、先进的开放模型家族，由用于创建 Google Gemini 模型的研究和技术构建。Gemma 可以进一步微调以满足特定需求。但是，像 Gemma 这样的大型语言模型可能会非常大，有些可能不适合在单个加速器上进行微调。在这种情况下，有两种一般方法来对它们进行微调：\n参数高效微调（PEFT），旨在通过牺牲一些保真度来缩小有效模型大小。LoRA 属于这一类别，在 Keras 中使用 LoRA 微调 Gemma 模型1的教程演示了如何使用 KerasNLP 在单个 GPU 上使用 LoRA 微调 Gemma 2B 模型 gemma_2b_en。\n使用模型并行性的全参数微调。模型并行性将单个模型的权重分布在多个设备上，并实现水平扩展。您可以在这个 Keras指南2中了解更多关于分布式训练的信息。\n本教程指导您如何使用 Keras 与 JAX 后端，通过 LoRA 和模型并行分布式训练在 Google 的张量处理单元（TPU）上微调 Gemma 7B 模型。请注意，在本教程中可以关闭 LoRA，进行较慢但更准确的全参数调整。\n使用加速器 技术上，您可以在本教程中使用 TPU 或 GPU。\n关于 TPU 环境的说明 Google 提供了3种TPU产品：\nColab3 提供的 TPU v2 对于本教程来说不够用。 Kaggle4 免费提供 TPU v3，适用于本教程。 Cloud TPU5 提供 TPU v3 和更新一代的 TPU。设置它的一种方式是： 创建一个新的 TPU VM6 为您打算使用的 Jupyter 服务器端口设置SSH端口转发7 在 TPU VM 上安装 Jupyter 并启动，然后通过“连接到本地运行时”连接到 Colab 关于多 GPU 设置的说明 虽然本教程侧重于 TPU 的使用案例，但如果您有多 GPU 机器，可以轻松地根据自己的需要调整它。\n如果您倾向于通过 Colab 工作，也可以直接通过 Colab 连接菜单中的“连接到自定义 GCE VM”为 Colab 配置多 GPU VM。\n我们将重点放在使用 Kaggle 提供的免费 TPU 上。\n开始之前 Gemma 设置 要完成本教程，您首先需要按照 Gemma 设置8的说明完成设置。Gemma 设置说明将向您展示如何进行以下操作：\nGemma 模型由 Kaggle 托管。要使用 Gemma，请在 Kaggle 上请求访问权限：\n在 kaggle.com9 登录或注册。 打开 Gemma 模型卡片10并选择“请求访问权限”。 完成同意表格并接受条款和条件。 安装 安装 Keras 和 KerasNLP。\n# 安装最新的 Keras 3。更多信息查看 https://keras.io/getting_started/。 !pip install -q tensorflow-cpu !pip install -q -U keras-nlp tensorflow-hub !pip install -q -U keras\u0026gt;=3 !pip install -U tensorflow-text 设置 Keras JAX 后端 导入 JAX 并在 TPU 上运行健全性检查。 Kaggle 提供 TPUv3-8 设备，该设备具有 8 个 TPU 核心，每个核心有 16GB 内存。\nimport jax jax.devices() [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)] import os # Keras 3 分布式 API 目前仅针对 JAX 后端实现 os.environ[\u0026quot;KERAS_BACKEND\u0026quot;] = \u0026quot;jax\u0026quot; # 预分配 90% 的 TPU 内存，以最大程度地减少内存碎片和分配开销 os.environ[\u0026quot;XLA_PYTHON_CLIENT_MEM_FRACTION\u0026quot;] = \u0026quot;0.9\u0026quot; 加载模型 import keras import keras_nlp 在 NVIDIA GPU 上进行混合精度训练的说明 在 NVIDIA GPU 上训练时，可以使用混合精度（keras.mixed_precision.set_global_policy('mixed_bfloat16')）来加速训练，对训练质量的影响最小。在大多数情况下，建议开启混合精度，因为它既节省内存又节省时间。但是，请注意，在小批量大小下，它可能会使内存使用量增加1.5倍（权重将被加载两次，一次为半精度，一次为全精度）。\n对于推理，半精度（keras.config.set_floatx(\u0026quot;bfloat16\u0026quot;)）将会起作用并节省内存，而混合精度则不适用。\n# 如果您想在 GPU 上启用混合精度训练，请取消注释下面的行 # keras.mixed_precision.set_global_policy('mixed_bfloat16') 要在 TPU上分布式加载模型及其权重和张量，首先需要创建一个新的DeviceMesh。DeviceMesh 代表了一组为分布式计算配置的硬件设备，这在 Keras 3 中作为统一分布式API的一部分被引入。\n分布式 API 支持数据和模型并行性，允许在多个加速器和主机上高效地扩展深度学习模型。它利用底层框架（例如JAX）根据分片指令通过称为单程序多数据（SPMD）扩展的过程分布程序和张量。欲了解更多详情，请查看新的 Keras 3 分布式API指南11。\n# 要创建一个形状为（1, 8）的DeviceMesh，以便在所有8个TPUs上分片权重。 device_mesh = keras.distribution.DeviceMesh( (1, 8), [\u0026quot;batch\u0026quot;, \u0026quot;model\u0026quot;], devices=keras.distribution.list_devices()) 来自分布式 API 的 LayoutMap 指定了如何使用字符串键对权重和张量进行分片或复制，例如下面的 token_embedding/embeddings，这些键被当作正则表达式来匹配张量路径。匹配到的张量将根据模型维度（8 个 TPU）进行分片；其他的则会被完全复制。\nmodel_dim = \u0026quot;model\u0026quot; layout_map = keras.distribution.LayoutMap(device_mesh) # 与“token_embedding/embeddings”匹配的权重将在 8 个 TPU 上进行分片 layout_map[\u0026quot;token_embedding/embeddings\u0026quot;] = (None, model_dim) # 用于匹配解码器中的查询、键和值矩阵的正则表达式 # 注意力层 layout_map[\u0026quot;decoder_block.*attention.*(query|key|value).*kernel\u0026quot;] = ( None, model_dim, None) layout_map[\u0026quot;decoder_block.*attention_output.*kernel\u0026quot;] = ( None, None, model_dim) layout_map[\u0026quot;decoder_block.*ffw_gating.*kernel\u0026quot;] = (model_dim, None) layout_map[\u0026quot;decoder_block.*ffw_linear.*kernel\u0026quot;] = (None, model_dim) ModelParallel 允许您在 DeviceMesh 上的所有设备之间分片模型权重或激活张量。在这种情况下，一些 Gemma 7B 模型的权重根据上面定义的 layout_map 在 8 个 TPU 芯片之间进行了分片。现在以分布式方式加载模型。\nmodel_parallel = keras.distribution.ModelParallel( device_mesh, layout_map, batch_dim_name=\u0026quot;batch\u0026quot;) keras.distribution.set_distribution(model_parallel) gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\u0026quot;gemma_7b_en\u0026quot;) 现在验证模型是否已正确分区。 我们以decoder_block_1为例。\ndecoder_block_1 = gemma_lm.backbone.get_layer('decoder_block_1') print(type(decoder_block_1)) for variable in decoder_block_1.weights: print(f'{variable.path:\u0026lt;58} {str(variable.shape):\u0026lt;16} {str(variable.value.sharding.spec)}') \u0026lt;class 'keras_nlp.src.models.gemma.gemma_decoder_block.GemmaDecoderBlock'\u0026gt; decoder_block_1/pre_attention_norm/scale (3072,) PartitionSpec(None,) decoder_block_1/attention/query/kernel (16, 3072, 256) PartitionSpec(None, 'model', None) decoder_block_1/attention/key/kernel (16, 3072, 256) PartitionSpec(None, 'model', None) decoder_block_1/attention/value/kernel (16, 3072, 256) PartitionSpec(None, 'model', None) decoder_block_1/attention/attention_output/kernel (16, 256, 3072) PartitionSpec(None, None, 'model') decoder_block_1/pre_ffw_norm/scale (3072,) PartitionSpec(None,) decoder_block_1/ffw_gating/kernel (3072, 24576) PartitionSpec('model', None) decoder_block_1/ffw_gating_2/kernel (3072, 24576) PartitionSpec('model', None) decoder_block_1/ffw_linear/kernel (24576, 3072) PartitionSpec(None, 'model') 微调前推理 gemma_lm.generate(\u0026quot;Best comedy movies in the 90s \u0026quot;, max_length=64) 'Best comedy movies in the 90s 1. The Naked Gun 2½: The Smell of Fear (1991) 2. Wayne’s World (1992) 3. The Naked Gun 33⅓: The Final Insult (1994)' 该模型生成了 90 年代值得观看的精彩喜剧电影列表。 现在我们微调 Gemma 模型来改变输出风格。\n使用 IMDB数据微调 import tensorflow_datasets as tfds imdb_train = tfds.load( \u0026quot;imdb_reviews\u0026quot;, split=\u0026quot;train\u0026quot;, as_supervised=True, batch_size=2, ) # 丢弃标签 imdb_train = imdb_train.map(lambda x, y: x) imdb_train.unbatch().take(1).get_single_element().numpy() # 使用数据集的子集来加快训练速度。 imdb_train = imdb_train.take(2000) 使用低秩适应（LoRA）12进行微调。LoRA 是一种微调技术，通过冻结模型的全部权重并在模型中插入较少数量的新可训练权重，大大减少了下游任务的可训练参数数量。基本上，LoRA 通过两个较小的低秩矩阵 AxB 进行重新参数化，以进行训练，这种技术使训练更加快速和内存高效。\n# 为模型启用 LoRA 并将 LoRA 秩设置为 4。 gemma_lm.backbone.enable_lora(rank=4) # 对 IMDb 电影评论数据集进行微调。 # 将输入序列长度限制为 128 以控制内存使用。 gemma_lm.preprocessor.sequence_length = 128 # 使用 AdamW（transformer 模型的常见优化器）。 optimizer = keras.optimizers.AdamW( learning_rate=5e-5, weight_decay=0.01, ) # 从衰减（decay）中排除 layernorm 和偏置项。 optimizer.exclude_from_weight_decay(var_names=[\u0026quot;bias\u0026quot;, \u0026quot;scale\u0026quot;]) gemma_lm.compile( loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=optimizer, weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()], ) gemma_lm.summary() gemma_lm.fit(imdb_train, epochs=1) 请注意，启用 LoRA 会显着减少可训练参数的数量，从 70 亿个减少到仅 1100 万个。\n微调后推理 gemma_lm.generate(\u0026quot;Best comedy movies in the 90s \u0026quot;, max_length=64) 'Best comedy movies in the 90s 1990-1999. 10. Austin Powers - International Man of Mystery (1997) 9. The Wedding Singer (1998) 8. The Cable Guy (1996) 7' 经过微调后，该模型已经了解了电影评论的风格，并且不会在 90 年代喜剧电影的背景下生成该风格的输出。\n来源 本文翻译自 Keras Gemma distributed finetuning and inference https://www.kaggle.com/code/nilaychauhan/keras-gemma-distributed-finetuning-and-inference\n在 Keras 中使用 LoRA 微调 Gemma 模型 https://ganymedenil.com/2024/03/30/Fine-tune-Gemma-model-%20in-Keras-using-LoRA.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeras指南 https://keras.io/guides/distribution/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nColab https://colab.sandbox.google.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKaggle https://www.kaggle.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nCloud TPU https://cloud.google.com/tpu?hl=en\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTPU VM https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm#tpu-vms\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSSH端口转发 https://cloud.google.com/solutions/connecting-securely#port-forwarding-over-ssh\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 设置 https://ai.google.dev/gemma/docs/setup\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nkaggle.com https://www.kaggle.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 模型卡片 https://www.kaggle.com/models/google/gemma\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeras 3 分布式API指南 https://keras.io/guides/distribution/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n低秩适应 https://arxiv.org/abs/2106.09685\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":2,"section":"posts","summary":"\u003cp\u003eGemma 是一个轻量级、先进的开放模型家族，由用于创建 Google Gemini 模型的研究和技术构建。Gemma 可以进一步微调以满足特定需求。但是，像 Gemma 这样的大型语言模型可能会非常大，有些可能不适合在单个加速器上进行微调。在这种情况下，有两种一般方法来对它们进行微调：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e参数高效微调（PEFT），旨在通过牺牲一些保真度来缩小有效模型大小。LoRA 属于这一类别，在 Keras 中使用 LoRA 微调 Gemma 模型\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e的教程演示了如何使用 KerasNLP 在单个 GPU 上使用 LoRA 微调 Gemma 2B 模型 gemma_2b_en。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e使用模型并行性的全参数微调。模型并行性将单个模型的权重分布在多个设备上，并实现水平扩展。您可以在这个 Keras指南\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e中了解更多关于分布式训练的信息。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e本教程指导您如何使用 Keras 与 JAX 后端，通过 LoRA 和模型并行分布式训练在 Google 的张量处理单元（TPU）上微调 Gemma 7B 模型。请注意，在本教程中可以关闭 LoRA，进行较慢但更准确的全参数调整。\u003c/p\u003e","tags":["gemma","kerasNLP"],"title":"在使用 Keras 进行 Gemma 模型的分布式微调和推理","uri":"https://www.ganymedenil.com/2024/03/30/Keras-Gemma-distributed-finetuning-and-inference.html","year":"2024"},{"content":"大型语言模型（LLM）如 Gemma 已被证明在多种自然语言处理（NLP）任务上有效。LLM首先通过自监督方式在大量文本语料上进行预训练。预训练帮助 LLM 学习通用知识，例如单词之间的统计关系。然后，可以使用特定领域的数据对 LLM 进行微调，以执行下游任务（如情感分析）。\nLLM 的大小极大（参数数量达到数百万）。对于大多数应用来说，不需要进行完全微调（更新模型中的所有参数），因为典型的微调数据集相对于预训练数据集要小得多。\n低秩适应（LoRA）1是一种微调技术，通过冻结模型的权重并在模型中插入较少数量的新权重，大大减少了下游任务的可训练参数数量。这使得使用 LoRA 进行训练更快、更节省内存，并且生成的模型权重更小（几百MB），同时保持了模型输出的质量。\n本教程将引导您使用 KerasNLP 对 Gemma 2B 模型进行 LoRA 微调，使用的是 Databricks Dolly 15k数据集2。该数据集包含15,000个高质量的人类生成的提示/响应对，专门用于微调 LLM。\n设置 Gemma 设置 要完成本教程，您首先需要按照 Gemma 设置3的说明完成设置。Gemma 设置说明将向您展示如何进行以下操作：\nGemma 模型由 Kaggle 托管。要使用 Gemma，请在 Kaggle 上请求访问权限：\n在 kaggle.com4 登录或注册。 打开 Gemma 模型卡片5并选择“请求访问权限”。 完成同意表格并接受条款和条件。 安装依赖 安装 Keras 、 KerasNLP 和其他依赖。\n# 安装最新的 Keras 3。更多信息查看 https://keras.io/getting_started/。 !pip install -q -U keras-nlp !pip install -q -U keras\u0026gt;=3 选择一个后端 Keras 是一个高级的、多框架的深度学习API，设计上注重简单性和易用性。Keras 3 允许您选择后端：TensorFlow、JAX或 PyTorch。这三个后端对于本教程都适用。\n在本教程中，我们使用 JAX 作为后端。\nimport os os.environ[\u0026quot;KERAS_BACKEND\u0026quot;] = \u0026quot;jax\u0026quot; # 或者 \u0026quot;tensorflow\u0026quot; 、 \u0026quot;torch\u0026quot;。 # 在使用JAX后端时，避免内存碎片化。 os.environ[\u0026quot;XLA_PYTHON_CLIENT_MEM_FRACTION\u0026quot;]=\u0026quot;1.00\u0026quot; 导入包 导入 Keras 和 KerasNLP。\nimport keras import keras_nlp 加载数据集 预处理数据是微调模型的重要步骤，尤其是当使用大型语言模型时。本教程使用的是1000个训练示例的子集，以便更快地执行。如果想要获得更高质量的微调效果，建议使用更多的训练数据。\nimport json data = [] with open('/kaggle/input/databricks-dolly-15k/databricks-dolly-15k.jsonl') as file: for line in file: features = json.loads(line) # 过滤掉带有上下文的示例，以保持简单。 if features[\u0026quot;context\u0026quot;]: continue # 将整个示例格式化为单个字符串。 template = \u0026quot;Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\u0026quot; data.append(template.format(**features)) # 仅使用 1000 个训练示例，以保持快速。 data = data[:1000] 加载模型 KerasNLP 提供了许多流行模型架构6的实现。在本教程中，您将使用 GemmaCausalLM 创建一个模型，这是一个用于因果语言建模的端到端 Gemma 模型。因果语言模型基于前面的令牌预测下一个令牌。\n使用 from_preset 方法创建模型：\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\u0026quot;gemma_2b_en\u0026quot;) gemma_lm.summary() Preprocessor: \u0026quot;gemma_causal_lm_preprocessor\u0026quot; Tokenizer (type) Vocab # gemma_tokenizer (GemmaTokenizer) 256,000 Model: \u0026quot;gemma_causal_lm\u0026quot; Layer (type) Output Shape Param # Connected to padding_mask (InputLayer) (None, None) 0 - token_ids (InputLayer) (None, None) 0 - gemma_backbone (GemmaBackbone) (None, None, 2048) 2,506,172,416 padding_mask[0][0], token_ids[0][0] token_embedding (ReversibleEmbedding) (None, None, 256000) 524,288,000 gemma_backbone[0][0] Total params: 2,506,172,416 (9.34 GB) Trainable params: 2,506,172,416 (9.34 GB) Non-trainable params: 0 (0.00 B) from_preset 方法从预设的架构和权重中实例化模型。在上述代码中，字符串 \u0026ldquo;gemma_2b_en\u0026rdquo; 指定了预设的架构 —— 一个拥有 20 亿参数的 Gemma 模型。\n注意：Gemma 也提供了一个有 70 亿参数的模型。要在 Colab 中运行更大的模型，您需要访问付费计划中提供的高级 GPU。或者，您可以在 Kaggle 或 Google Cloud 上对 Gemma 7B 模型进行分布式调优7。\n在微调之前的推理 在本节中，您将用各种提示查询模型，以查看其如何响应。\n欧洲旅行提示 查询模型以获取关于欧洲旅行应做些什么的建议。\nprompt = template.format( instruction=\u0026quot;What should I do on a trip to Europe?\u0026quot;, response=\u0026quot;\u0026quot;, ) print(gemma_lm.generate(prompt, max_length=256)) Instruction: What should I do on a trip to Europe? Response: 1. Take a trip to Europe. 2. Take a trip to Europe. 3. Take a trip to Europe. 4. Take a trip to Europe. 5. Take a trip to Europe. 6. Take a trip to Europe. 7. Take a trip to Europe. 8. Take a trip to Europe. 9. Take a trip to Europe. 10. Take a trip to Europe. 11. Take a trip to Europe. 12. Take a trip to Europe. 13. Take a trip to Europe. 14. Take a trip to Europe. 15. Take a trip to Europe. 16. Take a trip to Europe. 17. Take a trip to Europe. 18. Take a trip to Europe. 19. Take a trip to Europe. 20. Take a trip to Europe. 21. Take a trip to Europe. 22. Take a trip to Europe. 23. Take a trip to Europe. 24. Take a trip to Europe. 25. Take a trip to 该模型只是重复打印“Take a trip to Europe”。\nELI5 光合作用提示 提示模型用 5 岁儿童能够理解的简单术语解释光合作用。\nprompt = template.format( instruction=\u0026quot;Explain the process of photosynthesis in a way that a child could understand.\u0026quot;, response=\u0026quot;\u0026quot;, ) print(gemma_lm.generate(prompt, max_length=256)) Instruction: Explain the process of photosynthesis in a way that a child could understand. Response: Photosynthesis is the process by which plants use the energy from the sun to convert water and carbon dioxide into oxygen and glucose. The process begins with the absorption of light energy by chlorophyll molecules in the leaves of plants. The energy from the light is used to split water molecules into hydrogen and oxygen. The oxygen is released into the atmosphere, while the hydrogen is used to make glucose. The glucose is then used by the plant to make energy and grow. Explanation: Photosynthesis is the process by which plants use the energy from the sun to convert water and carbon dioxide into oxygen and glucose. The process begins with the absorption of light energy by chlorophyll molecules in the leaves of plants. The energy from the light is used to split water molecules into hydrogen and oxygen. The oxygen is released into the atmosphere, while the hydrogen is used to make glucose. The glucose is then used by the plant to make energy and grow. Explanation: Photosynthesis is the process by which plants use the energy from the sun to convert water and carbon dioxide into oxygen and glucose. The process begins with the absorption of light energy by chlorophyll molecules in the leaves of plants. The energy from 回答中包含对儿童来说可能不容易理解的单词，例如叶绿素、葡萄糖等。\nLoRA 微调 要从模型中获得更好的响应，可以使用 Databricks Dolly 15k 数据集通过低秩适应（LoRA）对模型进行微调。\nLoRA 秩决定了添加到 LLM 原始权重中的可训练矩阵的维度。它控制着微调调整的表达性和精度。\n更高的秩意味着可以进行更详细的更改，但也意味着有更多的可训练参数。较低的秩意味着计算开销较小，但可能导致适应性不够精确。\n本教程使用的 LoRA 秩为 4。在实践中，从相对较小的秩开始（例如 4、8、16）是计算上高效的试验方法。使用这个秩训练您的模型，并评估在您的任务上的性能改进。逐渐增加后续试验的秩，看看是否能进一步提高性能。\n# 为模型启用 LoRA 并将 LoRA 秩设置为 4。 gemma_lm.backbone.enable_lora(rank=4) gemma_lm.summary() Preprocessor: \u0026quot;gemma_causal_lm_preprocessor\u0026quot; Tokenizer (type) Vocab # gemma_tokenizer (GemmaTokenizer) 256,000 Model: \u0026quot;gemma_causal_lm\u0026quot; Layer (type) Output Shape Param # Connected to padding_mask (InputLayer) (None, None) 0 - token_ids (InputLayer) (None, None) 0 - gemma_backbone (GemmaBackbone) (None, None, 2048) 2,507,536,384 padding_mask[0][0], token_ids[0][0] token_embedding (ReversibleEmbedding) (None, None, 256000) 524,288,000 gemma_backbone[0][0] Total params: 2,507,536,384 (9.34 GB) Trainable params: 1,363,968 (5.20 MB) Non-trainable params: 2,506,172,416 (9.34 GB) 请注意，启用 LoRA 会显着减少可训练参数的数量（从 25 亿减少到 130 万）。\n# 将输入序列长度限制为 512（以控制内存使用）。 gemma_lm.preprocessor.sequence_length = 512 # 使用 AdamW（transformer 模型的常见优化器）。 optimizer = keras.optimizers.AdamW( learning_rate=5e-5, weight_decay=0.01, ) # 从衰减（decay）中排除 layernorm 和偏置项。 optimizer.exclude_from_weight_decay(var_names=[\u0026quot;bias\u0026quot;, \u0026quot;scale\u0026quot;]) gemma_lm.compile( loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=optimizer, weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()], ) gemma_lm.fit(data, epochs=1, batch_size=1) 微调之后的推理 微调后，模型的响应会遵循提示中提供的指令。\n欧洲旅行提示 prompt = template.format( instruction=\u0026quot;What should I do on a trip to Europe?\u0026quot;, response=\u0026quot;\u0026quot;, ) print(gemma_lm.generate(prompt, max_length=256)) Instruction: What should I do on a trip to Europe? Response: You should plan to see the most famous sights in Europe. The Eiffel Tower, the Acropolis, and the Colosseum are just a few. You should also plan on seeing as many countries as possible. There are so many amazing places in Europe, it is a shame to not see them all. Additional Information: Europe is a very interesting place to visit for many reasons, not least of which is that there are so many different places to see. 微调后的模型现在可以推荐在欧洲访问的地方了。\nELI5 光合作用提示 prompt = template.format( instruction=\u0026quot;Explain the process of photosynthesis in a way that a child could understand.\u0026quot;, response=\u0026quot;\u0026quot;, ) print(gemma_lm.generate(prompt, max_length=256)) Instruction: Explain the process of photosynthesis in a way that a child could understand. Response: Photosynthesis is a process in which plants and photosynthetic organisms (such as algae, cyanobacteria, and some bacteria and archaea) use light energy to convert water and carbon dioxide into sugar and release oxygen. This process requires chlorophyll, water, carbon dioxide, and energy. The chlorophyll captures the light energy and uses it to power a reaction that converts the carbon from carbon dioxide into organic molecules (such as sugar) that can be used for energy. The process also generates oxygen as a by-product. 该模型现在用简单的术语解释了光合作用。\n请注意，出于演示目的，本教程仅在数据集的小子集上对模型进行了一次迭代（epoch）的微调，并且使用了较低的 LoRA 秩值。要从微调后的模型中获得更好的响应，您可以尝试：\n增加微调数据集的大小。 增加训练步骤（迭代次数）。 设置更高的 LoRA 秩。 修改超参数值，如学习率（learning_rate）和权重衰减（weight_decay）。 来源 本文翻译自 Fine-tune Gemma models in Keras using LoRA https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora\n低秩适应（LoRA）https://arxiv.org/abs/2106.09685\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDatabricks Dolly 15k数据集 https://www.kaggle.com/datasets/databricks/databricks-dolly-15k\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 设置 https://ai.google.dev/gemma/docs/setup\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nkaggle.com https://www.kaggle.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 模型卡片 https://www.kaggle.com/models/google/gemma\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n模型架构 https://keras.io/api/keras_nlp/models/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 7B 模型进行分布式调优 https://ai.google.dev/gemma/docs/distributed_tuning\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":3,"section":"posts","summary":"\u003cp\u003e大型语言模型（LLM）如 Gemma 已被证明在多种自然语言处理（NLP）任务上有效。LLM首先通过自监督方式在大量文本语料上进行预训练。预训练帮助 LLM 学习通用知识，例如单词之间的统计关系。然后，可以使用特定领域的数据对 LLM 进行微调，以执行下游任务（如情感分析）。\u003c/p\u003e\n\u003cp\u003eLLM 的大小极大（参数数量达到数百万）。对于大多数应用来说，不需要进行完全微调（更新模型中的所有参数），因为典型的微调数据集相对于预训练数据集要小得多。\u003c/p\u003e\n\u003cp\u003e低秩适应（LoRA）\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e是一种微调技术，通过冻结模型的权重并在模型中插入较少数量的新权重，大大减少了下游任务的可训练参数数量。这使得使用 LoRA 进行训练更快、更节省内存，并且生成的模型权重更小（几百MB），同时保持了模型输出的质量。\u003c/p\u003e\n\u003cp\u003e本教程将引导您使用 KerasNLP 对 Gemma 2B 模型进行 LoRA 微调，使用的是 Databricks Dolly 15k数据集\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e。该数据集包含15,000个高质量的人类生成的提示/响应对，专门用于微调 LLM。\u003c/p\u003e","tags":["gemma","kerasNLP"],"title":"在 Keras 中使用 LoRA 微调 Gemma 模型","uri":"https://www.ganymedenil.com/2024/03/30/Fine-tune-Gemma-model-in-Keras-using-LoRA.html","year":"2024"},{"content":"本教程将向您展示如何使用 KerasNLP1 开始使用 Gemma。Gemma 是一个轻量级的、采用最新技术的开放模型家族，这些技术源于创建 Gemini 模型的同一研究和技术。KerasNLP 是一个自然语言处理（NLP）模型的集合，这些模型使用 Keras2 实现，并能在 JAX、PyTorch 和 TensorFlow 上运行。\n在本教程中，您将使用 Gemma 生成对几个提示的文本响应。如果您对 Keras 不熟悉，可能会想在开始前阅读《 Keras 入门3》，但这不是必须的。通过本教程的学习，您将更加了解 Keras。\n设置 Gemma 设置 要完成本教程，您首先需要按照 Gemma 设置4的说明完成设置。Gemma 设置说明将向您展示如何进行以下操作：\nGemma 模型由 Kaggle 托管。要使用 Gemma，请在 Kaggle 上请求访问权限：\n在 kaggle.com5 登录或注册。 打开 Gemma 模型卡片6并选择“请求访问权限”。 完成同意表格并接受条款和条件。 安装依赖 安装 Keras 和 KerasNLP\n# 安装最新的 Keras 3。更多信息查看 https://keras.io/getting_started/。 !pip install -q -U keras-nlp !pip install -q -U keras\u0026gt;=3 导入包 导入 Keras 和 KerasNLP。\nimport keras import keras_nlp 选择一个后端 Keras 是一个高级的、多框架的深度学习API，设计上注重简单性和易用性。Keras 3 7允许您选择后端：TensorFlow、JAX或 PyTorch。这三个后端对于本教程都适用。\nimport os os.environ[\u0026quot;KERAS_BACKEND\u0026quot;] = \u0026quot;jax\u0026quot; # 或者 \u0026quot;tensorflow\u0026quot; 、 \u0026quot;torch\u0026quot;。 创建模型 KerasNLP 提供了许多流行模型架构8的实现。在本教程中，您将使用 GemmaCausalLM 创建一个模型，这是一个端到端的 Gemma 模型，用于因果语言建模。因果语言模型基于之前的 token 预测下一个 token。\n使用from_preset方法创建模型：\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\u0026quot;gemma_2b_en\u0026quot;) from_preset方法通过预设的架构和权重来实例化模型。在上述代码中，字符串\u0026quot;gemma_2b_en\u0026quot;指定了预设的架构：一个拥有20亿参数的 Gemma 模型。（也提供了一个有70亿参数的 Gemma 模型。要在 Colab上运行更大的模型，您需要访问付费计划中提供的高级GPU。或者，您也可以在Kaggle 或 Google Cloud 上进行 Gemma 7B 模型的分布式调优9。）\n使用summary方法可以获取更多关于模型的信息：\ngemma_lm.summary() Preprocessor: \u0026quot;gemma_causal_lm_preprocessor\u0026quot; Tokenizer (type) Vocab # gemma_tokenizer (GemmaTokenizer) 256,000 Model: \u0026quot;gemma_causal_lm\u0026quot; Layer (type) Output Shape Param # Connected to padding_mask (InputLayer) (None, None) 0 - token_ids (InputLayer) (None, None) 0 - gemma_backbone (GemmaBackbone) (None, None, 2048) 2,506,172,416 padding_mask[0][0], token_ids[0][0] token_embedding (ReversibleEmbedding) (None, None, 256000) 524,288,000 gemma_backbone[0][0] Total params: 2,506,172,416 (9.34 GB) Trainable params: 2,506,172,416 (9.34 GB) Non-trainable params: 0 (0.00 B) 从摘要中可以看到，该模型具有25亿可训练的参数。\n生成文本 现在是时候生成一些文本了！模型有一个generate方法，可以基于一个提示来生成文本。可选的max_length参数指定了生成序列的最大长度。\n尝试使用提示“What is the meaning of life?”来试一试。\ngemma_lm.generate(\u0026quot;What is the meaning of life?\u0026quot;, max_length=64) 'What is the meaning of life?\\n\\nThe question is one of the most important questions in the world.\\n\\nIt’s the question that has been asked by philosophers, theologians, and scientists for centuries.\\n\\nAnd it’s the question that has been asked by people who are looking for answers to their own lives' 调用generate方法时，可以尝试使用一个不同的提示。\ngemma_lm.generate(\u0026quot;How does the brain work?\u0026quot;, max_length=64) 'How does the brain work?\\n\\nThe brain is the most complex organ in the human body. It is responsible for controlling all of the body’s functions, including breathing, heart rate, digestion, and more. The brain is also responsible for thinking, feeling, and making decisions.\\n\\nThe brain is made up' 如果您使用的是 JAX 或 TensorFlow 后端，您会注意到第二次调用generate方法几乎立即返回结果。这是因为每次对给定批量大小和max_length的generate调用都会用XLA编译。第一次运行成本较高，但后续运行会快得多。\n您也可以使用列表作为输入来提供批量的提示：\ngemma_lm.generate( [\u0026quot;What is the meaning of life?\u0026quot;, \u0026quot;How does the brain work?\u0026quot;], max_length=64) ['What is the meaning of life?\\n\\nThe question is one of the most important questions in the world.\\n\\nIt’s the question that has been asked by philosophers, theologians, and scientists for centuries.\\n\\nAnd it’s the question that has been asked by people who are looking for answers to their own lives', 'How does the brain work?\\n\\nThe brain is the most complex organ in the human body. It is responsible for controlling all of the body’s functions, including breathing, heart rate, digestion, and more. The brain is also responsible for thinking, feeling, and making decisions.\\n\\nThe brain is made up'] 可选操作：尝试不同的采样器 您可以通过在compile()上设置sampler参数来控制 GemmaCausalLM 的生成策略。默认情况下，将使用“greedy”（贪婪）采样10。\n作为实验，尝试设置一个“top_k”11策略：\ngemma_lm.compile(sampler=\u0026quot;top_k\u0026quot;) gemma_lm.generate(\u0026quot;What is the meaning of life?\u0026quot;, max_length=64) 'What is the meaning of life? That is a question that has been asked for centuries and has yet to be answered. However, there are some people who believe they know the answer and they are willing to share it with the rest of us. In this essay, I will explore the meaning of life from their perspective' 虽然默认的贪婪算法总是选择概率最大的token，但top-K算法会从概率最高的K个token中随机挑选下一个token。\n您不必特别指定一个采样器，如果最后的代码片段对您的使用案例没有帮助，可以忽略它。如果您想了解更多可用的采样器，请参阅“采样器”12一节。\n来源 本文翻译自 Get started with Gemma using KerasNLP https://www.kaggle.com/code/nilaychauhan/get-started-with-gemma-using-kerasnlp/notebook\nKerasNLP https://keras.io/keras_nlp/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeras https://keras.io/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeras 入门 https://keras.io/getting_started/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 设置 https://ai.google.dev/gemma/docs/setup\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nkaggle.com https://www.kaggle.com/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 模型卡片 https://www.kaggle.com/models/google/gemma\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nKeras 3 https://keras.io/keras_3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n模型架构 https://keras.io/api/keras_nlp/models/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma 7B 模型的分布式调优 https://ai.google.dev/gemma/docs/distributed_tuning\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ngreedy 采样 https://keras.io/api/keras_nlp/samplers/greedy_sampler/#greedysampler-class\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntop_k 采样 https://keras.io/api/keras_nlp/samplers/top_k_sampler/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n采样器 https://keras.io/api/keras_nlp/samplers/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":4,"section":"posts","summary":"\u003cp\u003e本教程将向您展示如何使用 KerasNLP\u003csup id=\"fnref:1\"\u003e\u003ca href=\"#fn:1\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e1\u003c/a\u003e\u003c/sup\u003e  开始使用 Gemma。Gemma 是一个轻量级的、采用最新技术的开放模型家族，这些技术源于创建 Gemini 模型的同一研究和技术。KerasNLP 是一个自然语言处理（NLP）模型的集合，这些模型使用 Keras\u003csup id=\"fnref:2\"\u003e\u003ca href=\"#fn:2\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e2\u003c/a\u003e\u003c/sup\u003e 实现，并能在 JAX、PyTorch 和 TensorFlow 上运行。\u003c/p\u003e\n\u003cp\u003e在本教程中，您将使用 Gemma 生成对几个提示的文本响应。如果您对 Keras 不熟悉，可能会想在开始前阅读《 Keras 入门\u003csup id=\"fnref:3\"\u003e\u003ca href=\"#fn:3\" class=\"footnote-ref\" role=\"doc-noteref\"\u003e3\u003c/a\u003e\u003c/sup\u003e》，但这不是必须的。通过本教程的学习，您将更加了解 Keras。\u003c/p\u003e","tags":["gemma","kerasNLP"],"title":"使用 KerasNLP 快速开始 Gemma","uri":"https://www.ganymedenil.com/2024/03/30/Get-started-with-Gemma-using-KerasNLP.html","year":"2024"},{"content":"本文我将使用 Google 的 Gemma-2b 模型来微调一个基于IT科技新闻正文来生成对应标题的模型。并且我将介绍如何使用高度集成的训练框架来进行快速微调。\n开始前 为了尽可能简化整个流程，我将使用 linux-cn 数据集1作为本次训练任务的训练数据。\n模型选择使用 Gemma-2b2，在目前这个任务中 2b 级别的参数模型已经完全能满足当前的需求，当然你也可以尝试使用 7b 的模型。\n我们在这里将直接使用 LLaMA-Factory3 训练框架来直接完成监督微调部分工作。当然该框架不仅支持监督微调（SFT）也支持预训练（PT）、奖励模型（RM）以及 PPO/DPO 的训练。\n数据整理 linux-cn 数据集本身已经进行了数据的清洗和格式化，这一步我们只需要把我们需要的字段提取出后来后根据一定格式转换为 LLaMA-Factory 监督微调格式即可。\n在本任务中，我们只需要数据集中的“title”和“content”两个字段即可。而 LLaMA-Factory 监督微调格式是如下格式的json文件。\n[ { \u0026quot;instruction\u0026quot;: \u0026quot;What are the three primary colors?\u0026quot;, \u0026quot;input\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;output\u0026quot;: \u0026quot;The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).\u0026quot;, }, ... ] 因为我们选择使用的是预训练模型，所以我们还需要指定一个 prompt template。指定 prompt template 的一个好处是你如果希望同时训练多个不同类型的任务，这样可以保证不同任务之间不会相互干扰。\n完整代码如下：\nimport json result = [] prompt_template = \u0026quot;\u0026quot;\u0026quot;Generate a title for the article: {content} --- Title: \u0026quot;\u0026quot;\u0026quot; with open('archve.jsonl', 'r') as f: for line in f: p = json.loads(line) result.append({ \u0026quot;instruction\u0026quot;: prompt_template.replace(\u0026quot;{content}\u0026quot;, p['content']), \u0026quot;input\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;output\u0026quot;: p['title'] }) with open('itnews_data.json', 'w') as f: json.dump(result, f,ensure_ascii=False, indent=4) 完成这一步后，我们就可以开始训练我们的模型了。但往往耗费时间最长以及最头疼的也是数据收集和数据整理这一部分。\n模型微调 首先你需要保证 LLaMA-Factory 框架已经在你本地已经 ready 了。即你已经下载了该项目并且已经进行了项目的安装。\n具体如何安装你可以查看该项目的 README，本文不再过多赘述。\n首先我们需要将数据集移动到框架的 data 目录中，然后在 dataset_info.json 中添加我们自定义的数据集。\n以下是本文实例所添加的数据集信息：\n\u0026quot;itnews\u0026quot;: { \u0026quot;file_name\u0026quot;: \u0026quot;itnews_data.json\u0026quot;, }, 当然不同类型的任务该框架会有不同的数据集格式要求，你可以参考项目中 dataset_info.json 的README 4。\n然后我们只需要执行如下命令就可以开始微调了,本文是在单张A100（80G）上进行的微调。\nCUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\ --stage sft \\ --do_train True \\ --model_name_or_path google/gemma-2b \\ --finetuning_type lora \\ --template default \\ --dataset itnews \\ --use_unsloth \\ --cutoff_len 8192 \\ --learning_rate 5e-05 \\ --num_train_epochs 10.0 \\ --max_samples 10000 \\ --per_device_train_batch_size 4 \\ --per_device_eval_batch_size 4 \\ --gradient_accumulation_steps 4 \\ --lr_scheduler_type cosine \\ --max_grad_norm 1.0 \\ --logging_steps 10 \\ --save_steps 100 \\ --eval_steps 100 \\ --evaluation_strategy steps \\ --warmup_steps 0 \\ --output_dir saves/Gemma-2B/lora/train_v1 \\ --bf16 True \\ --lora_rank 8 \\ --lora_dropout 0.1 \\ --lora_target q_proj,v_proj \\ --val_size 0.1 \\ --load_best_model_at_end True \\ --plot_loss True \\ --report_to \u0026quot;tensorboard\u0026quot; 在这里我需要对其中的几个参数进行简短的介绍：\n--stage 即任务类型，在这里我们本文做的是监督微调所以是 sft，如果是其他任务你需要指定不同的类型。\n--dataset 即数据集，这里的名称就是我们在 dataset_info.json 文件中指定的数据集名称。\n--use_unsloth 这是一个训练加速器，官方宣称在 Gemma 7b 上拥有 2.4x 的加速，并且节省超一半的显存。在使用这个之前你需要按照官方文档进行安装5。\n--cutoff_len 文本令牌化后输入到模型的截止长度，因为本文使用的 Gemma 2b 模型，它的最大长度是 8192 ，所以在这里我设置的是 8192。但请记住更长的上下文也需要更多的 GPU 显存！\n--max_samples 设置数据集加载的最大条数。本参数主要用作调试目的时非常好用，尤其是在你不确定 cutoff_len 和 batch_size的时候，你可以加载很小的一部分数据进行测试，然后查看你显存的使用情况。\n--learning_rate --num_train_epochs 学习率和训练周期，这是一个经验值，一般通过查看模型的 loss 来调整，当然在 LLM 模型训练中，本参数主要以模型是否符合任务需求而决定，也就是说完美的 loss 可能并不满足需求。\n--per_device_train_batch_size --per_device_eval_batch_size --gradient_accumulation_steps 这三个参数需要根据你的显存大小以及是否使用多个GPU等条件进行不同的调整。\n--output_dir 模型保存的目录。\n更多的参数解释可以查看项目说明6，以及 transformers Trainer 的说明7。\n模型使用 在这里我们可以直接使用 transformers 来执行。\nfrom transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig peft_model_id = \u0026quot;checkpoint-2000\u0026quot; model = AutoModelForCausalLM.from_pretrained(peft_model_id,device_map=\u0026quot;cuda\u0026quot;) tokenizer = AutoTokenizer.from_pretrained(\u0026quot;google/gemma-2b\u0026quot;) input_text = \u0026quot;\u0026quot;\u0026quot; Generate a title for the article: {content} --- Title: \u0026quot;\u0026quot;\u0026quot; # 固定格式 encoding = tokenizer(input_text, return_tensors=\u0026quot;pt\u0026quot;).to(\u0026quot;cuda\u0026quot;) outputs = model.generate(**encoding,max_length=8192,temperature=0.2,do_sample=True) generated_ids = outputs[:, encoding.input_ids.shape[1]:] generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True) print(generated_texts[0]) 我通过使用我自己的一篇差不多 5000 tokens 关于微服务的文章进行测试，并且这篇文章没有出现在数据集中8。\n在使用相同 prompt 的情况下的输出：\ngemma-2b-it\n\u0026gt; 微服务架构 概述 微服务架构的定义 微服务架构的定义 微服务架构的定义 微服务架构的定义 微服务架构的定义 微服务架构的定义 ... lora\n\u0026gt; 微服务架构的优势 通过简单的测试，不难发现模型在微调后，其返回格式上更加稳定，并且更加符合我们的要求。\n总结 如果你不想训练，但又希望尝试本文中的模型，你可以在 huggingface 上搜索 gemma-2b-technology-news-title-generation-lora，找到从100-2200 steps 的所有 checkpoint 9。\n本文使用了一种相对简单的方式来训练符合自己需求的模型。在真实的企业场景中往往还涉及如何生成符合需求的数据集，集群训练，模型的AB测试，企业级部署等问题。我会在未来的文章中和大家分享。\nLinux-cn 数据集 https://huggingface.co/datasets/linux-cn/archive\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nGemma-2b 模型 huggingface: https://huggingface.co/google/gemma-2b | kaggle: https://www.kaggle.com/models/google/gemma\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLLaMA-Factory https://github.com/hiyouga/LLaMA-Factory\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ndataset_info 说明 https://github.com/hiyouga/LLaMA-Factory/tree/main/data\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nunsloth https://github.com/unslothai/unsloth\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ndata args https://github.com/hiyouga/LLaMA-Factory/blob/main/src/llmtuner/hparams/data_args.py\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntransformers Trainer https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n我的微服务总结 https://ganymedenil.com/2022/04/22/what-are-microservices.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntechnology news title generation lora https://huggingface.co/GanymedeNil/gemma-2b-technology-news-title-generation-lora\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":5,"section":"posts","summary":"\u003cp\u003e本文我将使用 Google 的 Gemma-2b 模型来微调一个基于IT科技新闻正文来生成对应标题的模型。并且我将介绍如何使用高度集成的训练框架来进行快速微调。\u003c/p\u003e","tags":["gemma","LLM"],"title":"Google Gemma 2B 微调实战（IT科技新闻标题生成）","uri":"https://www.ganymedenil.com/2024/03/24/Google-Gemma-2B-fine-tuning-practice-IT-technology-news-headline-generation.html","year":"2024"},{"content":"我本身是一个不太写总结类内容的人，但这次跟风写一回，总结我这一年AI相关的技术总结和我整体的思考。\n时间线 我跃跃欲试要进AI的坑要追溯到22年底，OpenAI 推出 GPT-3.5 的时候，当时其实并不太了解 OpenAI 这家公司，当时还是听完《vol.440 科技乱炖：ChatGPT 的惊喜与意料之内》这期播客的时候让我感觉，2023年可以搞搞AI。\n2023年2月中旬，我开始在推特和即刻上分享我对大预言模型的见解。\n2023年3月初，我开始尝试使用 GPT-3.5 接口做一些事情，刚好当时我在研究《默沙东诊疗手册》，就想能不能做一个通过描述症状然后匹配相关病症的demo。做完我就发推上了，竟然意外的火了。但当时考虑到 OpenAI 本身对于医疗问诊场景的约束以及可能带来的潜在风险，我就把服务关停了。但因为那条推火了，也陆续有人问我是如何实现的。考虑再三，再不牵扯各种已知风险（版权、医疗风险等），作为还算有点开源精神的程序员，我就把这个简单的demo，做成了一个开源的解决方案——《基于向量数据库与GPT3.5的通用本地知识库方案》。后续也跟新了一些常见问题的解。\n当时想着能不能搞一个本地的 Embedding 模型，毕竟如果要做一个可用的知识库需要将大量的文本转为向量，如果用 OpenAI 的接口虽然效果很好，但还是很贵。然后想着找个本地模型，效果能差不多就可以。找了一圈之后发现中文场景下开源的模型并没有多少，而且效果也一般。作为一个在公司搞过几年基础架构的人来说，没有好用的轮子那就造一个。然后就开始着手微调第一个模型，当时完全小白，但还好有很多开源项目，救我一命。当时为了做对比实验，其实训练了好几个模型用来做对比测试，但最后还是 text2vec-large-chinese 这个效果相对较好（当时真实感受到了摄影圈常说的“底大一级压死人”，完全可以把这句话套用在AI模型上）。后来因为知识库项目的 star 上来后这个模型在 huggingface 的句子相似度任务中一度排在前三（写本文的时候我又去看了一下还在前十）。\n2023年3月中旬，我自己有一个需求就是想能方便的对长音频进行降噪。当时使用了 adobe 出的免费服务 Enhance，效果虽好但是对于长音频往往会直接不响应。我这造轮子的热情一下子又上来了，然后就有了基于深度学习的语音增强工具，一开始找了个需要GPU的模型，效果很好但无奈我很穷，买不起GPU。然后又将 github 翻了个底朝天找到了个不需要 GPU 的模型，效果也还不错，处理速度也还可以。然后就封装了一下，满足了我自己的需求，独乐乐不如众乐乐，再次选择了开源。\n2023年3月底开始，因为项目的影响力，陆续有一些企业和个人开始找我聊基于 LLM 的应用场景。聊了很多当时发现一个问题就是，大量的初创公司也好个人也好，做的项目都没有一个主体去支撑。要不就做 GPT 套壳，要不就是单纯做基于OpenAI的知识库内容的问答（对B端或者C端）。当时我给他们举的B端的例子是zendesk（因为我在公司负责过2年多的CRM系统，对这家公司的工单和QA系统印象比较深刻），对于它而言集成 LLM 是迟早的事，并且它本身拥有大量的企业客户，也有大量的文本化内容的积累。而作为一个新起的项目，很难去跟这类公司去竞争相似的市场，而且如果都是套壳 OpenAI 大家本质功能也不会拉开太大的差距。第二个例子是针对C端，当时就有传言微软要在操作系统层级集成大模型能力，那么针对个人市场的文档问答服务也就可能会形成冲击。个人市场针对LLM能力的付费意愿我个人的观察属于“我能白嫖干什么还要付费”。\n2023年4月初，和《津津乐道》播客一拍既合尝试通过OpenAI 本身对于语言的理解能力，将281个节目字幕提取为QA数据集（JinJinLeDao QA Dataset）。也算是对大语言模型的另一种使用方式的探索。\n2023年4月底开始折腾ASR（语音转文本）任务，并且希望真正落地一个基于本地AI模型的企业级解决方案。虽然都是用Whisper，但如何提升质量和转译速度变成了一个难题。接下来几个月的状态就是看论文，看开源项目的优化实现以及进行大量的测试和调整。最后找了一个相对合适的 pipline 就是串联或并联多个模型，并且使用鉴别模型进行判断是否需要进行相应的处理。但因为整个服务流里面有大量的模型，并且有些模型体积又特别大，导致部署难度上升，但还好组内有大佬暂且解决了，折腾了这几个月下来服务整体还算稳定。\n期间还去津津乐道播客聊了聊 OpenAI 的发布会《编码人声：几千块钱换来的 OpenAI 新功能体验报告》。强烈推介大家去订阅津津乐道播客宇宙的相关节目！\n最近这两个月开始折腾支持语音克隆的TTS本地化解决方案，目前看整体还可以，但如何能进行“无人值守”级别的长文本TTS生成，还需要进一步探索和解决，期望年前能解决吧。\n写在最后 我其实还是很愿意花钱投资自己，尤其是知识上的，今年AI上的投入比我以前在任何其他技术上投资都要大的多（我都不敢看我的余额\u0026hellip;）。租线上GPU训练模型，买相关书籍和课程，尝试各种AI相关付费服务，以及为了方便调试攒了一个本地开发机。今年也要感谢朋友们的赞助和付费咨询，帮我抹掉了部分的成本。但从今年一年来看个人搞 AI 局限性还是太大，有很多想尝试的因为要投入比较多的成本而无法进行。明年可能找个搞 AIGC 的公司搞点正事？也未可知。\n","id":6,"section":"posts","summary":"\u003cp\u003e我本身是一个不太写总结类内容的人，但这次跟风写一回，总结我这一年AI相关的技术总结和我整体的思考。\u003c/p\u003e","tags":["总结"],"title":"2023年终终结","uri":"https://www.ganymedenil.com/2023/12/25/2023-summary.html","year":"2023"},{"content":"我将以阿里云竞价实例来配置使用 GPU 的 Docker 环境，希望这个例子能对你有所帮助。\n准备工作 首先你需要准备一台拥有GPU的实例，在这里我将使用阿里云的竞价实例来做演示，因为它对于短期使用GPU更加划算。\n注意，本篇文章将教你手动进行GPU驱动的配置，所以在购买时选择系统的时候不要选择自动安装GPU驱动。\n具体关于竞价实例如何购买和配置，请参考各个云平台的介绍，本文不再赘述。\n主机配置 在这里我买了一台配有Ubuntu 22.04和一块T4显卡的实例作为演示。\n显卡驱动安装 现在我们需要安装 NVIDIA 的驱动，在这里下载驱动。 选择你的显卡和CUDA Toolkit版本，以及你的系统版本，就能得到相应的驱动下载。 在这个案例中我的显卡选择的是 Tesla T4 ，系统选择 Linux64-bit，CUDA Toolkit 选择 12.0。 点击搜索后就能得到对应的驱动，点击下载后就得到了对应的驱动。 把驱动文件上传到你的实例上，并用以下命令进行安装： $chmod 755 NVIDIA-Linux-x86_64-525.85.12.run $sudo ./NVIDIA-Linux-x86_64-525.85.12.run --no-cc-version-check 脚本中的版本号可能会随有所变化，请以你下载的驱动为准。\n安装完后执行 nvidia-smi 命令显示如下就是安装完成了：\nFri Mar 3 15:17:34 2023 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 525.85.12 Driver Version: 525.85.12 CUDA Version: 12.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla T4 Off | 00000000:00:07.0 Off | 0 | | N/A 57C P0 30W / 70W | 2MiB / 15360MiB | 7% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ Docker 安装 可以使用 Docker 的官方脚本在 Ubuntu 上设置 Docker-CE：\ncurl https://get.docker.com | sh \\ \u0026amp;\u0026amp; sudo systemctl --now enable docker 请按照官方说明了解更多详细信息和安装后操作。\n安装 NVIDIA Container Toolkit 在线安装 设置软件包仓库和GPG密钥\n$ distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\ \u0026amp;\u0026amp; curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ \u0026amp;\u0026amp; curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\ sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list 在更新软件包列表之后，安装 nvidia-container-toolkit 包（以及依赖项）。\n$ sudo apt-get update $ sudo apt-get install -y nvidia-container-toolkit 离线安装 离线安装包都在以下仓库和分支下： https://github.com/NVIDIA/libnvidia-container/tree/gh-pages\n以 ubuntu22.04为例，点开对应的目录，如果显示的是 Symbolic Link，则表示是个软链，例如我这点开后是 stable/ubuntu22.04，则代表软链到这个目录，进行跳转后发现还是一个 Symbolic Link ，里面是 ubuntu18.04，继续跳转，现在出现了系统的选择，这里我选择 amd64，进去后的目录里就是对应的安装包了。\n在这里我们需要选择如下的安装包：\nnvidia-container-toolkit-base_xxxx-1_amd64 nvidia-container-toolkit_1.xxxx-1_amd64 libnvidia-container1_1.xxxx-1_amd64 libnvidia-container-tools_1.xxxx-1_amd64 xxxx代表对应的 CUDA 版本，在我的这个实例中 xxxx，就是12.0，按以下顺序安装：\ndpkg -i libnvidia-container1_1.12.0-1_amd64.deb dpkg -i libnvidia-container-tools_1.12.0-1_amd64.deb dpkg -i nvidia-container-toolkit-base_1.12.0-1_amd64.deb dpkg -i nvidia-container-toolkit_1.12.0-1_amd64.deb 配置Docker守护程序，使其能够识别NVIDIA Container Runtime：\n$ sudo nvidia-ctk runtime configure --runtime=docker 在设置默认 runtime 后，重新启动Docker守护程序以完成安装。\n$ sudo systemctl restart docker 测试 最后，通过运行一个基本的CUDA容器来测试是否配置完成：\n$ sudo docker run --rm --runtime=nvidia --gpus all nvidia/cuda:12.0.1-runtime-ubuntu22.04 nvidia-smi 输出如下所示就代表你的容器以及支持GPU：\nFri Mar 3 07:47:04 2023 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 525.85.12 Driver Version: 525.85.12 CUDA Version: 12.0 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Tesla T4 Off | 00000000:00:07.0 Off | 0 | | N/A 37C P0 27W / 70W | 2MiB / 15360MiB | 7% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ ","id":7,"section":"posts","summary":"\u003cp\u003e我将以阿里云竞价实例来配置使用 GPU 的 Docker 环境，希望这个例子能对你有所帮助。\u003c/p\u003e","tags":["docker"],"title":"配置 Docker 使用 GPU","uri":"https://www.ganymedenil.com/2023/03/03/configuring-docker-to-use-gpus.html","year":"2023"},{"content":"Nuxt 3在引入 wavesurfer.js 时会出现很多问题，这篇文章将完整介绍如何正确引用 wavesurfer.js。\n安装 wavesurfer.js 在项目中安装 wavesurfer.js\nnpm install --save wavesurfer.js 常规方式引入 如果你的根目录中没有 components 目录则需要创建该目录，并在此目录中创建 WaveSurfer.vue 内容如下：\n\u0026lt;template\u0026gt; \u0026lt;div ref=\u0026quot;wavesurferMain\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; import WaveSurfer from 'wavesurfer.js' const props = defineProps({ src:{ type:String, required:true }, options:{ type:Object, } }); const wavesurferMain = ref(null); const waveSurfer = ref(null); let options = props.options; let wsOptions = Object.assign({ container: wavesurferMain.value }, options); waveSurfer.value = new WaveSurfer.create(wsOptions); waveSurfer.value.load(props.src); \u0026lt;/script\u0026gt; 然后我们集成该组件，在这个例子中我们将在 app.vue 直接引用，并且我将测试音频文件 demo.wav，放在根目录的public 中。\n\u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;WaveSurfer src=\u0026quot;/demo.wav\u0026quot;:options=\u0026quot;waveSurferOption\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; const waveSurferOption = { height: 340, progressColor: '#e03639', waveColor: '#e7e7e7', cursorColor: '#FFDDDD', barWidth: 2, mediaControls: true, backend: 'MediaElement', scrollParent:true, xhr: { mode: 'no-cors' } }; \u0026lt;/script\u0026gt; 现在执行 npm run dev ，页面将报错 self is not defined。 这是因为在 setup 这个生命周期中，DOM 节点并未创建，所以我们需要在mounted 阶段进行导入。\n正确的引入方式 更改 WaveSurfer.vue 文件内容如下：\n\u0026lt;template\u0026gt; \u0026lt;div ref=\u0026quot;wavesurferMain\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; const props = defineProps({ src:{ type:String, required:true }, options:{ type:Object, } }); const wavesurferMain = ref(null); const waveSurfer = ref(null); onMounted(async ()=\u0026gt;{ const WaveSurfer = (await import('wavesurfer.js')).default; const options = props.options; const wsOptions = Object.assign({ container: wavesurferMain.value }, options); waveSurfer.value = new WaveSurfer.create(wsOptions); waveSurfer.value.load(props.src); }); \u0026lt;/script\u0026gt; 现在你应该能看到已经可以正常加载了。\n加载插件 加载方式和插件一样，官方的插件在 wavesurfer.js/dist/plugin 目录下，这个例子将加载时间线插件如下：\n\u0026lt;template\u0026gt; \u0026lt;div ref=\u0026quot;wavesurferMain\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div ref=\u0026quot;waveTimeline\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; const props = defineProps({ src:{ type:String, required:true }, options:{ type:Object, } }); const wavesurferMain = ref(null); const waveTimeline = ref(null); const waveSurfer = ref(null); onMounted(async ()=\u0026gt;{ const WaveSurfer = (await import('wavesurfer.js')).default; const Timeline = (await import('wavesurfer.js/dist/plugin/wavesurfer.timeline')).default; const options = props.options; const wsOptions = Object.assign({ container: wavesurferMain.value, plugins:[ Timeline.create({container:waveTimeline.value}) ] }, options); waveSurfer.value = new WaveSurfer.create(wsOptions); waveSurfer.value.load(props.src); }); \u0026lt;/script\u0026gt; 加载波形数据 如果音频文件过大，使用插件原生的波形生成方式会非常慢。这个时候可以通过服务端生成波形数据，并让插件直接通过波形数据进行渲染。具体生成方式可以参考官方的解决方案FAQ。在这个项目中，生成波形数据文件后，我把它移动到项目的public中，更改 WaveSurfer.vue 内容如下：\n\u0026lt;template\u0026gt; \u0026lt;div ref=\u0026quot;wavesurferMain\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div ref=\u0026quot;waveTimeline\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; const props = defineProps({ src:{ type:String, required:true }, peaksData:{ type:String, }, options:{ type:Object, } }); const wavesurferMain = ref(null); const waveTimeline = ref(null); const waveSurfer = ref(null); onMounted(async ()=\u0026gt;{ const WaveSurfer = (await import('wavesurfer.js')).default; const Timeline = (await import('wavesurfer.js/dist/plugin/wavesurfer.timeline')).default; const options = props.options; const wsOptions = Object.assign({ container: wavesurferMain.value, plugins:[ Timeline.create({container:waveTimeline.value}) ] }, options); waveSurfer.value = new WaveSurfer.create(wsOptions); fetch(props.peaksData) .then(response =\u0026gt; { if (!response.ok) { throw new Error(\u0026quot;HTTP error \u0026quot; + response.status); } return response.json(); }) .then(peaks =\u0026gt; { waveSurfer.value.load(props.src,peaks.data); }) .catch((e) =\u0026gt; { console.error('error', e); }); }); \u0026lt;/script\u0026gt; 在 app.vue 中变更如下：\n\u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;WaveSurfer src=\u0026quot;/demo.wav\u0026quot; peaks-data=\u0026quot;/demo.json\u0026quot; :options=\u0026quot;waveSurferOption\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; const waveSurferOption = { height: 340, progressColor: '#e03639', waveColor: '#e7e7e7', cursorColor: '#FFDDDD', barWidth: 2, mediaControls: false, backend: 'MediaElement', scrollParent:true, xhr: { mode: 'no-cors' } } \u0026lt;/script\u0026gt; 暴露插件的方法 现在我们只是正常初始化插件并让它加载了音频文件，目前我们并不能操作它。 因为 Vue3 中，默认并不会暴露 \u0026lt;script setup\u0026gt; 中声明的绑定。我们需要使用 defineExpose 来暴露对应的属性。WaveSurfer.vue 如下变更：\n\u0026lt;template\u0026gt; \u0026lt;div ref=\u0026quot;wavesurferMain\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div ref=\u0026quot;waveTimeline\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; const props = defineProps({ src:{ type:String, required:true }, peaksData:{ type:String, }, options:{ type:Object, } }); const wavesurferMain = ref(null); const waveTimeline = ref(null); const waveSurfer = ref(null); onMounted(async ()=\u0026gt;{ // 省略逻辑 }); defineExpose( { waveSurfer } ) \u0026lt;/script\u0026gt; 在 app.vue 中我们可以这样调用：\n\u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;WaveSurfer ref=\u0026quot;refWaveSurfer\u0026quot; src=\u0026quot;/demo.wav\u0026quot; peaks-data=\u0026quot;/demo.json\u0026quot; :options=\u0026quot;waveSurferOption\u0026quot;/\u0026gt; \u0026lt;button @click=\u0026quot;play\u0026quot;\u0026gt;play\u0026lt;/button\u0026gt; \u0026lt;button @click=\u0026quot;pause\u0026quot;\u0026gt;pause\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; const waveSurferOption = { height: 340, progressColor: '#e03639', waveColor: '#e7e7e7', cursorColor: '#FFDDDD', barWidth: 2, mediaControls: false, backend: 'MediaElement', scrollParent:true, xhr: { mode: 'no-cors' } } const refWaveSurfer = ref(null); function play() { refWaveSurfer.value.waveSurfer.play(); // 调用播放方法 } function pause(){ refWaveSurfer.value.waveSurfer.pause(); // 调用暂停方法 } \u0026lt;/script\u0026gt; 项目 你可以在以下仓库看到完整的示例 https://github.com/AnyStudy/nuxt-3-wavesurfer-demo\n","id":8,"section":"posts","summary":"\u003cp\u003eNuxt 3在引入 wavesurfer.js 时会出现很多问题，这篇文章将完整介绍如何正确引用 wavesurfer.js。\u003c/p\u003e","tags":["nuxt"],"title":"如何在 Nuxt 3 中使用 wavesurfer.js","uri":"https://www.ganymedenil.com/2023/01/13/how-to-use-wavesurferjs-in-nuxt3.html","year":"2023"},{"content":"Go是一种非常受欢迎的编程语言，它具有内置的并发支持和众多其他优秀的特性。在众多现代语言中，Go在基本语言设计方面格外出众。\n首先，Go是一种非常简洁的语言，它的简洁性使其与像Lua这样的简单语言相似。Go设计时十分注重简洁主义 \u0026hellip;\n前言 Go是一种非常受欢迎的编程语言，它具有内置的并发支持和众多其他优秀的特性。在众多现代语言中，Go在基本语言设计方面格外出众。\n首先，Go是一种非常简洁的语言，它的简洁性使其与像Lua这样的简单语言相似。Go设计时十分注重简洁主义。\n其次，Go非常重视语言的稳定性，与许多其他语言形成了鲜明的对比。Go更像C语言，自从40多年前创建以来几乎没有任何改变。\n最近Go 1.18中引入的泛型是一个例外，但这显然是必要的改变。\n第三，在标准库方面，Go是一种\u0026quot;综合性\u0026quot;编程语言，它提供了开发专业软件所需的所有功能，而无需过多依赖外部库。\n本书是Go编程语言的\u0026quot;迷你\u0026quot;语言参考手册，它概述了现代Go编程语言（1.18和1.19）的所有基本功能。虽然它是作为参考手册而写的，但你几乎可以从头到尾阅读它，并且应该能够了解Go语言的整体概念（但不一定是所有的细节）。\n值得注意的是，与教程风格的书籍不同，本书有大量交叉引用，如果您之前没有使用Go编程的经验，可能会发现很难阅读本书的某些部分。\n本书也是我在2022年自由职业期间翻译的一本书，借此机会巩固自己对Go的相关知识。\n阅读地址 写给大忙人看的Go语言快速指南\n","id":9,"section":"posts","summary":"\u003cp\u003eGo是一种非常受欢迎的编程语言，它具有内置的并发支持和众多其他优秀的特性。在众多现代语言中，Go在基本语言设计方面格外出众。\u003c/p\u003e\n\u003cp\u003e首先，Go是一种非常简洁的语言，它的简洁性使其与像Lua这样的简单语言相似。Go设计时十分注重简洁主义 \u0026hellip;\u003c/p\u003e","tags":["go"],"title":"写给大忙人看的Go语言快速指南（中文翻译）","uri":"https://www.ganymedenil.com/2023/01/04/a-quick-guide-to-the-go-programming-language-for-busy-coders.html","year":"2023"},{"content":"slog 是 Go 团队开发的一个实验性日志包，它提供了结构化日志记录的功能。 注意：当前该包还未在Go基础库中包含。\n安装 创建新的 Go 项目或者使用现有的项目通过以下命令进行安装。\ngo get golang.org/x/exp/slog 使用 package main import \u0026quot;golang.org/x/exp/slog\u0026quot; func main() { slog.Info(\u0026quot;Go is best language!\u0026quot;) } 输出：\n$ go run main.go 2022/12/21 11:16:00 INFO Go is best language! 默认情况下，输出包括时间、日志级别和消息。\n以下是可用的日志级别。\nDebug Info Warn Error 结构化日志记录 slog 是一个结构化日志记录工具，支持两种记录格式：text 和 json。\nText Handler 首先创建一个 text handler 和 一个 new logger。\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { textHandler := slog.NewTextHandler(os.Stdout) logger := slog.New(textHandler) logger.Info(\u0026quot;Go is the best language!\u0026quot;) } 输出：\n$ go run main.go time=2022-12-21T11:20:52.919+08:00 level=INFO msg=\u0026quot;Go is the best language!\u0026quot; 我们可以看出日志是以键值对的形式输出。这通常称为 logfmt 格式。\n许多日志分析工具都可以处理logfmt格式的日志。Logfmt 也是人类可读的一种日志格式。\nJSON Handler 你还可以输出 JSON 格式的日志。\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { jsonHandler := slog.NewJSONHandler(os.Stdout) // 👈 logger := slog.New(jsonHandler) logger.Info(\u0026quot;Go is the best language!\u0026quot;) } 输出：\n$ go run main.go {\u0026quot;time\u0026quot;:\u0026quot;2022-12-21T11:26:08.355317+08:00\u0026quot;,\u0026quot;level\u0026quot;:\u0026quot;INFO\u0026quot;,\u0026quot;msg\u0026quot;:\u0026quot;Go is the best language!\u0026quot;} 每个日志都记录为一个 json 对象，其中包含属性。\n属性 slog 是一个结构化的记录器，提供了指定属性的能力。\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { textHandler := slog.NewTextHandler(os.Stdout) logger := slog.New(textHandler) logger.Info(\u0026quot;Usage Statistics\u0026quot;, slog.Int(\u0026quot;current-memory\u0026quot;, 50)) } 输出：\n$ go run main.go time=2022-12-21T11:28:27.209+08:00 level=INFO msg=\u0026quot;Usage Statistics\u0026quot; current-memory=50 在上面的示例中，使用 . 添加了一个整数属性slog.Int。\n以下是各类支持的属性：\nString Int64 Int Uint64 Float64 Bool Time Duration 你可以根据需要添加任意数量的属性。\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { textHandler := slog.NewTextHandler(os.Stdout) logger := slog.New(textHandler) logger.Info(\u0026quot;Usage Statistics\u0026quot;, slog.Int(\u0026quot;current-memory\u0026quot;, 50), slog.Int(\u0026quot;min-memory\u0026quot;, 20), slog.Int(\u0026quot;max-memory\u0026quot;, 80), slog.Int(\u0026quot;cpu\u0026quot;, 10), slog.String(\u0026quot;app-version\u0026quot;, \u0026quot;v0.0.1-beta\u0026quot;), ) } 输出：\n$ go run main.go time=2022-12-21T11:31:12.469+08:00 level=INFO msg=\u0026quot;Usage Statistics\u0026quot; current-memory=50 min-memory=20 max-memory=80 cpu=10 app-version=v0.0.1-beta 分组属性 你可以将属性分组在一个键下。例如，所有内存属性都可以分组在 memory 键下。\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { textHandler := slog.NewTextHandler(os.Stdout) logger := slog.New(textHandler) logger.Info(\u0026quot;Usage Statistics\u0026quot;, slog.Group(\u0026quot;memory\u0026quot;, slog.Int(\u0026quot;current\u0026quot;, 50), slog.Int(\u0026quot;min\u0026quot;, 20), slog.Int(\u0026quot;max\u0026quot;, 80)), slog.Int(\u0026quot;cpu\u0026quot;, 10), slog.String(\u0026quot;app-version\u0026quot;, \u0026quot;v0.0.1-beta\u0026quot;), ) } 输出：\n$ go run main.go time=2022-12-21T11:33:38.016+08:00 level=INFO msg=\u0026quot;Usage Statistics\u0026quot; memory.current=50 memory.min=20 memory.max=80 cpu=10 app-version=v0.0.1-beta 使用 JsonHandler 输出将如下所示。\n$ go run main.go | jq { \u0026quot;time\u0026quot;: \u0026quot;2022-12-21T11:35:24.648829+08:00\u0026quot;, \u0026quot;level\u0026quot;: \u0026quot;INFO\u0026quot;, \u0026quot;msg\u0026quot;: \u0026quot;Usage Statistics\u0026quot;, \u0026quot;memory\u0026quot;: { \u0026quot;current\u0026quot;: 50, \u0026quot;min\u0026quot;: 20, \u0026quot;max\u0026quot;: 80 }, \u0026quot;cpu\u0026quot;: 10, \u0026quot;app-version\u0026quot;: \u0026quot;v0.0.1-beta\u0026quot; } 公共属性 假设你希望拥有一个应包含在所有正在生成的日志中的属性，此类属性的示例包括服务名称、应用程序版本。\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { textHandler := slog.NewTextHandler(os.Stdout). WithAttrs([]slog.Attr{slog.String(\u0026quot;app-version\u0026quot;, \u0026quot;v0.0.1-beta\u0026quot;)}) // 👈 为所有日志添加属性 logger := slog.New(textHandler) logger.Info(\u0026quot;Generating statistics\u0026quot;) logger.Info(\u0026quot;Usage Statistics\u0026quot;, slog.Group(\u0026quot;memory\u0026quot;, slog.Int(\u0026quot;current\u0026quot;, 50), slog.Int(\u0026quot;min\u0026quot;, 20), slog.Int(\u0026quot;max\u0026quot;, 80)), slog.Int(\u0026quot;cpu\u0026quot;, 10), ) } 输出：\n$ go run main.go time=2022-12-21T11:37:26.363+08:00 level=INFO msg=\u0026quot;Generating statistics\u0026quot; app-version=v0.0.1-beta time=2022-12-21T11:37:26.363+08:00 level=INFO msg=\u0026quot;Usage Statistics\u0026quot; app-version=v0.0.1-beta memory.current=50 memory.min=20 memory.max=80 cpu=10 你可以看到 app-version 两个日志中都包含该属性。在处理程序上使用函数指定的属性WithAttrs将包含在所有日志中。\n在 context 中传递 logger 理想情况下，你希望创建一个具有特定配置和属性的记录器，并在整个应用程序中使用它。\nslog具有内置函数，可让让你在context中使用。\npackage main import ( \u0026quot;context\u0026quot; \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { textHandler := slog.NewTextHandler(os.Stdout). WithAttrs([]slog.Attr{slog.String(\u0026quot;app-version\u0026quot;, \u0026quot;v0.0.1-beta\u0026quot;)}) logger := slog.New(textHandler) ctx := slog.NewContext(context.Background(), logger) // 👈 context containing logger sendUsageStatus(ctx) } func sendUsageStatus(ctx context.Context) { logger := slog.FromContext(ctx) // 👈 grab logger from context logger.Info(\u0026quot;Generating statistics\u0026quot;) logger.Info(\u0026quot;Usage Statistics\u0026quot;, slog.Group(\u0026quot;memory\u0026quot;, slog.Int(\u0026quot;current\u0026quot;, 50), slog.Int(\u0026quot;min\u0026quot;, 20), slog.Int(\u0026quot;max\u0026quot;, 80)), slog.Int(\u0026quot;cpu\u0026quot;, 10), ) } 输出：\n$ go run main.go time=2022-12-21T11:41:28.333+08:00 level=INFO msg=\u0026quot;Generating statistics\u0026quot; app-version=v0.0.1-beta time=2022-12-21T11:41:28.334+08:00 level=INFO msg=\u0026quot;Usage Statistics\u0026quot; app-version=v0.0.1-beta memory.current=50 memory.min=20 memory.max=80 cpu=10 NewContext创建一个包含 logger 的 新的 context。\nFromContext从 contex t中获取 logger。如果 context 不包含 logger，它会返回default logger。\n日志级别 如果你使用的是默认 logger，它不会记录调试日志，因为默认日志级别为Info.\n你可以创建一个新的 logger，并将默认日志级别设置为Debug以显示调试日志。\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;golang.org/x/exp/slog\u0026quot;) func main() { opts := slog.HandlerOptions{ Level: slog.LevelDebug, } textHandler := opts.NewTextHandler(os.Stdout) logger := slog.New(textHandler) logger.Debug(\u0026quot;Debug\u0026quot;) logger.Info(\u0026quot;Info\u0026quot;) logger.Warn(\u0026quot;Warn\u0026quot;) } 输出：\n$ go run main.go time=2022-12-21T11:45:23.466+08:00 level=DEBUG msg=Debug time=2022-12-21T11:45:23.466+08:00 level=INFO msg=Info time=2022-12-21T11:45:23.466+08:00 level=WARN msg=Warn 本文来源 Logging in Go with slog - https://thedevelopercafe.com/articles/logging-in-go-with-slog-a7bb489755c2\n本文作者的其他 Go 语言文章也非常值得一读。\n","id":10,"section":"posts","summary":"\u003cp\u003e\u003cstrong\u003eslog\u003c/strong\u003e 是 Go 团队开发的一个实验性日志包，它提供了结构化日志记录的功能。\n\u003cstrong\u003e注意：当前该包还未在Go基础库中包含。\u003c/strong\u003e\u003c/p\u003e","tags":["go"],"title":"Go slog 日志包尝鲜","uri":"https://www.ganymedenil.com/2022/12/21/go-standard-library-by-slog-early.html","year":"2022"},{"content":"促使我写这篇文章主要是在写一个关于虚拟货币账户监控的项目时使用 Ticker 的问题。\nTicker 的问题 如果用过 Ticker 的朋友会知道，创建 Ticker 后并不会马上执行，而是会等待一个时间 d，这就是创建时的间隔时间。如果间隔时间很短这基本上不会有太大问题，但是如果对首次执行时间有要求，就会很麻烦。例如以下这个案例：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;time\u0026quot; ) func main() { ts := time.NewTicker(5 * time.Second) fmt.Println(\u0026quot;start_time#\u0026quot;, time.Now().Unix()) chanClose := make(chan struct{}) var wg sync.WaitGroup wg.Add(1) go func() { defer wg.Done() for { select { case \u0026lt;-chanClose: return case \u0026lt;-ts.C: fmt.Println(\u0026quot;run_time#\u0026quot;, time.Now().Unix()) } } }() go func() { time.Sleep(10 * time.Second) chanClose \u0026lt;- struct{}{} ts.Stop() }() wg.Wait() } 它将返回以下内容：\nstart_time# 1656860176 run_time# 1656860181 run_time# 1656860186 为了方便演示我们在事例中设了一个很短的时间，我们可以看到从代码启动到真正定时器触发，代码等待了5秒，就是time.NewTicker 创建时我们传的参数时间。但如果我们把这个时间改成1个小时，我们需要等待1个小时才会真正开始执行。\n寻找解决方案 在我的项目中需要定时器马上执行，所以我通过搜索搜到了 Go 官方仓库 Issues 中提到过这个问题的解决方案 “time: create ticker with instant first tick”。我们可以看一下这个事例：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;time\u0026quot; ) func main() { ts := time.NewTicker(5 * time.Second) fmt.Println(\u0026quot;start_time#\u0026quot;, time.Now().Unix()) var wg sync.WaitGroup wg.Add(1) go func() { for ; true; \u0026lt;-ts.C { fmt.Println(\u0026quot;run_time#\u0026quot;, time.Now().Unix()) } }() go func() { time.Sleep(10 * time.Second) ts.Stop() wg.Done() }() wg.Wait() } 上述的执行后返回内容：\nstart_time# 1656860889 run_time# 1656860889 run_time# 1656860894 我们可以看到首次定时器触发任务的时间变成了程序执行的开始时间！在我们的例子中，这种方式没有问题，但是我们需要关注退出条件，在这里是 main goroutine 直接退出。第一个 goroutine 其实直到 main 退出前一直是堵塞状态。如果你的项目中多次使用这种形式的定时器，每一个都会有一个堵塞的 goroutine，虽然不会对你程序造成 panic，但我还是感觉不是很好。\n我的版本 先上代码：\npackage ticktock import ( \u0026quot;time\u0026quot; ) // 这个结构体内容是为了兼容 Ticker 的使用方式 type tickerStart struct { C chan time.Time ticker *time.Ticker close chan struct{} } func NewTickerStart(d time.Duration) *tickerStart { // 这里我们创建的 channel 设了一个 buffer，原因是我们需要 // 在下面 Start 方法中及时推送当前时间而不至于堵塞。 // c := make(chan time.Time, 1) return \u0026amp;tickerStart{ticker: time.NewTicker(d), C: c, close: make(chan struct{})} } // 这是我们核心的方法 func (ts *tickerStart) Start() { ts.C \u0026lt;- time.Now() // 首次触发关键 go func() { for { select { case _, ok := \u0026lt;-ts.close: // 用于关闭这个 goroutine if !ok { return } case t := \u0026lt;-ts.ticker.C: // 把go原生定时器 push 的时间推送到我们定义的 time channel 中 ts.C \u0026lt;- t } } }() } // 兼容 ticker func (ts *tickerStart) Reset(d time.Duration) { ts.ticker.Reset(d) } // 兼容 ticker func (ts *tickerStart) Stop() { ts.ticker.Stop() close(ts.close) } 使用代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;time\u0026quot; \u0026quot;ticktock\u0026quot; ) func main() { fmt.Println(\u0026quot;start_time#\u0026quot;, time.Now().Unix()) chanClose := make(chan struct{}) tts := ticktock.NewTickerStart(5 * time.Second) tts.Start() var wg sync.WaitGroup wg.Add(1) go func() { defer wg.Done() for { select { case \u0026lt;-chanClose: return case \u0026lt;-tts.C: fmt.Println(\u0026quot;run_time#\u0026quot;, time.Now().Unix()) } } }() go func() { time.Sleep(10 * time.Second) chanClose \u0026lt;- struct{}{} tts.Stop() }() wg.Wait() } 执行返回内容如下：\nstart_time# 1656861872 run_time# 1656861872 run_time# 1656861877 可以看到，和我们想要的一致。但和官方给出的不同我们不会堵塞 goroutine 。\n最后 这是我在写虚拟货币账户监控项目中碰到的其中一个问题，我也会在后续的文章中写一写我碰到的其他问题。当然这个项目会开源，可以关注我的 github GanymedeNil\u0026rsquo;s github。\n最后的最后 顺便给自己宣传一下，如果你对我感兴趣或者想和我聊聊可以加我微信 ganymede-nil和下载我的简历，找工作中，注明加我的理由，防止被我当作营销人员😊。\n","id":11,"section":"posts","summary":"\u003cp\u003e促使我写这篇文章主要是在写一个关于虚拟货币账户监控的项目时使用 Ticker 的问题。\u003c/p\u003e","tags":["go"],"title":"支持首次触发的 Go Ticker","uri":"https://www.ganymedenil.com/2022/07/04/support-for-first-trigger-go-ticker.html","year":"2022"},{"content":"微服务是围绕业务领域建模可独立发布的服务。服务封装了对应功能并可以通过网络被其他服务访问。从外部来看，单个微服务被视为一个黑盒子。它使用最合适的协议在一个或多个网络端点(例如，队列或REST API)上承载业务功能。消费者，无论他们是其他微服务还是其他类型的程序\u0026hellip;\n微服务概览 微服务是围绕业务领域建模可独立发布的服务。服务封装了对应功能并可以通过网络被其他服务访问。\n从外部来看，单个微服务被视为一个黑盒子。它使用最合适的协议在一个或多个网络端点(例如，队列或REST API)上承载业务功能。消费者，无论他们是其他微服务还是其他类型的程序，都通过这些联网的端点来访问这个功能。内部实现细节(如编写服务的技术或存储数据的方式)完全对外部世界隐藏。这意味着微服务架构在大多数情况下避免使用共享数据库;相反，每个微服务在需要的地方封装自己的数据库。\n信息隐藏指的是尽可能少的对外部接口暴露服务信息。微服务公开的网络接口只要向后兼容，就可以自由的对服务内部进行更改。这也符合系统的高内聚低耦合设计思路。\n微服务的关键概念 独立可部署 我们可以对微服务进行更改、部署并将更改发布给我们的用户，而无需部署任何其他微服务。\n围绕业务领域建模 对于微服务架构，我们使用像领域驱动设计的思想来定义我们的服务边界。通过围绕业务领域建模服务，我们可以更轻松地推出新功能并以不同方式重组微服务，从而为我们的用户提供新功能。\n对于微服务，我们优先考虑业务功能的高内聚性，而不是技术功能的高内聚性。\n拥有自己的状态 微服务应该避免使用共享数据库。\n隐藏微服务中的内部状态类似于面向对象（OO）编程中的封装实践。\n尺寸 Thoughtworks 的技术总监 James Lewis 曾说过“微服务应该和你的脑袋一样大”。\n微服务模式（Manning Publications）的作者 Chris Richardson 曾经说过的——微服务的目标是“尽可能小地接口” 。 尺寸并不需要太担心，比这个更需要关注的两件事\n你可以处理多少个微服务 增量迁移到微服务架构 灵活性 James Lewis 说过 “microservices buy you options.”。这句话可以这么理解，微服务架构是有成本的，你必须决定付出的成本是否值得你选择的选项。\n越向微服务演进，则灵活性会大幅提升，而这也会增加更多的痛点。所以强烈提倡逐步采用微服务。然后时刻评估引入微服务的影响，并在需要时停下来。\n架构和组织的一致性 一般的Web业务都会有一个三层架构——前端团队的UI、后端负责的业务逻辑层以及负责管理数据存储的DBA。\n如果需要开发一个新的需求，我们需要拆分需求到三个团队，然后需要各个团队以正确的顺序进行部署。这是一种相关技术内聚度高但业务功能内聚度低的架构。\n这种组织方式在微服务场景下变的不太适用，我们需要垂直业务线分解组织和架构。\n这样变更后，我们的业务领域成为推动我们系统架构的主要力量，能够更容易地进行更改，并使我们更容易将团队与组织内的业务线保持一致。\nTeam Topologies 出品的《高效能团队模式：支持软件快速交付的组织架构》一书中就介绍了这种组织方式的概念： A stream-aligned team is a team aligned to a single, valuable stream of work\u0026hellip;[T]he team is empowered to build and deliver customer or user value as quickly, safely, and independently as possible, without requiring hand-offs to other teams to perform parts of the work.\n单体 Single-Process Monolith Ruby on Rails 的创建者 David Heinemeier Hansson 有效地证明了这种架构对小型组织有意义。\nModular Monolith 对于许多组织来说，模块化单体可以是一个很好的选择。如果模块边界定义良好，它可以支持高度的并行工作，同\n时通过使用更简单的部署拓扑来避免更分布式微服务架构的挑战。 模块化单体架构的挑战之一是数据库往往缺乏我们在代码级别的拆分，如果你想在未来拆分单体架构，则会面临重大挑战。\n我们也看到过一些团队通过将数据库按照与模块相同的方式来拆分进一步推动模块化单体的想法\nDistributed Monolith 分布式单体是一个由多个服务组成的系统，但无论出于何种原因，整个系统都必须部署在一起。分布式单体架构可能很符合 SOA 的定义，但往往无法兑现 SOA 的承诺。以我的经验，分布式单体具有分布式系统的所有缺点，也具有单体的缺点，但没有足够的优点。\n分布式单体通常出现在没有足够关注信息隐藏和业务功能凝聚力等概念的环境中。取而代之的是，高度耦合的体系结构会导致更改跨越服务边界，而看似无害的本地范围内的更改会破坏系统的其他部分。\n单体和交付竞争 不同的开发人员想要更改同一段代码，不同的团队想要在不同的时间推出功能（或延迟部署），以及围绕谁拥有什么以及谁做决定的混乱局面。大量研究表明，所有权界限混淆的挑战。此问题称为交付竞争。\n拥有一个单体并不意味着你肯定会面临交付竞争的挑战，就像拥有一个微服务架构意味着你永远不会面临这个问题一样。但是微服务架构确实为您提供了更具体的边界，可以围绕这些边界在系统中绘制所有权的分界线，从而在减少此问题时为你提供更大的灵活性。\n单体的优势 单体也有很多优点。更简单的部署拓扑可以避免许多与分布式系统相关的陷阱。这可以使开发人员的工作流程更加简单，监控、故障排除和端到端测试等也可以大大简化。\n单体应用还可以简化单体应用内部的代码重用。如果我们想在分布式系统中重用代码，我们需要决定是要复制代码、拆分库还是将共享功能推送到服务中。有了单体，我们的选择就简单多了，很多人喜欢这种简单——所有的代码都在那里；用它！\n关于代码重用的问题，谷歌提出的单一仓库（所有项目在一个仓库中）其实可以解决，但是这也就导致开发流程变的更复杂。\n技术采用 当你升级你的微服务架构时，你应该不断地寻找由日益分散的系统引起的问题，然后寻找可能有帮助的技术。而不是一上来就开始使用各种新的技术。\n日志聚合与分布式跟踪 随着你管理的微服务越来越多，你就很难了解系统在生产环境中的表现。这也会导致线上故障排除变得更加困难。我们主张日志聚合系统作为采用微服务架构的先决条件。\n这些系统允许你收集和汇总所有服务的日志，为你提供一个可以分析日志的中心位置，甚至成为主动警报机制的一部分。该领域的许多选择可满足多种情况。\n你可以通过实现相关 ID 使这些日志聚合工具更加有用，其中单个 ID 用于一组相关的服务调用，例如，用户交互而触发的调用链。通过将此 ID 记录为每个日志条目的一部分，隔离与给定调用流相关联的日志变得更加容易，这反过来又使故障排除更加容易。\n你的系统变得越来越复杂，因此必须考虑一些工具，这些工具可以让你更好地探索系统正在做什么，提供跨多个服务分析跟踪、检测瓶颈以及提供给你不了解的系统问题的能力。开源工具可以提供其中一些功能。一个例子是Jaeger，它专注于等式的分布式跟踪方面。\n容器和 Kubernetes 不要急于采用 Kubernetes，甚至是容器。与更传统的部署技术相比，它们绝对具有显着优势，但如果你只有几个微服务，则很难证明采用它们的合理性。在管理部署的开销开始变得令人头疼之后，开始考虑服务的容器化和 Kubernetes 的使用。但是，如果你最终这样做了，请尽最大努力确保有专业人士正在为你维护 Kubernetes 集群，可能是通过使用公共云提供商上的托管服务。运行你自己的 Kubernetes 集群可能需要大量工作！\n流式传输 Apache Kafka已成为微服务环境中流数据的选择，这是有充分理由的。消息持久性、压缩以及处理大量消息的扩展能力等功能非常有用。Kafka 已开始以 KSQLDB 的形式添加流处理功能，但你也可以将其与Apache Flink等专用流处理解决方案一起使用。Debezium是一种开源工具，旨在帮助通过 Kafka 从现有数据源流式传输数据，帮助传统数据源可以成为基于流的架构的一部分。\n公共云和无服务器 公共云提供商提供大量托管服务，从托管数据库实例或 Kubernetes 集群到消息队列或分布式文件系统。通过使用这些托管服务，你可以将大量工作转嫁给可以更好地处理这些任务的第三方。\n功能即服务 (FaaS) 平台特别受关注，因为它们围绕代码部署提供了很好的抽象。你不必担心需要多少台服务器来运行服务，只需部署代码并让底层平台按需处理代码实例。\n微服务的优势 技术异质性 一个由多个微服务协作组成的系统，我们可以决定在每个微服务内部使用不同的技术。这使我们能够为每项工作选择正确的工具，而不必选择一种更标准化、一刀切的方法。 微服务可以让你更轻松地拥抱不同的技术\n借助微服务，我们还能够更快地采用技术并了解新的进步如何帮助我们。尝试和采用新技术的最大障碍之一是与之相关的风险。对于单体应用程序，如果我想尝试一种新的编程语言、数据库或框架，任何更改都会影响我的大部分系统。有了一个由多种服务组成的系统，我有多个新地方可以尝试一项新技术。我可以选择风险最低的微服务并在那里使用该技术，因为我知道我可以限制任何潜在的负面影响。许多组织发现这种更快地吸收新技术的能力是一个真正的优势。\n鲁棒性 一种提高应用程序稳健性的关键概念是隔板。系统的一个组件可能会发生故障，但只要该故障没有级联，你就可以隔离问题，系统的其余部分可以继续工作。服务边界成为明显的隔板。在单体服务中，如果服务失败，一切都会停止工作。使用单体系统，我们可以在多台机器上运行以减少失败的机会，但是使用微服务，我们可以构建系统来处理某些组成服务的完全故障并相应地进行降级。\n然而，我们确实需要小心。为了确保我们的微服务系统能够正确地接受这种改进的健壮性，我们需要了解分布式系统必须处理的新故障源。网络会失败，机器也会失败。我们需要知道如何处理此类故障以及这些故障将对我们软件的最终用户产生的影响（如果有的话）。\n缩放 在一个大型的单体服务中，我们需要一起扩展所有内容。也许我们整个系统的一小部分在性能上受到限制，但如果这种行为被锁定在一个巨大的单体应用程序中，我们需要将所有东西都作为一个整体来处理。使用微服务，我们可以只扩展那些需要扩展的服务，允许我们在更小、更不强大的硬件上运行系统的其他部分。\n易于部署 对百万行单体应用程序的单行更改需要部署整个应用程序才能发布更改。这可能是一个影响大、风险高的部署。在实践中，由于可以理解到的恐惧，诸如此类的部署最终很少发生。不幸的是，这意味着我们的更改会在不同版本之间继续累积，直到我们进入生产环境的应用程序的新版本发生大量更改。版本之间的差异越大，我们出错的风险就越高！\n使用微服务，我们可以对单个服务进行更改并独立于系统的其余部分进行部署。这使我们能够更快地部署我们的代码。如果确实出现问题，可以快速将其隔离到单个服务，从而轻松实现快速回滚。这也意味着我们可以更快地将我们的新功能提供给客户。\n组织协调 我们中的许多人都经历过与大型团队和大型代码库相关的问题。当团队分散时，这些问题可能会加剧。我们还知道，处理较小代码库的较小团队往往更有效率。\n微服务使我们能够更好地使我们的架构与我们的组织保持一致，帮助我们最大限度地减少在任何一个代码库上工作的人数，从而达到团队规模和生产力的最佳平衡点。微服务还允许我们随着组织的变化而改变服务的所有权——使我们能够在未来保持架构和组织之间的一致性。\n可组合性 使用微服务，我们允许我们的功能以不同的方式用于不同的目的。当我们考虑消费者如何使用我们的软件时，这一点尤其重要。\n微服务的劣势 开发者体验 越来越多的服务，这让本地开发变的复杂，本地环境能运行服务的数量是有限的 极端解决方案“云上开发”，但这会导致反馈周期受到很大影响\n针对于微服务开发部分解决方案确实很少，我了解的方案比如建立内网网关打通开发网络与企业网络，然后来进行开发。但这也只是解决了网络问题。之前了解过云原生工具Nocalhost，可以缩短整个开发反馈周期，并且可以和IDE直接集成。\n技术过载 微服务很可能让你可以选择使用不同的编程语言编写每个微服务、在不同的运行时上运行或使用不同的数据库——但这些只是选项，而不是要求。你必须仔细平衡你使用的技术的广度和复杂性与各种技术可能带来的成本。\n当你开始采用微服务时，一些基本挑战是不可避免的：你需要花费大量时间来了解围绕数据一致性、延迟、服务建模等问题。如果你试图了解这些想法如何改变你对软件开发的看法，同时你正在接受大量新技术，那么你将遇到困难。还需要知道的是，尝试了解所有这些新技术所将占用你大量的时间，同时也将减少功能实际交付给用户的时间。\n随着你增加微服务架构的复杂性，请考虑根据需要引入新技术。当你拥有三个服务时，你不需要 Kubernetes 集群！除了确保你不会因这些新工具的复杂性而不堪重负之外，这种逐渐增加的额外好处是使你能够获得新的更好的做事方式，这些方式无疑会随着时间的推移而出现。\n成本 短期来看，你会看到因为引入微服务你的成本会随之增加。 其次学习新的技术和思想以及团队工作方式的变更都需要时间。这将导致新功能交付变缓，你或许需要更多的人员来抵消这一成本。\n根据经验，对于一个主要关注降低成本的组织来说，微服务是一个非常糟糕的选择，因为决策者将始终有削减陈本的心态，而IT被视为成本中心而不是利润中心。另一方面，如果你可以使用这一架构来接触更多的客户或并行开发更多功能，那么微服务可以帮你赚到更多的钱。微服务是增加利润的一种方式吗？也许。那微服务是降低成本的方法吗？基本不可能。\n报表 对于单体系统，通常只有一个数据库。这就意味着想要分析所有数据，只需要对这个数据库（也可能针对只读副本）进行报表的生成。\n通过微服务架构，我们打破了这种单体架构。这并不意味着我们不再需要生成报表；我们只是让它变得更加困难，因为现在我们的数据分散在多个逻辑隔离的模式中。 更现代的报表生成的方法，例如使用流式传输来允许对大量数据进行实时传输，这可以很好地与微服务架构配合使用，但通常需要采用新的想法和相关技术。或者，可能只需将微服务中的数据发布到中央报表数据库（或者可能是不太结构化的数据湖）中。\n监控和故障排除 对于一个标准的单体应用程序，我们可以相当简单的进行监控。我们要担心的机器数量很少，应用程序的故障模式也很单一——应用程序通常要么全部启动，要么全部关闭。使用微服务架构，如果只有一个服务实例出现故障，我们是否了解其影响？\n对于单体系统，如果我们的 CPU 长时间卡在 100%，我们知道这是一个大问题。拥有数十或数百个进程的微服务架构，我们可以说同样的话吗？当只有一个进程卡在 100% CPU 时，我们是否需要在凌晨 3 点叫醒某人？\n安全 现在，更多信息通过我们的服务之间的网络流动。这可能使我们的数据更容易在传输过程中被观察到，并且可能被作为中间人攻击的一部分进行操纵。这意味着您可能需要更加小心地保护传输中的数据，并确保您的微服务端点受到保护，以便只有授权方才能使用它们。\n测试 对于任何类型的自动化功能测试，你都有一个微妙的平衡行为。测试执行的功能越多（即测试范围越广），你对应用程序的信心就越大。另一方面，测试的范围越大，设置测试数据和支持的工具就越困难，测试运行的时间就越长，当它失败时就越难弄清楚什么是坏的。\n就其涵盖的功能而言，任何类型系统的端到端测试都处于规模的极端，而且我们习惯于它们在编写和维护方面比小范围的单元测试更有问题。但是，这通常是值得的，因为我们希望通过端到端测试以与用户相同的方式使用我们的系统来获得信心。\n但是使用微服务架构，我们端到端测试的范围变得非常大。我们现在需要跨多个进程运行测试，所有这些都需要针对测试场景进行部署和适当配置。我们还需要为环境问题（例如服务实例死亡或部署失败的网络超时）导致我们的测试失败时发生的误报做好准备。\n这些力量意味着，随着你的微服务架构的发展，你在端到端测试方面的投资回报将逐渐减少。测试将花费更多，但无法给你与过去相同的信心。这将推动你走向新的测试形式，例如合同驱动测试或生产测试，以及探索渐进式交付技术，例如并行运行或金丝雀发布。\n延迟 以前可能在一个处理器上本地完成的处理现在最终可以拆分为多个单独的微服务。以前仅在单个进程中流动的信息现在需要通过网络进行序列化、传输和反序列化，你可能比以往任何时候都更频繁地使用这些网络。所有这些都可能导致系统延迟恶化。\n尽管在设计或编码阶段很难衡量对操作延迟的确切影响，但这是以增量方式进行任何微服务迁移很重要的另一个原因。做一个小的改变，然后衡量影响。这假设你有某种方法可以测量你关心的操作的端到端延迟——像 Jaeger 这样的分布式跟踪工具可以在这里提供帮助。但是你还需要了解 这些操作可接受的延迟时间。有时让操作变慢是完全可以接受的，只要它仍然足够快！\n数据一致性 在单个数据库中存储和管理数据的单体系统到在不同数据库中管理多个进程的分布式系统，这对数据的一致性造成了潜在的挑战。尽管过去你可能依赖数据库事务来管理状态更改，但你需要了解在分布式系统中不容易提供类似的安全性。在大多数情况下，分布式事务的使用被证明在协调状态更改方面存在很大问题。\n相反，你可能需要开始使用 sagas 和最终一致性等概念来管理和推理系统中的状态。这些想法可能需要从根本上改变你对系统中数据的思考方式，这在迁移现有系统时可能会非常令人生畏。再一次，这是另一个在分解应用程序时要谨慎的好理由。采用增量方法进行分解，以便你能够评估更改对生产体系结构的影响，这一点非常重要。\n我应该使用微服务吗 它们可能不适合为谁工作 微服务架构对于全新的产品或初创公司来说往往是一个糟糕的选择。\n往往全新的产品或初创公司在前期业务改动会非常频繁，服务边界无法确定，域模型也无法很好的建立，但这是微服务的前置条件。 微服务带来了新工作和复杂性，这会占用宝贵的开发资源。团队越小，这种成本就越明显。 它们在哪里工作的更好 组织采用微服务的最大原因可能是允许更多的开发人员在同一个系统上工作，而不会互相妨碍。正确设置架构和组织边界，让更多人彼此独立工作，从而减少交付争用。一家五人创业公司可能会觉得微服务架构很麻烦。一个快速增长的 100 人规模化企业可能会发现，它的增长更容易适应与其产品开发工作适当协调的微服务架构。\n软件即服务 (SaaS)，这类非常适合微服务架构。这些产品通常需要 24-7 小时运行，这在推出变更时会带来挑战。微服务架构的独立可发布性是该领域的一大福音。此外，微服务可以根据需要扩大或缩小。这意味着，当你为系统的负载特性建立一个合理的基线时，你将获得更多控制权，以确保你可以以最具成本效益的方式扩展您的系统。\n微服务与技术无关的特性确保可以充分利用云平台。公共云供应商为你的代码提供广泛的服务和部署机制。你可以更轻松地将特定服务的要求与最能帮助你实施它们的云服务相匹配。例如，你可能决定将一个服务部署为一组功能，另外部署为托管虚拟机 (VM)，还可以部署在托管平台即服务 (PaaS) 平台上。\n值得注意的是，采用广泛的技术通常会成为一个问题，但能够轻松尝试新技术是快速识别可能产生效益的好方法。FaaS 平台的日益普及就是这样一个例子。对于适当的工作负载，FaaS 平台可以大大减少运营开销，但目前，它并不是一种适用于所有情况的部署机制。\n微服务还为希望通过各种新渠道为客户提供服务的组织带来了明显的好处。许多数字化转型工作似乎都涉及尝试解锁隐藏在现有系统中的功能。我们的愿望是创造新的客户体验，通过任何最有意义的交互机制来支持用户的需求。 最重要的是，微服务架构可以在你继续发展系统时为你提供很大的灵活性。当然，这种灵活性是有代价的，但如果你想在未来可能想要做出的改变方面保持开放的选择，这可能是一个值得付出的代价。\n概括 微服务架构可以为你在技术选择、处理健壮性和扩展性、组织团队等方面提供极大的灵活性。这种灵活性是许多人采用微服务架构的部分原因。但是微服务带来了很大程度的复杂性，你需要确保这种复杂性是合理的。对于许多人来说，它们已成为默认的系统架构，几乎可以在所有情况下使用。但是，我仍然认为它们是一种架构选择，必须根据你要解决的问题来证明其使用是合理的；通常，更简单的方法可以更轻松地交付。\n尽管如此，许多组织，尤其是大型组织，已经展示了微服务的有效性。当微服务的核心概念被正确理解和实施时，它们可以帮助创建授权、高效的架构，从而帮助系统变得不仅仅是其部分的总和。\n","id":12,"section":"posts","summary":"\u003cp\u003e微服务是围绕业务领域建模可独立发布的服务。服务封装了对应功能并可以通过网络被其他服务访问。从外部来看，单个微服务被视为一个黑盒子。它使用最合适的协议在一个或多个网络端点(例如，队列或REST API)上承载业务功能。消费者，无论他们是其他微服务还是其他类型的程序\u0026hellip;\u003c/p\u003e","tags":null,"title":"我的微服务总结","uri":"https://www.ganymedenil.com/2022/04/22/what-are-microservices.html","year":"2022"},{"content":"0x1 概述 我在入门以太坊智能合约开发时，首先我就面临了一个选择，Hardhat Vs Truffle Vs Remix，我应该选择哪个开发工具。我就在谷歌上搜索很多对比，其中霍利维尔·瓦尔迪兹 的 《Hardhat Vs Truffle Vs Remix - Which Is The Best For Blockchain Development?》 这篇文章很及时的帮助了我，并且OpenZeppelin、Aave、BitGo、1inch等都在使用该开发工具，而且我在深入了解官方文档后发现文档整体很清晰并且有条理，而我又有一定的前端开发经验，所以在开发工具的选型上我选择了 Hardhat 。如果你没有前端经验，希望在前期学习的时候更关注合约本身，那么我会推荐 Remix 作为前期学习的开发工具。 这是我基于 Hardhat 官方教程写的第一篇以太坊合约和 dApp 开发指南，未来我也会持续分享所学。\n0x2 搭建环境 首先 Hardhat 是基于 JavaScript 编写的，所以我们首先需要安装 Node.js 环境。\n安装 Node.js 如果你已经安装了 Node.js 你可以跳过这个部分。如果没有，接下来会介绍如何在 Ubuntu、MacOS和 Windows 上安装它。\nLinux Ubuntu 将以下命令复制粘贴到终端：\nsudo apt update sudo apt install curl git curl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash - sudo apt install nodejs MacOS 确保你已经安装了 git ,如果没有安装可以参考 atlassian 写的 《Install Git》。 在 MacOS 上安装 Node.js 有多种方法。我选择了使用 Node 版本管理器（nvm）。将以下命令复制粘贴到终端：\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash nvm install --lts nvm use stable nvm alias default stable npm install npm --global # 升级 npm 到最新版本 Windows Windows 可以直接到 Node.js 官网，下载对应的安装包即可完成安装。\n0x3 创建一个新的项目 我们将使用 npm CLI 来安装 Hardhat。 打开终端并运行以下命令：\nmkdir hardhat-tutorial cd hardhat-tutorial npm init --yes npm install --save-dev hardhat 安装 Hardhat 的过程中会安装 Ethereum JavaScript 依赖项，所以请耐心等待。 在安装 Hardhat 的同一目录下运行：\nnpx hardhat 使用键盘选择 Create an empty hardhat.config.js 并按下回车键。\n$ npx hardhat 888 888 888 888 888 888 888 888 888 888 888 888 888 888 888 8888888888 8888b. 888d888 .d88888 88888b. 8888b. 888888 888 888 \u0026quot;88b 888P\u0026quot; d88\u0026quot; 888 888 \u0026quot;88b \u0026quot;88b 888 888 888 .d888888 888 888 888 888 888 .d888888 888 888 888 888 888 888 Y88b 888 888 888 888 888 Y88b. 888 888 \u0026quot;Y888888 888 \u0026quot;Y88888 888 888 \u0026quot;Y888888 \u0026quot;Y888 👷 Welcome to Hardhat v2.9.1 👷‍ ? What do you want to do? … Create a basic sample project Create an advanced sample project Create an advanced sample project that uses TypeScript ❯ Create an empty hardhat.config.js Quit 当 Hardhat 运行时，它会从当前工作目录开始搜索最近的 hardhat.config.js 文件。这个文件通常在你的项目根目录，一个空的 hardhat.config.js 就足以让 Hardhat 工作。未来我们对 Hardhat 的全部设置都会在这个文件中。\nHardhat 架构 Hardhat 基于任务和插件的理念设计。而 Hardhat 的大部分功能都来自插件，作为开发人员，你可以自由选择要使用的插件。\n任务 每次从 CLI 运行 Hardhat 时，你都在运行一项任务。例如 npx hardhat compile 命令就是运行 compile 任务。要查看项目当前可用的任务，只执行 npx hardhat。你也可以通过帮助命令了解其他任务 npx hardhat help [task]。\n当然我们也可以创建自定义的任务，参考创建任务。\n插件 在你最终使用什么工具方面，Hardhat 并不会限制你，但它确实带有一些内置的默认设置。所有这些也都可以被重写。 在本文中，我们将使用 Ethers.js 和 Waffle 插件。它们将允许你与以太坊交互并测试你的合约。稍后我们将解释它们是如何使用的。要安装它们，你只需在项目目录中运行以下命令：\nnpm install --save-dev @nomiclabs/hardhat-ethers ethers @nomiclabs/hardhat-waffle ethereum-waffle chai 我们需要添加以下代码\nrequire(\u0026quot;@nomiclabs/hardhat-waffle\u0026quot;); 到如下位置，看起来会是这样：\nrequire(\u0026quot;@nomiclabs/hardhat-waffle\u0026quot;); /** * @type import('hardhat/config').HardhatUserConfig */ module.exports = { solidity: \u0026quot;0.7.3\u0026quot;, }; 我们只需要引用 hardhat-waffle。\n0x4 编写与编译合约 我们将创建一个简单的智能合约来实现代币转移。代币合约最常用于交换和存储价值。我们不会在本文中展开详细谈考合约中的 Solidity 代码，但是我们实现了一些你应该之大的逻辑：\n代币的总供应量时固定的，无法被改变 整个供应量分配到部署合约的地址 任何人都可以收到代币 任何拥有至少一个代币的人都可以转移代币 代币是不可分割的。你可以转移1、2、3或者37个代币，但不能转移2.5个 你可能听说过 ERC20，它是以太坊中的代币标准。DAI、USDC、MKR和ZRX等代币遵循 ERC20 标准，这使得它们都可以与任何可以处理 ERC20 代币的软件兼容。为简单起见，我们要构建的代币没有遵循 ERC20。\n编写智能合约 首先创建一个名为新目录 contracts，并在该目录中创建一个名为 Token.sol。 将下面的代码粘贴到该文件中，花一点时间阅读代码。它很简单，并且充满了解释 Solidity 基础知识的备注。\n要获得语法高亮，你应该在文本编辑器中添加 Solidity 语言的支持。只需寻找 Solidity 或 Ethereum 插件。我们建议使用 Visual Studio Code 或 Sublime Text 3。\n// Solidity 文件 第一行代码都会是 pragma // Solidity 编译器将使用它来验证对应的版本 pragma solidity ^0.7.0; // 这是智能合约的主要组成部分 contract Token { // 一些字符串类型变量来标识代币 // `public` 修饰符使变量在合约外部可读 string public name = \u0026quot;My Hardhat Token\u0026quot;; string public symbol = \u0026quot;MHT\u0026quot;; // 存储在无符号整型变量中的固定数量代币 uint256 public totalSupply = 1000000; // 地址类型变量用于存储以太坊账户 address public owner; // `mapping` 是一个键/值映射。我们在这里存储每个帐户余额 mapping(address =\u0026gt; uint256) balances; /** * 合约初始化 * * `constructor` 只在合约创建时执行 */ constructor() { // totalSupply 被分配给交易发送方，即部署合约的帐户 balances[msg.sender] = totalSupply; owner = msg.sender; } /** * 传递代币的函数 * * `external` 修饰符使函数只能从合约外部调用 */ function transfer(address to, uint256 amount) external { // 检查交易发送方是否有足够的代币 // 如果 `require` 的第一个参数计算结果为 `false``,则整个交易会恢复 require(balances[msg.sender] \u0026gt;= amount, \u0026quot;Not enough tokens\u0026quot;); // 转移金额 balances[msg.sender] -= amount; balances[to] += amount; } /** * 读取给定帐户的代币余额 * * `view` 修饰符表示它不修改合约的状态，这允许我们在不执行交易的情况下调用它 */ function balanceOf(address account) external view returns (uint256) { return balances[account]; } } *.sol 是 Solidity 的文件类型。我们建议将文件名与其包含的合约相匹配，这是一个常见的做法。\n编译合同 编译合约，在你的终端中执行npx hardhat compile。该 compile 任务是内置任务之一。\n$ npx hardhat compile Compiling 1 file with 0.7.3 Compilation finished successfully 合约已经编译成功，现在你就可以使用了。\n0x5 测试合约 在构建智能合约时编写自动化测试是至关重要的，因为我们的代码将直接操作用户的钱！为此，我们将使用 Hardhat 网络，这是一个为开发而设计的本地以太坊网络，它内置在 Hardhat 工具中，并且是默认网络。你无需设置任何内容即可使用它。在我们的测试中，我们将使用 ethers.js 与我们在上节中构建的以太坊合约进行交互，并且使用 Mocha 作为我们的测试运行时。\n编写测试 在我们的项目根目录中创建名为test的目录，并在里面创建一个文件名为Token.js的文件。 我们从下面的代码开始。我们将在接下来解释其中的含义，但现在你只需将其粘贴到 Token.js 中：\nconst { expect } = require(\u0026quot;chai\u0026quot;); describe(\u0026quot;Token contract\u0026quot;, function () { it(\u0026quot;Deployment should assign the total supply of tokens to the owner\u0026quot;, async function () { const [owner] = await ethers.getSigners(); const Token = await ethers.getContractFactory(\u0026quot;Token\u0026quot;); const hardhatToken = await Token.deploy(); const ownerBalance = await hardhatToken.balanceOf(owner.address); expect(await hardhatToken.totalSupply()).to.equal(ownerBalance); }); }); 在你的终端上运行 npx hardhat test，你应该看到以下输出：\nnpx hardhat test Token contract ✓ Deployment should assign the total supply of tokens to the owner (654ms) 1 passing (663ms) 这意味着测试通过了。现在让我们解释每一行：\nconst [owner] = await ethers.getSigners(); Signer 代表 ethers.js 中以太坊的对象。 它用于向合约和其他账户发送交易。在这里，我们得到了所连接节点中的账户列表，在本例中时Hardhat 网络，并且只保留第一个。\n该ethers变量在全局范围内可用。你可以在顶部添加这么一行：\nconst { ethers } = require(\u0026quot;hardhat\u0026quot;); 要了解更多关于Singer的信息，你可以查看 Signers 文档。\nconst Token = await ethers.getContractFactory(\u0026quot;Token\u0026quot;); 在 ethers.js 中，ContractFactory 是一个用于部署新智能合约的抽象，所以这里的 Token是我们的代币合约工厂的实例。\nconst hardhatToken = await Token.deploy(); 在 ContractFactory 上调用deploy()将开始部署，并返回Contract解析后的 Promise。这是为你的每个智能合约功能提供方法的对象。\nconst ownerBalance = await hardhatToken.balanceOf(owner.address); 一旦部署了合约，我们就可以在hardhatToken上调用我们的合约方法，并通过调用balanceOf()来获取相应所有者帐户的余额。\n请记住，获得整个供应量的代币所有者是进行部署的账户，当使用hardhat-ethers插件时，ContractFactory和Contract实例默认连接到第一个签名者。这意味着owner变量中的账户执行了部署，而balanceOf()应该返回整个供应量。\nexpect(await hardhatToken.totalSupply()).to.equal(ownerBalance); 在这里，我们再次使用我们的Contract实例来调用 Solidity 代码中的智能合约函数。totalSupply()返回代币的供应量，我们检查它是否等于ownerBalance，正如它应该做的那样。\n为了做到这一点，我们使用了 Chai，这是一个断言库。这些断言函数被称为 \u0026ldquo;匹配器\u0026rdquo;，而我们在这里使用的函数实际上来自 Waffle。这就是为什么我们要使用hardhat-waffle插件，它使我们更容易从Ethereum 断言值。请查看 Waffle 文档中的这一节，了解整个以太坊特定匹配器的列表。\n使用其他帐户 如果你需要从默认账户（或ethers.js中的Signer）以外的账户发送交易来测试你的代码，你可以使用ethers.js Contract中的connect()方法将其连接到一个不同的账户。像这样：\nconst { expect } = require(\u0026quot;chai\u0026quot;); describe(\u0026quot;Transactions\u0026quot;, function() { it(\u0026quot;Should transfer tokens between accounts\u0026quot;, async function() { const [owner, addr1, addr2] = await ethers.getSigners(); const Token = await ethers.getContractFactory(\u0026quot;Token\u0026quot;); const hardhatToken = await Token.deploy(); // 从所有者转移50个代币到addr1 await hardhatToken.transfer(addr1.address, 50); expect(await hardhatToken.balanceOf(addr1.address)).to.equal(50); // 从addr1转移50个代币到addr2 await hardhatToken.connect(addr1).transfer(addr2.address, 50); expect(await hardhatToken.balanceOf(addr2.address)).to.equal(50); }); }); 完全覆盖 现在我们已经介绍了测试合约所需的基础知识，这里有一个完整的代币测试套件，其中包含有关 Mocha 以及如何构建测试的大量附加信息。我们建议通读。\n// 我们在这里导入Chai以使用它的断言函数 const { expect } = require(\u0026quot;chai\u0026quot;); // `describe` 是一个Mocha函数，它允许您组织测试 // 实际上并不需要这样做，但是组织测试会使调试变得更容易。所有的Mocha函数都可以在全局作用域中使用 // `describe` 参数为一个测试名称和一个回调函数 // 回调必须定义该部分的测试。这个回调函数不能是一个异步函数 describe(\u0026quot;Token contract\u0026quot;, function () { // Mocha 有四个函数可以让你能在整个测试生命周期中进行不同的操作， // 它们是： `before`, `beforeEach`, `after`, `afterEach` // 它们在设置测试环境和运行后清理环境方面非常有用 // 一个常见的模式是声明一些变量，并在 `before` 和 `beforeEach` 回调中分配它们 let Token; let hardhatToken; let owner; let addr1; let addr2; let addrs; // `beforeEach` 将在每次测试之前运行，每次重新部署合约。它接收回调，可以是异步的 beforeEach(async function () { // 在这里获取 ContractFactory 和签名者 Token = await ethers.getContractFactory(\u0026quot;Token\u0026quot;); [owner, addr1, addr2, ...addrs] = await ethers.getSigners(); // 要部署我们的合约，只需调用 Token.deploy() 并等待它被 deployed()，一旦它的交易被挖掘，就会发生部署 hardhatToken = await Token.deploy(); }); // 你可以嵌套 describe 调用来创建小结 describe(\u0026quot;Deployment\u0026quot;, function () { // `it` 是 MoCha 函数，这是用来定义测试的工具。它接收测试名和回调函数 // 如果回调函数是一步的，Mocha 将 `await` it(\u0026quot;Should set the right owner\u0026quot;, async function () { // Expect 接收一个值，并将其包装在Assertion对象中。这些对象有很多实用方法来断言值 // 这个测试期望存储在合约中的所有者变量等于我们部署合约时候的所有者 expect(await hardhatToken.owner()).to.equal(owner.address); }); it(\u0026quot;Should assign the total supply of tokens to the owner\u0026quot;, async function () { const ownerBalance = await hardhatToken.balanceOf(owner.address); expect(await hardhatToken.totalSupply()).to.equal(ownerBalance); }); }); describe(\u0026quot;Transactions\u0026quot;, function () { it(\u0026quot;Should transfer tokens between accounts\u0026quot;, async function () { // 将50个代币从所有者转移到 addr1 await hardhatToken.transfer(addr1.address, 50); const addr1Balance = await hardhatToken.balanceOf(addr1.address); expect(addr1Balance).to.equal(50); // 将50个代币从 addr1 转移到 addr2 // 我们使用.connect(签名者)从另一个帐户发送交易 await hardhatToken.connect(addr1).transfer(addr2.address, 50); const addr2Balance = await hardhatToken.balanceOf(addr2.address); expect(addr2Balance).to.equal(50); }); it(\u0026quot;Should fail if sender doesn’t have enough tokens\u0026quot;, async function () { const initialOwnerBalance = await hardhatToken.balanceOf(owner.address); // 尝试从 addr1 (0 代币)发送1个代表给所有者(1000000 代币)。 // `require`将计算为 false 并恢复交易 await expect( hardhatToken.connect(addr1).transfer(owner.address, 1) ).to.be.revertedWith(\u0026quot;Not enough tokens\u0026quot;); // 所有者余额不应该改变 expect(await hardhatToken.balanceOf(owner.address)).to.equal( initialOwnerBalance ); }); it(\u0026quot;Should update balances after transfers\u0026quot;, async function () { const initialOwnerBalance = await hardhatToken.balanceOf(owner.address); // 将100个代币从所有者转移到 addr1 await hardhatToken.transfer(addr1.address, 100); // 将另外50个代币从所有者转移到addr2 await hardhatToken.transfer(addr2.address, 50); // 检查余额 const finalOwnerBalance = await hardhatToken.balanceOf(owner.address); expect(finalOwnerBalance).to.equal(initialOwnerBalance.sub(150)); const addr1Balance = await hardhatToken.balanceOf(addr1.address); expect(addr1Balance).to.equal(100); const addr2Balance = await hardhatToken.balanceOf(addr2.address); expect(addr2Balance).to.equal(50); }); }); }); 这就是npx hardhat test完整测试套件的输出，是这样的：\n$ npx hardhat test Token contract Deployment ✓ Should set the right owner ✓ Should assign the total supply of tokens to the owner Transactions ✓ Should transfer tokens between accounts (199ms) ✓ Should fail if sender doesn’t have enough tokens ✓ Should update balances after transfers (111ms) 5 passing (1s) 请记住，当你运行npx hardhat test时，如果你的合约自上次运行测试以来发生更改，则将编译它们。\n0x6 使用 Hardhat 网络进行调试 Hardhat 内置了Hardhat 网络，这是一个专为开发而设计的本地以太坊网络。它允许你部署合约、运行测试和调试代码。这是 Hardhat 连接的默认网络，因此你无需进行任何设置即可使其正常工作。只需运行你的测试。\nSolidity console.log 在 Hardhat 网络上运行合约和测试时，你可以在 Solidity 代码中使用console.log()来打印日志消息与合约变量。要使用它，你必须在你的合约代码中导入 hardhat/console.sol。\npragma solidity ^0.8.0; import \u0026quot;hardhat/console.sol\u0026quot;; contract Token { //... } 像在 JavaScript 中使用console.log那样在transfer()函数添加一些内容：\nfunction transfer(address to, uint256 amount) external { console.log(\u0026quot;Sender balance is %s tokens\u0026quot;, balances[msg.sender]); console.log(\u0026quot;Trying to send %s tokens to %s\u0026quot;, amount, to); require(balances[msg.sender] \u0026gt;= amount, \u0026quot;Not enough tokens\u0026quot;); balances[msg.sender] -= amount; balances[to] += amount; } 运行测试时将显示日志输出：\n$ npx hardhat test Token contract Deployment ✓ Should set the right owner ✓ Should assign the total supply of tokens to the owner Transactions Sender balance is 1000 tokens Trying to send 50 tokens to 0xead9c93b79ae7c1591b1fb5323bd777e86e150d4 Sender balance is 50 tokens Trying to send 50 tokens to 0xe5904695748fe4a84b40b3fc79de2277660bd1d3 ✓ Should transfer tokens between accounts (373ms) ✓ Should fail if sender doesn’t have enough tokens Sender balance is 1000 tokens Trying to send 100 tokens to 0xead9c93b79ae7c1591b1fb5323bd777e86e150d4 Sender balance is 900 tokens Trying to send 100 tokens to 0xe5904695748fe4a84b40b3fc79de2277660bd1d3 ✓ Should update balances after transfers (187ms) 5 passing (2s) 查看文档以了解有关此功能的更多信息。\n0x7 部署到真实网络 一旦你准备好与其他人分享你的 dApp，你可能想要做的就是部署到真实的网络。这样，其他人就可以访问你的 dApp了。\n涉及真钱交易的以太坊网络，被称为“mainnet”，然而还有其他不与真钱交易的网络，但却能很好的模拟现实世界的场景，也可以被其他人访问的网络称为“testnets”。以太坊有多个测试网:Ropsten、Kovan、Rinkeby和Goerli。我们建议将合约部署到 Ropsten 测试网。\n在软件层面，部署到测试网与部署到主网是一样的。唯一的区别是你连接到哪个网络。让我们看看使用ether.js部署合约的代码是什么样子的。\n使用的主要概念是Signer、ContractFactory和Contract，我们在测试部分中解释过。与测试相比，没有什么新事情需要做，因为当在测试合约时，实际上是在向你的开发网络进行部署。这使得代码非常相似。\n让我们在项目根目录中创建一个新的目录 scripts，并将以下内容粘贴到deploy.js文件中：\nasync function main() { const [deployer] = await ethers.getSigners(); console.log(\u0026quot;Deploying contracts with the account:\u0026quot;, deployer.address); console.log(\u0026quot;Account balance:\u0026quot;, (await deployer.getBalance()).toString()); const Token = await ethers.getContractFactory(\u0026quot;Token\u0026quot;); const token = await Token.deploy(); console.log(\u0026quot;Token address:\u0026quot;, token.address); } main() .then(() =\u0026gt; process.exit(0)) .catch((error) =\u0026gt; { console.error(error); process.exit(1); 要在运行任何任务时指定 Hardhat 连接到特定的以太坊网络，可以使用--network参数。像这样：\nnpx hardhat run scripts/deploy.js --network \u0026lt;network-name\u0026gt; 在这种情况下，不带--network参数运行它会使代码针在Hardhat 网络的嵌入式实例运行，因此当 Hardhat 完成运行时，部署实际上会丢失，但测试我们的部署代码是否有效仍然很有用：\n$ npx hardhat run scripts/deploy.js Deploying contracts with the account: 0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266 Account balance: 10000000000000000000000 Token address: 0x5FbDB2315678afecb367f032d93F642f64180aa3 部署到远程网络 要部署到远程网络（例如主网或任何测试网），你需要在hardhat.config.js文件中添加一个network条目。我们将在此示例中使用 Ropsten，但你也可以以类似地方式添加任何网络：\nrequire(\u0026quot;@nomiclabs/hardhat-waffle\u0026quot;); // 登录https://www.alchemyapi.io，注册， // 在其仪表板中创建一个新的应用程序，并将“KEY”替换为其密钥 const ALCHEMY_API_KEY = \u0026quot;KEY\u0026quot;; // 从 Metamask 导出你的私钥，打开Metamask，并进入帐户详细信息\u0026gt;导出私钥 // 千万注意，永远不要把真实的Ether转到测试帐户 const ROPSTEN_PRIVATE_KEY = \u0026quot;YOUR ROPSTEN PRIVATE KEY\u0026quot;; module.exports = { solidity: \u0026quot;0.7.3\u0026quot;, networks: { ropsten: { url: `https://eth-ropsten.alchemyapi.io/v2/${ALCHEMY_API_KEY}`, accounts: [`${ROPSTEN_PRIVATE_KEY}`] } } }; 我们正在使用Alchemy，但指向任何以太坊节点或网关的url都可以工作。\n要部署在Ropsten网络上，你需要将Ropsten-ETH发送到将要进行部署的地址。你可以从测试网的水龙头上得到一些ETH，这是一种免费分发测试ETH的服务。这是Ropsten的一个水龙头，你必须在交易之前将Metamask的网络更改为Ropsten。 最后，运行：\nnpx hardhat run scripts/deploy.js --network ropsten 如果一切顺利，你应该会看到已部署的合约地址。\n0x8 模版项目 如果你想快速开始使用你的dApp，亦或者想通过前端查看整个项目，你可以使用以下demo项目库。 https://github.com/nomiclabs/hardhat-hackathon-boilerplate\n包括些什么 我们在本教程中使用的 Solidity 合约 使用 ethers.js 和 Waffle 的测试套件 使用 ethers.js 与合约交互的最小前端 Solidity 合约和测试 在 repo 的根目录中，您会找到我们通过本教程与合约一起构建的Hardhat项目。Token刷新你对它实现的记忆：\n代币的总供应量是固定的，无法更改 整个供应分配到部署合约的地址 任何人都可以收到代币 任何拥有至少一个代币的人都可以转移代币 代币是不可分割的。你可以转移 1、2、3 或 37 个代币，但不能转移 2.5 个 前端应用 你会发现一个简单的应用程序，frontend它允许用户做两件事：\n检查已连接钱包的余额 将代币发送到地址 这是一个单独的 npm 项目，它是使用create-react-app创建的，所以这意味着它使用了 webpack 和 babel。 前端文件架构 `src/``包含所有代码 src/components包含反应组件 Dapp.js是唯一具有业务逻辑的文件。如果你将其用作模版，你可以在此处用你自己的代码替换 其他所有组件都只呈现 HTML，没有逻辑。 src/contracts有合约的 ABI 和地址，这些是由部署脚本自动生成的 如何使用它 首先克隆该库，然后部署合约：\ncd hardhat-hackathon-boilerplate npm install npx hardhat node 在这里，我们只安装 npm 项目的依赖项，并通过运行npx hardhat node启动一个Hardhat 网络实例，你可以使用 MetaMask 连接到该实例。在同一目录中的不同终端中，运行：\nnpx hardhat --network localhost run scripts/deploy.js 这会将合约部署到Hardhat网络。完成后运行：\ncd frontend npm install npm run start 启动react web app。打开http://localhost:3000/ ，你应该会看到： 在 MetaMask 中将你的网络设置为localhost:8545。 然后可能还需要配置 MetaMask 以与 Hardhat 配合使用。为此，请转到Settings -\u0026gt; Networks -\u0026gt; Localhost 8545并将链 ID 更改为 31337。\n现在单击 Web 应用程序中的按钮。然后你应该看到这个： 这里发生的情况是显示当前钱包余额的前端代码检测到余额为0，因此你将无法尝试转账功能。通过运行：\nnpx hardhat --network localhost faucet \u0026lt;your address\u0026gt; 这将运行我们包含在Hardhat中的自定义任务，该任务使用部署帐户的余额向你的地址发送 100 MBT 和 1 ETH。这将允许你将代币发送到另一个地址。 你可以查看/tasks/faucet.js中的任务代码。\n$ npx hardhat --network localhost faucet 0x0987a41e73e69f60c5071ce3c8f7e730f9a60f90 Transferred 1 ETH and 100 tokens to 0x0987a41e73e69f60c5071ce3c8f7e730f9a60f90 在你运行npx hardhat node的终端中，你也应该看到:\neth_sendTransaction Contract call: Token#transfer Transaction: 0x460526d98b86f7886cd0f218d6618c96d27de7c745462ff8141973253e89b7d4 From: 0xc783df8a850f42e7f7e57013759c285caa701eb6 To: 0x7c2c195cd6d34b8f845992d380aadb2730bb9c6f Value: 0 ETH Gas used: 37098 of 185490 Block #8: 0x6b6cd29029b31f30158bfbd12faf2c4ac4263068fd12b6130f5655e70d1bc257 console.log: Transferring from 0xc783df8a850f42e7f7e57013759c285caa701eb6 to 0x0987a41e73e69f60c5071ce3c8f7e730f9a60f90 100 tokens 在我们的合约中显示transfer()函数的console.log输出，这是运行水龙头任务后web应用程序的样子: 试着调试它并阅读代码。它充满了注释，解释正在发生的事情，并清楚地表明哪些代码是以太坊模版代码，哪些实际上是dApp逻辑。这将使该项目易于为你的项目重用。\n0x9 结束语 恭喜你完成了本教程！ 以下是一些补充链接，让你更深入了解：\nHardhat\u0026rsquo;s Hackathon Boilerplate Hardhat\u0026rsquo;s documentation site Hardhat Support Discord server Ethers.js Documentation Waffle Documentation Mocha Documentation Chai Documentation ","id":13,"section":"posts","summary":"0x1 概述 我在入门以太坊智能合约开发时，首先我就面临了一个选择，Hardhat Vs Truffle Vs Remix，我应该选择哪个开发工具。我就在谷歌上搜索很多对比","tags":["Hardhat","智能合约","以太坊","Solidity"],"title":"使用 Hardhat 入门以太坊智能合约","uri":"https://www.ganymedenil.com/2022/03/03/getting-started-with-ethereum-smart-contracts-with-hardhat.html","year":"2022"},{"content":"最近一直在研究 NFT 在此分享所学，以及对该技术的展望。part 1 主要跟大家分享什么是 NFT，区块链和NFT的关系，加密货币、区块链和NFT中的争议。\n什么是 NFT 简而言之，NFT 是由区块链支持的数字代币——跟比特币没有实质区别。但是，NFT 也代表了一个独特的数字文件，这个数字文件通常表现为视觉艺术品、GIF、音频文件或者其他类似的形式。\n另一种思考方式是，NFT是将数字艺术品、视频或者音频通过类似加密货币一样的技术方式语区块链相关联。虽然同一个加密货币在技术上都是独一无二的，但他们的价值相同（以比特币为例，假设在同一时间你拥有的1个btc和我拥有的1个btc在价值体系上并没有区别）。NFT 可能由相同的区块链支持，但在大多数情况下，它们的价值是不同的，就像它们是独特的艺术品一样。\n就像艺术品一样，数字NFT艺术品不会有一个你可以查询的 \u0026ldquo;价格\u0026rdquo;，就像你可以查询一个比特币的价格那样。你的NFT的购买价格会有一个记录，但如果你想知道你现在能得到多少钱，你必须把它拍卖掉或以其他方式出售它。(也会有一些与某些艺术家有关的经验法则，专家们将能够预估相应的价格。例如，一幅早期的萨尔瓦多-达利的油画通常能卖到多少钱？或者晚期的塞尚？艺术界的专家将能够提供非常有根据的猜测，但在画作真正出售之前，我们仍然无法确定）。\n将NFT视为 \u0026ldquo;独特的数字艺术作品，如绘画或视频 \u0026ldquo;是必要的，但并不充分。这就是说，艺术界是 NFT 似乎首先 \u0026ldquo;突破 \u0026ldquo;的地方。但正如你在本文后面所看到的，在各种行业中都会有大量的数字表现形式的应用，它们享有与区块链绑定的所有好处。\n音乐家凯西斯普纳在NFT上发布音乐视频\n当我购买NFT时，我到底在买什么 当大多数人问这个问题时，他们又指的是作为数字艺术作品的NFT，所以让我们从这里开始。\n购买NFT的艺术收藏家购买的是由区块链支持的独特而安全的数字代币，代表该数字艺术作品的所有权。简单地说，你得到一个数字文件。该文件包含艺术品的副本，而且它也与区块链挂钩。\n看上去很简单，对吗？但是，正如你所想象的那样，将NFT艺术品简化为这些细节，有点忽略了要点。当你了解并购买NFT时，你的行为就已存储到区块链上，并成为NFT本身的一部分，这一点就变得很明显。\n换句话说，当你购买NFT时，你购买的是你已经购买了NFT这一事实。你这样做的事实在该NFT的历史上永远是安全的，而且这个事实作为区块链的一部分，可以被任何人在任何地方核实。\n你拥有这个数字文件。你永远拥有它（或至少在你出售它之前）。而区块链上的任何人将能够在任何时候验证这一事实。\n这引出了另一个问题：当你买了NFT时，你没有买到什么？\n好吧，你并不拥有该作品的著作权；该版权仍然属于创作者/艺术家。 （如果你除了购买 NFT 之外的版权，那么你也会拥有这些东西。但是，大多数 NFT 艺术品的购买者不会这样做。）购买 NFT 更像是购买具有唯一序列号的数字艺术品。有多少像您这样的 NFT 由艺术家或创作者决定。 一个很好的类比可能是限量版棒球卡、手表或一幅画的印刷品。 您的可能是“1/100”或“1/1”。 重要的是——就像棒球卡、手表或印刷品一样——它是独一无二的，仍然可以升值，仍然可以出售，仍然可以交易。它还具有由区块链支持的真实性的独特优势。\n这是一种新的不同类型的艺术收藏吗？绝对的。但是，当它第一次出现时，一切都很重要。 请记住：拥有 NFT 并不比传统艺术形式“更好”或“更糟”。 它们是一种完全拥有艺术的新方式。\n当代艺术家村上隆 (Takashi Murakami) 探索了 NFT 的许多方面，包括对艺术家的版权影响\n我的 NFT 在“哪里”，我如何才能看到它 从技术上讲，你的 NFT 将存在于服务器支持的区块链上。 只要区块链存在，你的 NFT 就会存在。\n对于采用静止图像或视频剪辑形式的 NFT，您可以在任何屏幕或设备上查看 NFT。 人们如何“看到”你的 NFT 很大程度上取决于你。\n但仅仅因为 NFT 无法挂在你房子的墙上，并不意味着它不会是你的，或者不安全。（如果你愿意，它可以挂在你的墙上，并且可以通过电视屏幕等方式看到。）相反，你的 NFT 艺术品实际上可能是你拥有的最安全的东西。 它几乎肯定是你拥有的最安全的艺术品。 正如我们所见，由于 NFT 中的区块链技术确实将作品的历史烙印在作品上，因此可以立即知道身份验证和出处。 即使对油画进行碳年代测定，再加上训练有素的艺术历史学家的敏锐眼光，赝品仍然可以冒充真品。 （或者，一幅被盗的画作可能在经历了一系列可疑的所有权之后，在数年之后才被“发现”。）但是当一件艺术品是 NFT 时，这种可能性就完全消除了。\nNFT 将在区块链上\u0026quot;存在\u0026rdquo;，但它也将是你的，无论你想如何展示它。\n那么，我们是如何从区块链到NFT艺术的 NFT 是从 Beeple 开始的吗？ 当然不是。 找到 NFT 的确切起源可能有些困难。 独特的数字项目已经存在了几年。 但是，这些独特的数字项目是什么时候从商品跨越到“艺术”的呢？\n当然，这引出了一个更大的问题：\u0026ldquo;什么是艺术？\u0026ldquo;对此，并没有简单的答案。数字货币\u0026ndash;如 NFT 之前的比特币\u0026ndash;能算作艺术吗？\n事实上，也许它们可以。\n钱在艺术中使用(或作为)艺术品已经很多次了，一些艺术家只是把成堆的实物货币作为艺术品在画廊展出。2017年，艺术家Danai Anesiadou 将一公斤黄金密封在塑料中，并宣布它是一件艺术品。回到1994年，比尔·德拉蒙德(Bill Drummond)和吉米·考蒂(Jimmy Cauty)表演了一件“艺术品”，他们在一场大火中烧掉了价值100万英镑的钞票。\n在 NFT 之前，数字货币的形式是否已经起到了艺术的作用？ 这是可能的。 （这也是艺术史学家在未来几年肯定会争论的问题。）然而，该领域的大多数人都同意，数字 NFT 艺术的第一批真正作品可能是 CryptoPunks，紧随其后的是 CryptoKitties，它于 2017 年 11 月下旬首发。CryptoKitties 是 （现在仍然是）基于以太坊的区块链游戏，允许用户收集和繁殖数字猫。 通过强大的 CryptoKitties 在线社区，用户可以创建自己独特的猫——它们作为 NFT 永远存在——并相互交易和出售。 在推出的第一周内，CryptoKitties 的用户购买了超过 100 万美元的这些数字猫图像！\nLarva Labs 的 CryptoPunks已经卖出了数百万美元。\n虽然作为大规模艺术革命的始作俑者，网上的猫可能看起来有点不严肃，但人们购买这些猫的原因与任何人购买美术品的原因一样。这些图像很好看。购买它们很有趣。你可以从它们身上赚钱，因为你购买的是一种升值的资产。这是一种显示你 \u0026ldquo;了解 \u0026ldquo;和 \u0026ldquo;有文化\u0026rdquo;（或至少是 \u0026ldquo;网上有文化\u0026rdquo;）的方式。这也是一种表达自己兴趣的方式，同时在经济上支持艺术家。\nCryptoKitties 还显示了 NFT 艺术的一个决定性和革命性的特点，即几乎任何财富水平的收藏家都可以得到它。价格最适中的CryptoKitty NFT 起价仅为12美元。\n意识到这些猫 NFT 只是收集数字艺术的伟大交响乐的开始，开发者迅速开始创建在线市场，在那里可以买卖 NFT，并且新进入这个领域的艺术家可以将他们的作品变成NFT。2018年，SuperRare、OpenSea、Nifty Gateway 和 MakersPlace 等多个 NFT 市场启动并运行。\n在大多数情况下，这些 NFT 市场通过从每个出售的 NFT 中抽取一定比例来赚钱。作为回报，他们将 NFT 置于买家眼前，并促进交易。\n随着这些在线市场的兴起，更多的玩家开始参与其中。在 CryptoKitties 之后加入 NFT 领域的最著名的实体之一是 NBA 出售比赛亮点的官方平台——NBA Top Shot。在其上半年的运营中，NBA Top Shot 已经完成了大约 4 亿美元的业务！\nNBA Top Shot 的成功很重要，因为它表明，如果这意味着他们可以以一种令人兴奋的新方式参与到他们最喜爱的运动中，那么一群可能不喜欢技术的球迷也会采取措施成为这样的人。另一个类似的例子是摇滚乐队 Kings of Leon 在 2021 年初发行了一张专辑作为音频 NFT。他们的歌迷愿意向 NFT 迈进，这张专辑为乐队带来了数百万美元的收入。\n从区块链到 NFT 的故事也可以从 NFT 改变艺术品收藏作为一种金融风险的本质上看出来，尤其是当涉及到作品如何转售的时候。举一个突出的例子，一群自称 Metapurse 的艺术收藏家在 2021 年 1 月购买了 Beeple 的 20 件 NFT 艺术品。然后他们将这些作品的所有权分割成代币，然后将这些代币出售给公众。成千上万的人购买了它们。按照撰写本文时代币的价值计算，这 20 件艺术品现在的价值增加了大约 6 倍。\n所以现在，当我们看到区块链以新的方式与技术连接时，我们似乎处在一个充满无限机会和持续创新的时刻。\n至少就目前而言，对 NFT 产品的需求似乎无穷无尽。事实证明，即使是可能不喜欢“技术”的粉丝群也愿意跃跃欲试使用 NFT。但随着这一成功，NFT 下一步将走向何方的合理问题也随之而来。艺术家们不断尝试可以虚拟创作的新艺术形式。开发人员正在考虑还有什么可以虚拟出售（或作为 NFT 出售）。例如，虚拟 NFT 房地产市场蓬勃发展。你可能无法在现实生活中拥有豪宅，但现在用户可以在虚拟世界中购买豪宅。我们还看到收藏家争先恐后地找出展示他们的 NFT 的最佳方式。企业也在这样做，因为他们希望开发和推出自己独特的 NFT 产品。当你拥有产品时，你希望将其展示在客户的眼前。但是谁是你的客户，他们将如何找到你的 NFT？这就是我们仍在弄清楚的。\n从这个不断发展的格局中，已经出现了一条可靠的智慧:不要反对 NFT。那些认为 NFT 只在小圈子中流行这已被认为是错误的。那些声称只有在科技行业工作的人才会购买 NFT 的人也显然是错误的。还有那些声称 NFT 永远不会在大拍卖行以数百万美元的价格出售的人?你猜对了;也错了。\nnft接下来要突破什么壁垒?虽然没有人能确切地预测未来，但在本文的后面，我们将确定 NFT 下一步可能飞速发展的最佳候选者。\n在遥远的未来，有一天，在一个 NFT 如此普遍以至于几乎不会引起人们惊讶的市场，我们可能会愉快地回顾，知道这一切似乎都始于可收藏的数字猫。\n在加密货币、区块链和NFT中，是否存在任何有争议的领域 在区块链技术上我们已经看到了相当多的怀疑和批评。在这一点上，我想我们应该习惯了！\n从一开始，新的发明和创新就引起了人们对陌生产品的困惑。在一些不幸的案例中，这为消费者在购买时并不完全了解他们所购买的产品——甚至是彻头彻尾的欺诈行为奠定了基础。\n好消息是每个人都越来越熟悉区块链支持的技术，包括那些可能并不处于技术前沿（或根本不了解技术）的人。区块链是什么以及它是如何工作的，这些要点正在被传开。每个人都听说过比特币——这是一个好的开始——即使他们不知道它是如何工作的或如何购买它。虽然仍然存在误传的可能性，但是越来越多的受过教育的消费者基础意味着，区块链技术不再那么令人困惑。\n更好的消息是，当涉及到 NFT 时，他们独特的技术为他们的前辈所经历的许多批评提供了强有力的反击。\n例如，像比特币这样的加密货币长期以来一直因其能源消耗和碳足迹而受到批评。在“现实世界”中，甚至无法握持或触摸的数字硬币如何产生碳足迹？答案是：因为比特币通过挖矿来维护其区块链，矿工总是需要电力来为进行挖矿的计算机供电。随着比特币的增长——越来越多的硬币被开采——开采成本不断上升。剑桥大学于 2021 年初发表的一项研究报告称，在全球范围内，比特币挖矿现在每年消耗的电力大约与阿根廷国家一样多。所有这些能源的使用引发了对碳排放的担忧，并提高了比特币的碳足迹。可惜的是，为比特币挖矿提供动力的大部分能源还不是来自可再生能源（尽管比特币爱好者承诺这种情况很快就会改变）。好消息是，当代 NFT 的生产方式与比特币这类在环境影响上相比，只有很小的一部分（同样，稍后会详细介绍。）如果它们以正确的方式推出，NFT 将不会像比特币那样消耗能源。\n对区块链产品的其他批评来自于启用 \u0026ldquo;抽水和倾倒 \u0026ldquo;计划，或推出没有价值的加密货币以故意欺骗新来者的计划。例如，随着比特币的价值在2010年初开始缓慢但稳定地增长，加密货币市场充斥着每周推出的新 \u0026ldquo;币\u0026rdquo;。这些新币的许多创造者只是为了赚快钱。为了赚快钱，他们可能会推出一种毫无意义的噱头有关的加密货币\u0026ndash;\u0026ldquo;为鹦鹉爱好者提供的新的代币，每个有鹦鹉的人都会想用它！\u0026rdquo;\u0026ndash;然后会有10亿个币被发行。一半将在加密货币交易所出售，但另一半将由该币的创造者保留。例如，如果该新币的价值仅为1美分，那么该币的创造者可以出售他的5亿枚鹦鹉币，凭空获得2000万美元，然后离开。币持有者（和各地的鹦鹉爱好者）会感到被愚弄和利用了。\n但与艺术作品、标志性图像和其他独特而有意义的内容相关的 NFT 呈现出一种全新的安排，并消除了创作者寻求快速匿名“兑现”的可能性。 这是一个完全不同的主张。 所有权链清晰。 那些出售 NFT 的人是在透明的环境中这样做的。 潜在买家可以研究卖家是谁，并可以真正了解所提供的产品。 作为 NFT 购买的物品的价值、完整性和唯一性得到保证。\n其他争议领域也因侵犯版权而引起。这几乎是所有视觉媒体中的一个问题。虽然侵犯版权在 NFT 艺术领域似乎很少见，但还是有一些记录在案的案例。例如，在 2021 年初，CNN 和 VICE 都报道了艺术家声称有人复制了他们的一件原创数字艺术作品，并在未经许可的情况下将其作为 NFT 出售。发生这种情况时，原艺术家将被迫提出版权主张。随着待售 NFT 的数量呈指数级增长，此类违规行为可能会继续发生。然而，好消息是，由于该技术是数字化的，因此 1) 报告犯罪行为，2) 定位不良行为者，以及 3) 确保适当处理有问题的 NFT 会容易得多。当艺术家声称他们的作品在现实世界中未经许可被复制和出售时，可能会有大量（缓慢而乏味的）工作来确定到底涉及谁以及所有不适当的复制品在哪里。在数字世界中，这种问题——一旦用户意识到它——可以更快地解决，并且任何非法工作的位置都不会成为问题。与此同时，视觉艺术家的安全性将继续发展，以防止不当使用。 （例如，当在他们自己的网站上展示他们的作品时，许多视觉艺术家现在使用一个“浮动横幅”，总是遮住他们作品的一小部分。这可以防止它被数字化捕获。）\n总而言之，区块链技术受到批评并不新鲜。 然而，对加密货币等技术的最早批评者已经逐渐被证明是错误的。 现在对 NFT 的批评很少，远没有加密货币所面临的那么令人生畏，并且有充分的理由相信不断发展的技术将使我们能够解决我们前进过程中可能出现的任何问题。\n总结 在撰写本文时，大多数人在想到 NFT 时仍在考虑视觉艺术的数字作品——这完全没问题——但是，正如我在本文中要明确指出的那样，这种化身只是触及了技术将使之成为可能。此刻正在进行大规模行动，以扩大 NFT 的能力。它们发生在我们看不到的地方，但它们绝对存在。世界各地的企业和创作者都在急于为艺术和商业领域的 NFT 新世界做好准备。\nNFT 是数字文件，因此几乎任何以数字方式传输的东西都可以是 NFT。例如，音乐会门票或机票可以是 NFT。数字折扣码可以是 NFT。数字收据可以是 NFT。实用的 NFT 将有助于培养品牌、创作者和消费者之间的关系。\n当谈到数字物品时，问题真的不是“什么可以是 NFT？”而是“有什么不能成为 NFT 的吗？”\n正如很难想象一个没有无处不在的互联网或智能手机的世界一样，很快我们就很难回忆起 NFT 出现之前的时代。势头正在增强，而且不会消失。\n我们首先在艺术界看到它，是的——据《时代》杂志报道，在 2021 年前两个月，近 2.5 亿美元用于 NFT，不包括 Beeple 在佳士得的创纪录拍卖——但整个经济已经开始发展以支持将 NFT 整合到我们生活的其他领域、其他产品、其他服务。\n有些企业可以帮助创作者“铸造”他们的 NFT，还有一些平台可以帮助销售 NFT，也有一些平台可以帮助艺术家和投资者了解这些数字作品的合理价格，还有一些顾问可以帮助收藏家策划他们的收藏。\n奢侈品牌正在问自己，奢侈品购买如何包含 NFT，然后“解锁”更多高端体验、独特服务、获得新商品发布、合作等。体育公司正准备在 NFT 推动下的数字空间中实现大规模增长。各种面向客户的公司都准备在数字区块链的某个地方直接与那些未来的客户建立联系。\n企业开始意识到 NFT 的重要性。随着人们趋向于 \u0026ldquo;真迹 \u0026ldquo;和 \u0026ldquo;真实\u0026rdquo;，买家将越来越希望拥有某物的真实和独特版本。正如独特性存在于物理世界一样，它现在也将存在于数字世界中。\n随着每天有越来越多的人发现这种形式，要想 \u0026ldquo;把牙膏放回管子里 \u0026ldquo;几乎是不可能的了。NFT 将继续存在。\n在下一节中，我们将探讨企业和品牌正在创造的 NFT 的类型，并看看我们可以期望这些 NFT 在哪里创造最大的机会。\n参考 The Comprehensive Guide to NFTs, Digital Artwork, and Blockchain Technology NFT Art and Collectables for Beginners: The Must Have Guide for Understanding Non Fungible Tokens NFT FOR BEGINNERS: The Simple Guide for Understand Non-Fungible Tokens and Economically Exploit the New Digital El Dorado. Learn How to Monetize Them Like Bitcoin. The Nft Revolution - Crypto art edition: 2 in 1 practical guide for beginners to create, buy and sell digital artworks and collectibles as non-fungible tokens ","id":14,"section":"posts","summary":"\u003cp\u003e最近一直在研究 NFT 在此分享所学，以及对该技术的展望。part 1 主要跟大家分享什么是 NFT，区块链和NFT的关系，加密货币、区块链和NFT中的争议。\u003c/p\u003e","tags":["NFT"],"title":"NFT 数字艺术品  part 1","uri":"https://www.ganymedenil.com/2021/11/09/ntf-dabt-part-1.html","year":"2021"},{"content":"公司项目从 7.1 升级到 7.4 故对 php 升级文档进行整理与翻译。\n不向下兼容的变更 7.1.x -\u0026gt; 7.2.x 防止 number_format() 返回负零 之前版本中，number_format() 有可能会返回 -0。虽然这是符合 IEEE 754 规范的，但是这样会导致可读性不好，新版本中会将这样的负数去掉。\n\u0026lt;?php var_dump(number_format(-0.01)); // 新版本输出 string(1) \u0026quot;0\u0026quot; 旧版本输出 string(2) \u0026quot;-0\u0026quot; 转换对象和数组中的数字键 将数组转换为对象，或将对象转换为数组时，数字键现在得到了更好的处理（无论是通过显式转换还是通过 settype() 函数）。\n这意味着现在可以访问数组中的整数(或者说是字符串整数)键，这些键会映射到对象中：\n\u0026lt;?php // array to object $arr = [0 =\u0026gt; 1]; $obj = (object)$arr; var_dump( $obj, $obj-\u0026gt;{'0'}, // 新写法 $obj-\u0026gt;{0} // 新写法 ); 以上例程会输出：\nobject(stdClass)#1 (1) { [\u0026quot;0\u0026quot;]=\u0026gt; // string key now, rather than integer key int(1) } int(1) int(1) 从对象转换成的数组中的整数（或者说是字符串整数）键现在也可以直接访问：\n\u0026lt;?php // object to array $obj = new class { public function __construct() { $this-\u0026gt;{0} = 1; } }; $arr = (array)$obj; var_dump( $arr, $arr[0], // 新写法 $arr['0'] // 新写法 ); 以上例程会输出：\narray(1) { [0]=\u0026gt; // integer key now, rather than string key int(1) } int(1) int(1) get_class() 函数不再接受 null 参数 之前版本中，传递 null 给 get_class() 函数将返回当前类名。在新版本中，此行为会抛出一个 E_WARNING 错误。如果想实现与之前版本同样的效果，请不要传递任何参数进来。\n计算非可数类型（non-countable）时发出警告 对非可数类型调用 count()（或 sizeof()）函数，会抛出一个 E_WARNING 错误。\n\u0026lt;?php var_dump( count(null), // NULL is not countable count(1), // integers are not countable count('abc'), // strings are not countable count(new stdclass), // objects not implementing the Countable interface are not countable count([1,2]) // arrays are countable ); 以上例程会输出：\nWarning: count(): Parameter must be an array or an object that implements Countable in %s on line %d Warning: count(): Parameter must be an array or an object that implements Countable in %s on line %d Warning: count(): Parameter must be an array or an object that implements Countable in %s on line %d Warning: count(): Parameter must be an array or an object that implements Countable in %s on line %d int(0) int(1) int(1) int(1) int(2) ext/hash 从资源变成对象 作为摆脱资源长期迁移的一部分，Hash 扩展已被更新为使用对象而不是资源。对于 PHP 开发者来说，这一变化应该是无缝的，除了is_resource()（需要更新为is_object()）。\nSSL/TLS 的默认选项的改进 下列默认选项被修改：\ntls:// 默认为 TLSv1.0 or TLSv1.1 or TLSv1.2 ssl:// 成为 tls:// 的别名 STREAM_CRYPTO_METHOD_TLS_* 常量默认为 TLSv1.0 或 TLSv1.1 + TLSv1.2，替代之前的 TLSv1.0 gettype() 在闭包资源中的返回值 之前版本中，如果在一个闭包资源中使用 gettype() 会返回字符串 \u0026ldquo;unknown type\u0026rdquo;，现在将会返回字符 \u0026ldquo;resource (closed)\u0026quot;。\nis_object() 和 __PHP_Incomplete_Class 之前版本中，对 __PHP_Incomplete_Class 调用 is_object() 函数会返回 false，现在会返回 true。\n提升未定义常量的错误级别 调用未定义的常量，现在会抛出一个 E_WARNING 错误(之前版本中为 E_NOTICE)。在下一个 PHP 大版本中，将会抛出一个 Error 错误。\nWindows 支持 官方支持的最低 Windows 版本为 Windows 7/Server 2008 R2。\n检查 traits 的默认属性值 对默认 traits 属性值的兼容性检查将不再执行强制转换。\nobject 保留字的变化 object 在之前的 PHP 7.0 版本 中被声明为软保留字（soft-reserved）。现在变更为强制保留字，禁止在任何类或接口中使用该名称。\nNetWare 支持 NetWare 已不再被支持。\n具有SORT_STRING 的 array_unique() 虽然先前使用 SORT_STRING 的 array_unique() 复制了数组并删除了非唯一元素（此后不打包数组），但现在通过添加唯一元素来构建新数组。 这可能会导致不同的数字索引。\nbcmod() 浮动数的变化 bcmod() 函数不再将小数截断为整数。 因此，它的行为现在遵循fmod()方法，而不是 % 运算符。 例如 bcmod（\u0026lsquo;4\u0026rsquo;，\u0026lsquo;3.5\u0026rsquo;）现在返回0.5而不是1。\n哈希函数和非加密哈希值 hash_hmac()、hash_hmac_file()、hash_pbkdf2()和hash_init()（带HASH_HMAC）函数不再接受非加密的哈希值。\njson_decode() 函数变更 json_decode()函数选项JSON_OBJECT_AS_ARRAY现在在第二个参数（assoc）为 null 时作为默认参数。以前，JSON_OBJECT_AS_ARRAY总是被忽略。\nrand() 和 mt_rand() 输出 由 rand() 和 mt_rand() 作为特定种子生成的序列可能与64位计算机上的 PHP7.1 不同（由于修复了实现中的一个模数偏差错误）。\nsql.safe_mode ini 选项移除 sql.safe_mode ini 设置项已被移除。\n对 date_parse() 和 date_parse_from_format() 的更改 date_parse() 和 date_parse_from_format() 返回的数组中的zone元素现在代表秒而不是分钟，其符号也被颠倒了。例如，-120现在是7200。\n接收到的 Cookies 从 PHP 7.2.34 开始，为了安全起见，接受到的 Cookie 中的 names 参数不再被 URL 编码。\n7.2.x -\u0026gt; 7.3.x Heredoc / Nowdoc 结尾标签解释 由于引入了灵活的 heredoc / nowdoc 语法，因此在正文中包含结尾标签的doc字符串可能会导致语法错误或解释更改。 例如在:\n\u0026lt;?php $str = \u0026lt;\u0026lt;\u0026lt;FOO abcdefg FOO FOO; ?\u0026gt; 缩进的 FOO 以前没有任何特殊含义。现在它将被解释为 heredoc 字符串的结尾，后面的 FOO; 将导致语法错误。这个问题可以通过选择一个不在字符串内容中出现的结束标签来解决。\nSwitch 结构中 Continue 问题的警告 针对 switch 控制流结构中的 continue 语句现在会产生一个警告。在 PHP 中，这种 continue 语句等同于 break，而在其他语言中则表现为 continue 2。\n\u0026lt;?php while ($foo) { switch ($bar) { case \u0026quot;baz\u0026quot;: continue; // Warning: \u0026quot;continue\u0026quot; targeting switch is equivalent to // \u0026quot;break\u0026quot;. Did you mean to use \u0026quot;continue 2\u0026quot;? } } ?\u0026gt; 严格解释 ArrayAccess 上的整数字符串键 对 $obj[“123”] 类型的数组访问，其中$obj实现了 ArrayAccess 并且 “123” 是整数字符串文本，这将不再进行隐式转换为整数，即 $obj-\u0026gt;offsetGet(“123”) 将不能通过 $obj-\u0026gt;offsetGet(123) 调用。 对于 non-literals 这符合现有行为。 数组的行为不会受到任何影响，它们会继续将整数字符串键隐式转换为整数。\n静态属性不再由引用赋值来分隔 在PHP中，静态属性在继承的类之间共享，除非在子类中显式覆盖了静态属性。 但是，由于存在实施构件(implementation artifact)，因此可以通过分配引用来分离静态属性。 此漏洞已得到修复。\n\u0026lt;?php class Test { public static $x = 0; } class Test2 extends Test { } Test2::$x = \u0026amp;$x; $x = 1; var_dump(Test::$x, Test2::$x); // Previously: int(0), int(1) // Now: int(1), int(1) ?\u0026gt; 数组和属性访问返回的引用将立即展开 现在，将数组和属性访问返回的引用展开为访问的一部分。 这意味着不再可能在访问和使用访问值之间修改引用：\n\u0026lt;?php $arr = [1]; $ref =\u0026amp; $arr[0]; var_dump($arr[0] + ($arr[0] = 2)); // Previously: int(4), Now: int(3) ?\u0026gt; 这使引用和非引用的行为保持一致。请注意，读取和写入单个表达式中的一个值仍然是未定义行为，并可能在未来再次改变。\n不再支持具有非整数键的遍历器的参数解包 对于非整数键的遍历器，参数解包停止工作。以下代码在PHP 5.6-7.2中意外地工作。\n\u0026lt;?php function foo(...$args) { var_dump($args); } function gen() { yield 1.23 =\u0026gt; 123; } foo(...gen()); ?\u0026gt; 杂项 ext_skel工具已经被完全重新设计，增加了新的选项并删除了一些旧的选项。现在它是用PHP编写的，没有任何外部依赖性。\n对 BeOS 的支持已经被放弃。\n由于在 EH_THROW 模式下将警告自动转换为异常而抛出的异常（例如一些DateTime异常）不再填充 error_get_last() 状态。因此，它们现在与手动抛出的异常的工作方式相同。\nTypeError 现在将错误的类型分别报告为 int 和 bool，而不是integer 和 boolean。\n传递给 compact() 的未定义变量现在将被报告为 notice。\ngetimagesize() 和相关函数现在将 BMP 图像的 mime 类型报告为 image/bmp，而不是image/x-ms-bmp，因为前者已经在 IANA注册（参见 RFC 7903）。\nstream_socket_get_name() 现在将返回括在方括号中的IPv6地址。例如，将返回“[::1]:1337”而不是“::1:1337”。\nBCMath 任意数学精度 由 BCMath 函数抛出的所有警告现在都使用了PHP 的错误处理。以前有些警告会直接写到 stderr。\nbcmul()和 bcpow()现在以所要求的比例返回数字。以前，返回的数字可能遗漏了小数点后的零。\nIMAP、POP3和NNTP rsh/ssh登录默认是禁用的。如果你想启用它们，请使用 imap.enable_insecure_rsh。请注意，IMAP库在将邮箱名称传递给rsh/ssh命令之前不会对其进行过滤，因此在启用rsh/ssh的情况下将不受信任的数据传递给这个函数是不安全的。\n多字节字符串 由于增加了对命名捕获的支持，使用命名捕获的 mb_ereg_*() 模式的行为将有所不同。特别是命名捕获将成为匹配的一部分，并且 mb_ereg_replace() 将解释额外的语法。更多信息，请参见命名捕获（Named Captures）。\nMySQL改进后的扩展 预备语句现在可以正确地报告DATETIME、TIME和TIMESTAMP列的小数秒数（例如，当使用微秒时，TIMESTAMP(6)）。以前，小数秒部分只是在返回值中被省略。\nMySQL函数 (PDO_MYSQL) 预备语句现在可以正确地报告DATETIME、TIME和TIMESTAMP列的小数秒数（例如，当使用微秒时，TIMESTAMP(6)）。以前，小数秒部分只是从返回值中省略。请注意，这只影响到PDO_MYSQL在关闭模拟准备时的使用（例如，使用本地准备功能）。使用具有PDO::ATTR_EMULATE_PREPARES=true（这是默认的）的连接的语句不受错误修复的影响，并且已经从引擎中获得了正确的小数秒值。\n反射 反射导出到字符串现在分别使用 int 和 bool 而不是 integer 和 boolean。\n标准PHP库（SPL） 如果SPL自动加载器抛出一个异常，后面的自动加载器将不会被执行。以前，所有的自动加载器都被执行，而异常是连锁的。\nSimpleXML 现在，涉及 SimpleXML 对象的数学运算会将文本视为 int 或 float，以两者中较合适的一个为准。 以前，将值无条件地视为整数。\n接收到的 Cookies 从 PHP 7.2.34 开始，为了安全起见，接受到的 Cookie 中的 names 参数不再被 URL 编码。\n7.3.x -\u0026gt; 7.4.x 以数组形式访问非数组 尝试以数组方式访问 null，bool， int，float 或 resource （例如 $null[\u0026quot;key\u0026quot;]）将会抛出 notice 通知。\nget_declared_classes() 函数 get_declared_classes() 函数将不再返回匿名的类，假如它们没有被实例化的话。\nfn 关键词 fn 成为了保留关键词。需要特别注意，它不能再做为函数名或类名使用，但是仍然可以做为方法名和常量名存在。\n文件尾部的 \u0026lt;?php 标签 文件尾部的 \u0026lt;?php 标签（不包含空行）将会被解释成一个 PHP 头标签。以前，它被解释为一个短的开始标记，后跟原义php，并导致语法错误（short_open_tag = 1），或者被解释为原义\u0026lt;?php字符串（其中short_open_tag = 0）。\nStream wrappers 当在流上使用include/require时，streamWrapper::stream_set_option()将在调用STREAM_OPTION_READ_BUFFER选项时被调用。自定义流包装器的实现可能需要实现streamWrapper::stream_set_option()方法以避免警告（始终返回false即可实现）。\nSerialization 序列化 序列化类型 o 被移除。因为它不是由 PHP 生成的，这可能会影响到之前项目中手动生成的序列化字符串。\n密码算法常量 密码哈希算法标识符现在是可空字符串，而不再是整数。\nPASSWORD_DEFAULT 之前是 int 1; 现在是 null PASSWORD_BCRYPT 之前是 int 1; 现在是 string \u0026lsquo;2y\u0026rsquo; PASSWORD_ARGON2I 之前是 int 2; 现在是 string \u0026lsquo;argon2i\u0026rsquo; PASSWORD_ARGON2ID 之前是 int 3; 现在是 string \u0026lsquo;argon2id\u0026rsquo; 应用中如果正常使用了常量 PASSWORD_DEFAULT，PASSWORD_BCRYPT，PASSWORD_ARGON2I 和 PASSWORD_ARGON2ID 将不会受到影响。\nhtmlentities() 函数 如果htmlentities()被用于只支持基本实体替换的编码，它现在会引发一个通知（而不是严格的标准警告），在这种情况下，它等同于htmlspecialchars()。\nfread() and fwrite() 函数 fread() 和 fwrite() 在操作失败的时候会返回 false。之前的版本中会返回空字符串或 0。EAGAIN/EWOULDBLOCK 不视为故障。\n这些函数现在也会在失败时发出 NOTICE 通知，例如当试图写入一个只读文件资源时。\nBCMath 任意数学精度 BCMath函数现在会在传递非格式化的数字时发出警告，例如 \u0026ldquo;32foo\u0026rdquo;。该参数将被解释为零，和以前一样。\nCURL 现在尝试序列化CURLFile类将生成一个异常。 以前，该异常仅在未序列化时抛出。\n不建议使用CURLPIPE_HTTP1，从cURL 7.62.0开始不再支持。\n不推荐使用curl_version()的$ version参数。 如果传递了不等于默认CURLVERSION_NOW的任何值，则会引发警告并忽略该参数。\nDate 和 Time 在DateTime或DateTimeImmutable实例上调用var_dump()或类似的方法，将不再留下该对象的可访问属性。\nDateInterval 对象的比较（使用 ==, \u0026lt; 等）现在将产生一个警告，并且总是返回 false。以前，所有的DateInterval对象都被认为是相等的，除非它们有属性。\nIntl idn_to_ascii() 和 idn_to_utf8() 的默认参数值现在是 INTL_IDNA_VARIANT_UTS46，而不是被废弃的 INTL_IDNA_VARIANT_2003。\nMySQLi 嵌入式服务器功能已被删除。 至少从PHP 7.0起就被破坏了。\n取而代之的是mysqli::stat()，删除了未公开的mysqli::$stat属性。\nOpenSSL 现在，openssl_random_pseudo_bytes()函数将在错误情况下引发异常，类似于random_bytes()。 特别是，如果请求的字节数小于或等于零，则引发Error；如果无法收集足够的随机性，则引发Exception。 如果函数不抛出，则保证$crypto_strong输出参数始终为true，因此无需进行显式检查。\n正则表达式（与Perl兼容） 使用PREG_UNMATCHED_AS_NULL模式时，尾部未匹配的捕获组现在也将被设置为 null（如果启用了偏移捕获，则为[null，-1]）。 这意味着$matches的大小将始终相同。\nPHP Data Objects 试图序列化一个PDO或PDOStatement实例现在将产生一个异常，而不是PDOException，这与其他不支持序列化的内部类一致。\n反射 如果试图对反射对象进行序列化，现在会产生一个异常。反射对象的序列化从来没有被支持过，并且会导致反射对象的损坏。现在它已被明确禁止。\n标准PHP库（SPL） 在 ArrayObject 实例上调用 get_object_vars() 现在将总是返回 ArrayObject 本身（或一个子类）的属性。以前，除非指定 ArrayObject::STD_PROP_LIST 标志，否则它会返回被包装的数组/对象的值。\n其他受影响的操作是:\nReflectionObject::getProperties() reset(), current(), 等等。使用Iterator方法代替。 潜在的其他工作对象属性为一个列表。\n（array）的转换不受影响。 它们将继续返回包装的数组或ArrayObject属性，具体取决于是否使用ArrayObject::STD_PROP_LIST标志。\n如果传递零，则SplPriorityQueue::setExtractFlags()将引发异常。 以前，这将在下一次提取操作中产生可恢复的致命错误。\n现在，除了Serializable接口之外，ArrayObject，ArrayIterator，SplDoublyLinkedList和SplObjectStorage还支持__serialize（）和__unserialize（）机制。 这意味着在较旧的PHP版本上创建的序列化有效负载仍然可以反序列化，但是较旧的版本将无法理解由PHP 7.4创建的新有效负载。\nTokenizer token_get_all() 现在将为意外字符发出T_BAD_CHARACTER令牌，而不是在令牌流中留下漏洞。\n接收到的 Cookies 从 PHP 7.4.11 开始，为了安全考虑，接受到的 Cookie 中的 names 参数不再被 URL 编码。\n废弃的功能 7.1.x -\u0026gt; 7.2.x 不带引号的字符串 不带引号的字符串是不存在的全局常量，转化成他们自身的字符串。 在以前，该行为会产生 E_NOTICE，但现在会产生 E_WARNING。在下一个 PHP 主版本中，将抛出 Error 异常。\n\u0026lt;?php var_dump(NONEXISTENT); /* Output: Warning: Use of undefined constant NONEXISTENT - assumed 'NONEXISTENT' (this will throw an Error in a future version of PHP) in %s on line %d string(11) \u0026quot;NONEXISTENT\u0026quot; */ png2wbmp() 和 jpeg2wbmp() GD 扩展内的 png2wbmp() 和 jpeg2wbmp() 现已被废弃，将在下一个 PHP 主版本中移除。\nINTL_IDNA_VARIANT_2003 转化 Intl 扩展废弃了 INTL_IDNA_VARIANT_2003 转化，为idn_to_ascii() 和 idn_to_utf8() 的默认选项。 PHP 7.4 会把默认值设置为 INTL_IDNA_VARIANT_UTS46， 并在下一个 PHP 主版本中完全移除 INTL_IDNA_VARIANT_2003\n__autoload() 方法 __autoload() 方法已被废弃， 因为和 spl_autoload_register() 相比功能较差 (因为无法链式处理多个 autoloader)， 而且也无法在两种 autoloading 样式中配合使用。\ntrack_errors ini 设置和 $php_errormsg 变量 当开启了 track_errors ini 设置，出现非致命错误时， 会在本地作用域创建 $php_errormsg 变量。 由于提供了更好的方式： error_get_last() 来获取此类错误信息，该功能被废弃。\ncreate_function() 函数 考虑到此函数的安全隐患问题（它是 eval() 的瘦包装器），该过时的函数现在已被废弃。 更好的选择是匿名函数。\nmbstring.func_overload ini 设置 由于此设置会影响环境中的字符串系列函数，带来相互操作中的问题，它现在已被废弃。\n(unset) 类型强制转化 转化任意表达式为此类型，结果总是 null，所以这个多余的类型转化现在也就被废弃了。\nparse_str() 不加第二个参数 使用 parse_str() 时，不加第二个参数会导致查询字符串参数导入当前符号表。 考虑到安全隐患问题，不加第二个参数使用 parse_str() 的行为已被废弃。 此函数的第二个选项为必填项，它使查询字符串转为 Array。\ngmp_random() 函数 此函数基于未知的、取决于平台的 limb 尺寸产生随机数。因此，该函数已被废弃。 使用更好的方式产生随机数： GMP 扩展中的 gmp_random_bits() 和 gmp_random_range()。\neach() 函数 使用此函数遍历时，比普通的 foreach 更慢， 并且给新语法的变化带来实现问题。因此它被废弃了。\nassert() 一个字符串参数 assert() 字符串参数将要求它能被 eval() 执行。 考虑到可能被执行远程代码，废弃了字符串的 assert()，最好提供 bool 的表达式。\n错误处理器内的 $errcontext 参数 $errcontext 参数包含了错误网站的所有本地变量。 考虑到它很少被用到，而且还会导致内部优化问题，它现在被废弃了。 代替用法：调试器应该自己取回错误站点的本地变量。\nread_exif_data() 函数 read_exif_data() 别名已被废弃 使用 exif_read_data() 函数代替。\n7.2.x -\u0026gt; 7.3.x 大小写不敏感的常量 大小写不敏感的常量声明现已被废弃。将 true 作为第三个参数传递给 define() 将会导致一个废弃警告。大小写不敏感的使用（在读取时使用一个与声明时不同的大小写方式）也已被废弃。\n命名空间中的 assert() 废弃：在一个命名空间中声明一个名为 assert() 的函数。 assert() 函数属于引擎特殊处理的情况，当在命名空间中使用相同名字去定义 函数时也许会导致不一致的行为。\n在字符串中搜索非字符串内容 废弃：将一个非字符串内容传递给字符串搜索函数。 在将来所有待搜索的内容都将被视为字符串，而不是 ASCII 编码值。如果需要依赖这个特性，你应该 要么显示地进行类型转换（转为字符串），或者显示地调用 chr()。 以下是受到影响的方法：\nstrpos() strrpos() stripos() strripos() strstr() strchr() strrchr() stristr() Strip-Tags Streaming fgetss() 函数和 string.strip_tags stream filter 已经被废弃。这同样影响了 SplFileObject::fgetss() 方法和 gzgetss() 函数。\nData Filtering 对于 FILTER_FLAG_SCHEME_REQUIRED 和 FILTER_FLAG_HOST_REQUIRED 常量的显示使用已被废弃。 总之，FILTER_VALIDATE_URL 已经隐含了这两者。\n图像处理和 GD 库 image2wbmp() 已被废弃。\n国际化相关函数 如果 PHP 关联的ICU ≥ 56, 那么 Normalizer::NONE 形式的使用将会导致抛出一个废弃警告。\n多字节字符串 以下在文档中不存在的 mbereg_() 别名已被废弃。请使用相应的 mb_ereg_() 变体替代。\nmbregex_encoding() mbereg() mberegi() mbereg_replace() mberegi_replace() mbsplit() mbereg_match() mbereg_search() mbereg_search_pos() mbereg_search_regs() mbereg_search_init() mbereg_search_getregs() mbereg_search_getpos() mbereg_search_setpos() ODBC 和 DB2 函数 (PDO_ODBC) pdo_odbc.db2_instance_name ini 设置项在先前已被废弃。 它在文档中自 PHP 5.1.1 起被废弃\n7.3.x -\u0026gt; 7.4.x 没有显式括号的嵌套三元运算符 嵌套的三元操作中，必须明确使用显式括号来决定操作的顺序。以前，如果不使用括号，在大多数情况下，左关联性不会导致预期的行为。\n\u0026lt;?php 1 ? 2 : 3 ? 4 : 5; // deprecated (1 ? 2 : 3) ? 4 : 5; // ok 1 ? 2 : (3 ? 4 : 5); // ok ?\u0026gt; 大括号访问数组和字符串索引 使用大括号访问数组及字符串索引的方式已被废弃。请使用 $var[$idx] 的语法来替代 $var{$idx}。\n(real) 类型和 is_real() 函数 (real) 类型已被废弃，请使用 (float) 来替代。\n同时被废弃的还有 is_real() 函数，请使用 is_float() 来替代。\n当$this被使用时，解除对$this的绑定 不建议使用$this的非静态闭包解除$this的绑定。\nparent 关键词在没父类的类中使用 在没有父类的类中使用 parent 关键词已被废弃，并且在将来的 PHP 版本中将会抛出一个编译错误。目前只在运行时访问父类时才会产生错误。\nallow_url_include INI 选项 配置文件中的 allow_url_include 选项被废弃。如果启用了该选项，将会产生一个弃用通知。\n基础转换函数中的无效字符处理 在下面这些基础转换函数中，base_convert(), bindec(), octdec() 和 hexdec() 如果传入了非法字符，将会抛出一个弃用通知。函数会忽略掉无效字符后正常返回结果。前导空格和尾部空格，以及类型为 0x (取决于基数) 被允许传入。\n在对象中使用 array_key_exists() 在一个对象中使用 array_key_exists() 已被废弃。请使用 isset() 或 property_exists() 来替代。\n魔术引号函数 魔术引号函数 get_magic_quotes_gpc() 和 get_magic_quotes_runtime() 已被废弃。它们将永远返回 false。\nhebrevc() 函数 hebrevc() 函数已被废弃。 可以用 nl2br(hebrev($str)) 来替代，更好的方法是启用 Unicode RTL 来支持。\nconvert_cyr_string() 函数 convert_cyr_string() 函数已被废弃。可以用 mb_convert_string()， iconv() 或 UConverter 替代。\nmoney_format() 函数 money_format() 函数已被废弃。 可以用更国际化的 NumberFormatter 功能来替代。\nezmlm_hash() 函数 ezmlm_hash() 函数已被废弃。\nrestore_include_path() 函数 restore_include_path() 函数已被废弃。可以用 ini_restore(\u0026lsquo;include_path\u0026rsquo;) 替代。\nImplode 函数的参数顺序 implode() 允许反转参数顺序的特性已被废弃，请使用 implode($glue, $parts) 来替代 implode($parts, $glue)。\nCOM 导入类型库的大小写不敏感的常量注册已被废弃。\nFilter FILTER_SANITIZE_MAGIC_QUOTES 已被废弃，使用 FILTER_SANITIZE_ADD_SLASHES 来替代。\n多字节字符串 向 mb_ereg_replace() 传递非字符串模式已被废弃。目前，非字符串模式被解释为 ASCII 代码点。在 PHP 8 中，模式将被解释为一个字符串。\n将编码作为第三参数传递给 mb_strrpos() 已被废弃。取而代之的是传递一个 0 偏移量，并将编码作为第四个参数。\nLightweight Directory Access Protocol ldap_control_paged_result_response() 和 ldap_control_paged_result() 函数已被废弃。控制页面操作可以使用 ldap_search() 替代。\n反射 调用 ReflectionType::__toString() 现在将会抛出一个弃用通知。 该方法从 PHP 7.1 开始，在 ReflectionNamedType::getName() 的文档中已经被声明废弃，但是由于技术原因，并没有抛出弃用通知。\n所有Reflection类的export()方法已被废弃。构建一个Reflection对象并将其转换为字符串。\n\u0026lt;?php // ReflectionClass::export(Foo::class, false) is: echo new ReflectionClass(Foo::class), \u0026quot;\\n\u0026quot;; // $str = ReflectionClass::export(Foo::class, true) is: $str = (string) new ReflectionClass(Foo::class); ?\u0026gt; Socket 常量 AI_IDN_ALLOW_UNASSIGNED 和 AI_IDN_USE_STD3_ASCII_RULES 在 socket_addrinfo_lookup() 中不再可用，因为该常量在 glibc 中已被废弃。\n","id":15,"section":"posts","summary":"\u003cp\u003e公司项目从 7.1 升级到 7.4 故对 php 升级文档进行整理与翻译。\u003c/p\u003e","tags":["php"],"title":"PHP 7.1 升级至 7.4","uri":"https://www.ganymedenil.com/2021/04/28/php71-to-php74.html","year":"2021"},{"content":"行为型解决的是不同对象之间的通信挑战。它们描述了不同的对象和类之间如何相互发送消息以使事情发生。\n以下是我们归类为行为型的模式列表。\n责任链模式 命令模式 解析器模式 迭代器模式 中介者模式 备忘录模式 观察者模式 状态模式 策略模式 模板方法模式 访问者模式 责任链模式 责任链模式通过使一个以上的对象以链式方式处理请求，将请求的发送方与接收方解耦。各种类型的处理对象可以动态地添加到链中。使用递归组成链，可以实现无限数量的处理对象。\n下面是一个责任链模式的实现例子。\nabstract class SocialNotifier { private $notifyNext = null; public function notifyNext(SocialNotifier $notifier) { $this-\u0026gt;notifyNext = $notifier; return $this-\u0026gt;notifyNext; } final public function push($message) { $this-\u0026gt;publish($message); if ($this-\u0026gt;notifyNext !== null) { $this-\u0026gt;notifyNext-\u0026gt;push($message); } } abstract protected function publish($message); } class TwitterSocialNotifier extends SocialNotifier { public function publish($message) { // Implementation... } } class FacebookSocialNotifier extends SocialNotifier { protected function publish($message) { // Implementation... } } class PinterestSocialNotifier extends SocialNotifier { protected function publish($message) { // Implementation... } } // Client $notifier = new TwitterSocialNotifier(); $notifier-\u0026gt;notifyNext(new FacebookSocialNotifier()) -\u0026gt;notifyNext(new PinterestSocialNotifier()); $notifier-\u0026gt;push('Awesome new product available!'); 我们首先创建了一个抽象的SocialNotifier类，并实现了抽象方法publish、notifyNext和push方法。然后我们定义了TwitterSocialNotifier、FacebookSocialNotifier和PinterestSocialNotifier，它们都是对抽象SocialNotifier的扩展。客户端首先实例化TwitterSocialNotifier，然后是两次notifyNext调用，在调用最后的push方法之前，向它传递另外两个notifier类型的实例。\n命令模式 命令模式将执行某些操作的对象与知道如何使用它的对象解耦。它通过封装以后执行某个操作所需的所有相关信息来实现。这意味着对象、方法名和方法参数的信息。\n下面是一个命令模式的实现例子。\ninterface LightBulbCommand { public function execute(); } class LightBulbControl { public function turnOn() { echo 'LightBulb turnOn'; } public function turnOff() { echo 'LightBulb turnOff'; } } class TurnOnLightBulb implements LightBulbCommand { private $lightBulbControl; public function __construct(LightBulbControl $lightBulbControl) { $this-\u0026gt;lightBulbControl = $lightBulbControl; } public function execute() { $this-\u0026gt;lightBulbControl-\u0026gt;turnOn(); } } class TurnOffLightBulb implements LightBulbCommand { private $lightBulbControl; public function __construct(LightBulbControl $lightBulbControl) { $this-\u0026gt;lightBulbControl = $lightBulbControl; } public function execute() { $this-\u0026gt;lightBulbControl-\u0026gt;turnOff(); } } // Client $command = new TurnOffLightBulb(new LightBulbControl()); $command-\u0026gt;execute(); 我们首先创建一个LightBulbCommand接口。然后我们定义了LightBulbControl类，它提供了两个简单的turnOn/turnOff方法。然后，我们定义了TurnOnLightBulb和TurnOffLightBulb类，它们实现了LightBulbCommand接口。最后，客户端是用LightBulbControl的实例实例化TurnOffLightBulb对象，并对其调用执行方法。\n解析器模式 解释器模式规定了如何评价语言语法或表达式。我们在定义解释器的同时，也定义了语言语法的表示方法。语言语法的表示使用复合类层次结构，其中规则被映射到类。然后，解释器使用表示法来解释语言中的表达式。\n下面是一个解释器模式实现的例子。\ninterface MathExpression { public function interpret(array $values); } class Variable implements MathExpression { private $char; public function __construct($char) { $this-\u0026gt;char = $char; } public function interpret(array $values) { return $values[$this-\u0026gt;char]; } } class Literal implements MathExpression { private $value; public function __construct($value) { $this-\u0026gt;value = $value; } public function interpret(array $values) { return $this-\u0026gt;value; } } class Sum implements MathExpression { private $x; private $y; public function __construct(MathExpression $x, MathExpression $y) { $this-\u0026gt;x = $x; $this-\u0026gt;y = $y; } public function interpret(array $values) { return $this-\u0026gt;x-\u0026gt;interpret($values) + $this-\u0026gt;y-\u0026gt;interpret($values); } } class Product implements MathExpression { private $x; private $y; public function __construct(MathExpression $x, MathExpression $y) { $this-\u0026gt;x = $x; $this-\u0026gt;y = $y; } public function interpret(array $values) { return $this-\u0026gt;x-\u0026gt;interpret($values) * $this-\u0026gt;y-\u0026gt;interpret($values); } } // Client $expression = new Product( new Literal(5), new Sum( new Variable('c'), new Literal(2) ) ); echo $expression-\u0026gt;interpret(array('c' =\u0026gt; 3)); // 25 我们首先创建一个MathExpression接口，有一个 interpret 方法。然后我们添加Variable、Literal、Sum和Product类，所有这些类都实现了MathExpression接口。然后，客户端从Product类中实例化，将Literal和Sum的实例传递给它，并以一个 interpret 方法调用结束。\n迭代器模式 迭代器模式用于遍历一个容器并访问其元素。换句话说，一个类可以遍历另一个类的元素。PHP对迭代器有一个本地支持，作为内置的\\Iterator和\\IteratorAggregate接口的一部分。\n下面是一个迭代器模式实现的例子。\nclass ProductIterator implements \\Iterator { private $position = 0; private $productsCollection; public function __construct(ProductCollection $productsCollection) { $this-\u0026gt;productsCollection = $productsCollection; } public function current() { return $this-\u0026gt;productsCollection-\u0026gt;getProduct($this-\u0026gt;position); } public function key() { return $this-\u0026gt;position; } public function next() { $this-\u0026gt;position++; } public function rewind() { $this-\u0026gt;position = 0; } public function valid() { return !is_null($this-\u0026gt;productsCollection-\u0026gt;getProduct($this-\u0026gt;position)); } } class ProductCollection implements \\IteratorAggregate { private $products = array(); public function getIterator() { return new ProductIterator($this); } public function addProduct($string) { $this-\u0026gt;products[] = $string; } public function getProduct($key) { if (isset($this-\u0026gt;products[$key])) { return $this-\u0026gt;products[$key]; } return null; } public function isEmpty() { return empty($products); } } $products = new ProductCollection(); $products-\u0026gt;addProduct('T-Shirt Red'); $products-\u0026gt;addProduct('T-Shirt Blue'); $products-\u0026gt;addProduct('T-Shirt Green'); $products-\u0026gt;addProduct('T-Shirt Yellow'); foreach ($products as $product) { var_dump($product); } 首先创建了一个ProductIterator，它实现了标准的PHP \\Iterator接口，然后我们添加了ProductCollection，它实现了标准的PHP \\IteratorAggregate接口。客户端创建了一个ProductCollection的实例，通过addProduct方法调用将值堆积到其中，并循环浏览整个集合。\n中介者模式 我们的软件中的类越多，它们的通信就越复杂。中介者模式通过将其封装成一个中介者对象来解决这种复杂性。对象不再直接通信，而是通过中介对象进行通信，因此降低了整体的耦合度。\n下面是一个中介者模式实现的例子。\ninterface MediatorInterface { public function fight(); public function talk(); public function registerA(ColleagueA $a); public function registerB(ColleagueB $b); } class ConcreteMediator implements MediatorInterface { protected $talk; // ColleagueA protected $fight; // ColleagueB public function registerA(ColleagueA $a) { $this-\u0026gt;talk = $a; } public function registerB(ColleagueB $b) { $this-\u0026gt;fight = $b; } public function fight() { echo 'fighting...'; } public function talk() { echo 'talking...'; } } abstract class Colleague { protected $mediator; // MediatorInterface public abstract function doSomething(); } class ColleagueA extends Colleague { public function __construct(MediatorInterface $mediator) { $this-\u0026gt;mediator = $mediator; $this-\u0026gt;mediator-\u0026gt;registerA($this); } public function doSomething() { $this-\u0026gt;mediator-\u0026gt;talk(); } } class ColleagueB extends Colleague { public function __construct(MediatorInterface $mediator) { $this-\u0026gt;mediator = $mediator; $this-\u0026gt;mediator-\u0026gt;registerB($this); } public function doSomething() { $this-\u0026gt;mediator-\u0026gt;fight(); } } // Client $mediator = new ConcreteMediator(); $talkColleague = new ColleagueA($mediator); $fightColleague = new ColleagueB($mediator); $talkColleague-\u0026gt;doSomething(); $fightColleague-\u0026gt;doSomething(); 我们首先创建了一个带有多个方法的MediatorInterface，由ConcreteMediator类实现。然后，我们定义了抽象类Colleague，强制在下面的ColleagueA和ColleagueB类上实现doSomething方法。客户端首先实例化ConcreteMediator，并将其实例传递给ColleagueA和ColleagueB的实例，并根据这些实例调用doSomething方法。\n备忘录模式 备忘录模式提供了对象还原功能。通过三个不同的对象来实现：originator、caretaker和memento，其中originator是保存以后还原所需的内部状态的对象。\n以下是备忘录模式实现的一个例子。\nclass Memento { private $state; public function __construct($state) { $this-\u0026gt;state = $state; } public function getState() { return $this-\u0026gt;state; } } class Originator { private $state; public function setState($state) { return $this-\u0026gt;state = $state; } public function getState() { return $this-\u0026gt;state; } public function saveToMemento() { return new Memento($this-\u0026gt;state); } public function restoreFromMemento(Memento $memento) { $this-\u0026gt;state = $memento-\u0026gt;getState(); } } // Client - Caretaker $savedStates = array(); $originator = new Originator(); $originator-\u0026gt;setState('new'); $originator-\u0026gt;setState('pending'); $savedStates[] = $originator-\u0026gt;saveToMemento(); $originator-\u0026gt;setState('processing'); $savedStates[] = $originator-\u0026gt;saveToMemento(); $originator-\u0026gt;setState('complete'); $originator-\u0026gt;restoreFromMemento($savedStates[1]); echo $originator-\u0026gt;getState(); // processing 我们首先创建一个Memento类，它将通过getState方法提供对象的当前状态。然后我们定义了Originator类，将状态推送给Memento。最后，客户端通过实例化Originator来扮演 caretaker 的角色，在它的几个状态之间进行杂耍，从Memento中保存和恢复这些状态。\n观察者模式 观察者模式实现了对象之间一对多的依赖关系。持有依赖列表的对象被称为subject，而依赖者被称为observer。当subject对象改变状态时，所有的依赖对象都会得到通知并自动更新。\n下面是一个观察者模式的实现例子。\nclass Customer implements \\SplSubject { protected $data = array(); protected $observers = array(); public function attach(\\SplObserver $observer) { $this-\u0026gt;observers[] = $observer; } public function detach(\\SplObserver $observer) { $index = array_search($observer, $this-\u0026gt;observers); if ($index !== false) { unset($this-\u0026gt;observers[$index]); } } public function notify() { foreach ($this-\u0026gt;observers as $observer) { $observer-\u0026gt;update($this); echo 'observer updated'; } } public function __set($name, $value) { $this-\u0026gt;data[$name] = $value; // notify the observers, that user has been updated $this-\u0026gt;notify(); } } class CustomerObserver implements \\SplObserver { public function update(\\SplSubject $subject) { /* Implementation... */ } } // Client $user = new Customer(); $customerObserver = new CustomerObserver(); $user-\u0026gt;attach($customerObserver); $user-\u0026gt;name = 'John Doe'; $user-\u0026gt;email = 'john.doe@fake.mail'; 我们首先创建一个Customer类，它实现了标准的PHP \\SplSubject接口。然后我们定义了CustomerObserver类，它实现了标准的PHP \\SplObserver接口。最后，客户端实例化Customer和CustomerObserver对象，并将CustomerObserver对象附加到Customer上。任何对姓名和电子邮件属性的改变都会被观察者捕获。\n状态模式 状态模式封装了同一对象根据其内部状态而产生的不同行为，使对象看起来像是改变了它的类。\n下面是一个状态模式的实现例子。\ninterface Statelike { public function writeName(StateContext $context, $name); } class StateLowerCase implements Statelike { public function writeName(StateContext $context, $name) { echo strtolower($name); $context-\u0026gt;setState(new StateMultipleUpperCase()); } } class StateMultipleUpperCase implements Statelike { private $count = 0; public function writeName(StateContext $context, $name) { $this-\u0026gt;count++; echo strtoupper($name); /* Change state after two invocations */ if ($this-\u0026gt;count \u0026gt; 1) { $context-\u0026gt;setState(new StateLowerCase()); } } } class StateContext { private $state; public function setState(Statelike $state) { $this-\u0026gt;state = $state; } public function writeName($name) { $this-\u0026gt;state-\u0026gt;writeName($this, $name); } } // Client $stateContext = new StateContext(); $stateContext-\u0026gt;setState(new StateLowerCase()); $stateContext-\u0026gt;writeName('Monday'); $stateContext-\u0026gt;writeName('Tuesday'); $stateContext-\u0026gt;writeName('Wednesday'); $stateContext-\u0026gt;writeName('Thursday'); $stateContext-\u0026gt;writeName('Friday'); $stateContext-\u0026gt;writeName('Saturday'); $stateContext-\u0026gt;writeName('Sunday'); 我们首先创建了一个Statelike接口，然后是实现该接口的StateLowerCase和StateMultipleUpperCase。StateMultipleUpperCase在它的writeName中加入了一点计数逻辑，所以它在两次调用之后就会启动新的状态。然后我们定义了StateContext类，我们将用它来切换上下文。最后，客户端实例化StateContext，并通过setState方法将StateLowerCase的一个实例传递给它，然后是几个writeName方法。\n策略模式 策略模式定义了一个算法家族，每个算法都被封装起来，并可与该家族中的其他成员互换。\n下面是一个策略模式的实现例子。\ninterface PaymentStrategy { public function pay($amount); } class StripePayment implements PaymentStrategy { public function pay($amount) { echo 'StripePayment...'; } } class PayPalPayment implements PaymentStrategy { public function pay($amount) { echo 'PayPalPayment...'; } } class Checkout { private $amount = 0; public function __construct($amount = 0) { $this-\u0026gt;amount = $amount; } public function capturePayment() { if ($this-\u0026gt;amount \u0026gt; 99.99) { $payment = new PayPalPayment(); } else { $payment = new StripePayment(); } $payment-\u0026gt;pay($this-\u0026gt;amount); } } $checkout = new Checkout(49.99); $checkout-\u0026gt;capturePayment(); // StripePayment... $checkout = new Checkout(199.99); $checkout-\u0026gt;capturePayment(); // PayPalPayment... 我们首先创建了一个PaymentStrategy接口，然后是实现它的具体类StripePayment和PayPalPayment。然后我们定义了Checkout类，并在capturePayment方法中加入了一些决策逻辑。最后，客户端实例化Checkout，通过其构造函数传递一定的金额。根据金额，Checkout内部在调用capturePayment时，会触发一个或另一个付款。\n模板方法模式 模板方法模式在方法中定义了算法的程序骨架。它让我们通过使用类重载，重新定义算法的某些步骤，而不真正改变算法的结构。\n下面是一个模板方法模式实现的例子。\nabstract class Game { private $playersCount; abstract function initializeGame(); abstract function makePlay($player); abstract function endOfGame(); abstract function printWinner(); public function playOneGame($playersCount) { $this-\u0026gt;playersCount = $playersCount; $this-\u0026gt;initializeGame(); $j = 0; while (!$this-\u0026gt;endOfGame()) { $this-\u0026gt;makePlay($j); $j = ($j + 1) % $playersCount; } $this-\u0026gt;printWinner(); } } class Monopoly extends Game { public function initializeGame() { // Implementation... } public function makePlay($player) { // Implementation... } public function endOfGame() { // Implementation... } public function printWinner() { // Implementation... } } class Chess extends Game { public function initializeGame() { // Implementation... } public function makePlay($player) { // Implementation... } public function endOfGame() { // Implementation... } public function printWinner() { // Implementation... } } $game = new Chess(); $game-\u0026gt;playOneGame(2); $game = new Monopoly(); $game-\u0026gt;playOneGame(4); 我们首先创建了一个抽象的Game类，该类提供了所有封装游戏玩法的实际抽象方法。然后我们定义了Monopoly和Chess类，这两个类都是由Game类扩展而来，为每个类实现了特定的游戏方法game-play。客户端只需实例化Monopoly和Chess对象，对每个对象调用playOneGame方法。\n访问者模式 访问者模式是一种将算法与其操作的对象结构分离的方法。因此，我们能够在现有的对象结构上添加新的操作，而不实际修改这些结构。\n下面是一个访问者模式的实现例子。\ninterface RoleVisitorInterface { public function visitUser(User $role); public function visitGroup(Group $role); } class RolePrintVisitor implements RoleVisitorInterface { public function visitGroup(Group $role) { echo 'Role: ' . $role-\u0026gt;getName(); } public function visitUser(User $role) { echo 'Role: ' . $role-\u0026gt;getName(); } } abstract class Role { public function accept(RoleVisitorInterface $visitor) { $klass = get_called_class(); preg_match('#([^\\\\\\\\]+)$#', $klass, $extract); $visitingMethod = 'visit' . $extract[1]; if (!method_exists(__NAMESPACE__ . '\\RoleVisitorInterface', $visitingMethod)) { throw new \\InvalidArgumentException(\u0026quot;The visitor you provide cannot visit a $klass instance\u0026quot;); } call_user_func(array($visitor, $visitingMethod), $this); } } class User extends Role { protected $name; public function __construct($name) { $this-\u0026gt;name = (string)$name; } public function getName() { return 'User ' . $this-\u0026gt;name; } } class Group extends Role { protected $name; public function __construct($name) { $this-\u0026gt;name = (string)$name; } public function getName() { return 'Group: ' . $this-\u0026gt;name; } } $group = new Group('my group'); $user = new User('my user'); $visitor = new RolePrintVisitor; $group-\u0026gt;accept($visitor); $user-\u0026gt;accept($visitor); 我们首先创建一个RoleVisitorInterface，然后是RolePrintVisitor，它实现了RoleVisitorInterface本身。然后我们定义了一个抽象类Role，它有一个接受方法来接受RoleVisitorInterface的参数类型。我们进一步定义了具体的User和Group类，这两个类都是从Role扩展而来的。客户端实例化User、Group和RolePrintVisitor；将 visitor 传入User和Group实例的accept方法调用。\n更多文章内容请参见\nhttps://github.com/AnyStudy/PHP-7-Real-World-Application-Development\n如果对您有所帮助希望您能点以下 star\n","id":16,"section":"posts","summary":"\u003cp\u003e行为型解决的是不同对象之间的通信挑战。它们描述了不同的对象和类之间如何相互发送消息以使事情发生。\u003c/p\u003e","tags":["php"],"title":"使用 PHP 7 实现 GoF 设计模式之行为型","uri":"https://www.ganymedenil.com/2021/01/09/php7-gof-behavioral-patterns.html","year":"2021"},{"content":"结构型处理的是类和对象的组成。利用接口或抽象类和方法，它们定义了组成对象的方法，进而获得新的功能。\n以下是我们归类为结构型的模式列表。\n适配器模式 桥接模式 组合模式 装饰器模式 门面模式 享元模式 代理模式 有关结构型的更多信息，请参见https://en.wikipedia.org/wiki/Structural_pattern。\n适配器模式 适配器模式允许从另一个接口使用现有类的接口，基本上是通过将一个类的接口转换为另一个类所期望的接口，帮助两个不兼容的接口一起工作。\n下面是一个适配器模式的实现例子。\nclass Stripe { public function capturePayment($amount) { /* Implementation... */ } public function authorizeOnlyPayment($amount) { /* Implementation... */ } public function cancelAmount($amount) { /* Implementation... */ } } interface PaymentService { public function capture($amount); public function authorize($amount); public function cancel($amount); } class StripePaymentServiceAdapter implements PaymentService { private $stripe; public function __construct(Stripe $stripe) { $this-\u0026gt;stripe = $stripe; } public function capture($amount) { $this-\u0026gt;stripe-\u0026gt;capturePayment($amount); } public function authorize($amount) { $this-\u0026gt;stripe-\u0026gt;authorizeOnlyPayment($amount); } public function cancel($amount) { $this-\u0026gt;stripe-\u0026gt;cancelAmount($amount); } } // Client $stripe = new StripePaymentServiceAdapter(new Stripe()); $stripe-\u0026gt;authorize(49.99); $stripe-\u0026gt;capture(19.99); $stripe-\u0026gt;cancel(9.99); 我们首先创建一个具体的Stripe类。然后我们定义了PaymentService接口与一些基本的支付处理方法。StripePaymentServiceAdapter实现了PaymentService接口，提供了支付处理方法的具体实现。最后，客户端实例化StripePaymentServiceAdapter并执行支付处理方法。\n桥接模式 当我们想把一个类或抽象从它的实现中解耦出来时，就会用到桥接模式，让它们都能独立地改变。当类和它的实现经常变化时，这很有用。\n下面是一个桥模式实现的例子。\ninterface MailerInterface { public function setSender(MessagingInterface $sender); public function send($body); } abstract class Mailer implements MailerInterface { protected $sender; public function setSender(MessagingInterface $sender) { $this-\u0026gt;sender = $sender; } } class PHPMailer extends Mailer { public function send($body) { $body .= \u0026quot;\\n\\n Sent from a phpmailer.\u0026quot;; return $this-\u0026gt;sender-\u0026gt;send($body); } } class SwiftMailer extends Mailer { public function send($body) { $body .= \u0026quot;\\n\\n Sent from a SwiftMailer.\u0026quot;; return $this-\u0026gt;sender-\u0026gt;send($body); } } interface MessagingInterface { public function send($body); } class TextMessage implements MessagingInterface { public function send($body) { echo 'TextMessage \u0026gt; send \u0026gt; $body: ' . $body; } } class HtmlMessage implements MessagingInterface { public function send($body) { echo 'HtmlMessage \u0026gt; send \u0026gt; $body: ' . $body; } } // Client $phpmailer = new PHPMailer(); $phpmailer-\u0026gt;setSender(new TextMessage()); $phpmailer-\u0026gt;send('Hi!'); $swiftMailer = new SwiftMailer(); $swiftMailer-\u0026gt;setSender(new HtmlMessage()); $swiftMailer-\u0026gt;send('Hello!'); 我们首先创建一个MailerInterface。然后，具体的Mailer类实现了MailerInterface，为PHPMailer和SwiftMailer提供了一个基类。然后我们定义MessagingInterface，它由TextMessage和HtmlMessage类实现。最后，客户端实例化PHPMailer和SwiftMailer，在调用发送方法之前传递TextMessage和HtmlMessage的实例。\n组合模式 组合模式就是将对象的层次结构作为一个对象，通过一个公共接口来处理。其中，对象组成三个结构，客户端因为只消耗公共接口，所以对底层结构的变化一无所知。\n下面是一个组合模式的实现例子。\ninterface Graphic { public function draw(); } class CompositeGraphic implements Graphic { private $graphics = array(); public function add($graphic) { $objId = spl_object_hash($graphic); $this-\u0026gt;graphics[$objId] = $graphic; } public function remove($graphic) { $objId = spl_object_hash($graphic); unset($this-\u0026gt;graphics[$objId]); } public function draw() { foreach ($this-\u0026gt;graphics as $graphic) { $graphic-\u0026gt;draw(); } } } class Circle implements Graphic { public function draw() { echo 'draw-circle'; } } class Square implements Graphic { public function draw() { echo 'draw-square'; } } class Triangle implements Graphic { public function draw() { echo 'draw-triangle'; } } $circle = new Circle(); $square = new Square(); $triangle = new Triangle(); $compositeObj1 = new CompositeGraphic(); $compositeObj1-\u0026gt;add($circle); $compositeObj1-\u0026gt;add($triangle); $compositeObj1-\u0026gt;draw(); $compositeObj2 = new CompositeGraphic(); $compositeObj2-\u0026gt;add($circle); $compositeObj2-\u0026gt;add($square); $compositeObj2-\u0026gt;add($triangle); $compositeObj2-\u0026gt;remove($circle); $compositeObj2-\u0026gt;draw(); 我们首先创建了一个Graphic接口。然后我们创建了CompositeGraphic、Circle、Square和Triangle，它们都实现了Graphic接口。除了仅仅实现了Graphic接口中的draw方法外，CompositeGraphic还增加了两个方法，用于跟踪添加到它的图形的内部集合。然后客户端将这些Graphic类全部实例化，将它们全部添加到CompositeGraphic中，然后由CompositeGraphic调用draw方法。\n装饰器模式 装饰器模式允许将行为添加到单个对象实例中，而不影响同一类的其他实例的行为。我们可以定义多个装饰器，其中每个装饰器都会增加新的功能。\n下面是一个装饰器模式实现的例子。\ninterface LoggerInterface { public function log($message); } class Logger implements LoggerInterface { public function log($message) { file_put_contents('app.log', $message, FILE_APPEND); } } abstract class LoggerDecorator implements LoggerInterface { protected $logger; public function __construct(Logger $logger) { $this-\u0026gt;logger = $logger; } abstract public function log($message); } class ErrorLoggerDecorator extends LoggerDecorator { public function log($message) { $this-\u0026gt;logger-\u0026gt;log('ERROR: ' . $message); } } class WarningLoggerDecorator extends LoggerDecorator { public function log($message) { $this-\u0026gt;logger-\u0026gt;log('WARNING: ' . $message); } } class NoticeLoggerDecorator extends LoggerDecorator { public function log($message) { $this-\u0026gt;logger-\u0026gt;log('NOTICE: ' . $message); } } $logger = new Logger(); $logger-\u0026gt;log('Resource not found.'); $logger = new Logger(); $logger = new ErrorLoggerDecorator($logger); $logger-\u0026gt;log('Invalid user role.'); $logger = new Logger(); $logger = new WarningLoggerDecorator($logger); $logger-\u0026gt;log('Missing address parameters.'); $logger = new Logger(); $logger = new NoticeLoggerDecorator($logger); $logger-\u0026gt;log('Incorrect type provided.'); 我们首先创建了一个LoggerInterface，其中有一个简单的log方法，然后我们定义了Logger和LoggerDecorator，两者都实现了LoggerInterface。然后我们定义了Logger和LoggerDecorator，它们都是实现LoggerInterface的。其次是ErrorLoggerDecorator、WarningLoggerDecorator和NoticeLoggerDecorator，它们实现了LoggerDecorator。最后，客户端部分三次实例化Logger，传递给它不同的装饰器。\n门面模式 当我们想通过一个更简单的接口来简化大型系统的复杂性时，就会用到门面模式。它通过为大多数常见任务提供方便的方法，通过一个客户端使用的单一封装类来实现。\n下面是一个门面模式实现的例子。\nclass Product { public function getQty() { // Implementation } } class QuickOrderFacade { private $product = null; private $orderQty = null; public function __construct($product, $orderQty) { $this-\u0026gt;product = $product; $this-\u0026gt;orderQty = $orderQty; } public function generateOrder() { if ($this-\u0026gt;qtyCheck()) { $this-\u0026gt;addToCart(); $this-\u0026gt;calculateShipping(); $this-\u0026gt;applyDiscount(); $this-\u0026gt;placeOrder(); } } private function addToCart() { // Implementation... } private function qtyCheck() { if ($this-\u0026gt;product-\u0026gt;getQty() \u0026gt; $this-\u0026gt;orderQty) { return true; } else { return true; } } private function calculateShipping() { // Implementation... } private function applyDiscount() { // Implementation... } private function placeOrder() { // Implementation... } } // Client $order = new QuickOrderFacade(new Product(), $qty); $order-\u0026gt;generateOrder(); 我们首先创建一个Product类，并提供一个单一的getQty方法。然后，我们创建了一个QuickOrderFacade类，通过构造函数接受产品实例和数量，并进一步提供generateOrder方法，聚合所有的订单生成动作。最后，客户端实例化产品，将其传递给QuickOrderFacade的实例，对其调用generateOrder。\n享元模式 享元模式是关于性能和资源的减少，在相似的对象之间共享尽可能多的数据。这意味着在一个实现中，一个类的相同实例被共享。当预计要创建大量相同的类实例时，这种模式效果最好。\n下面是一个享元模式实现的例子。\ninterface Shape { public function draw(); } class Circle implements Shape { private $colour; private $radius; public function __construct($colour) { $this-\u0026gt;colour = $colour; } public function draw() { echo sprintf('Colour %s, radius %s.', $this-\u0026gt;colour, $this-\u0026gt;radius); } public function setRadius($radius) { $this-\u0026gt;radius = $radius; } } class ShapeFactory { private $circleMap; public function getCircle($colour) { if (!isset($this-\u0026gt;circleMap[$colour])) { $circle = new Circle($colour); $this-\u0026gt;circleMap[$colour] = $circle; } return $this-\u0026gt;circleMap[$colour]; } } // Client $shapeFactory = new ShapeFactory(); $circle = $shapeFactory-\u0026gt;getCircle('yellow'); $circle-\u0026gt;setRadius(10); $circle-\u0026gt;draw(); $shapeFactory = new ShapeFactory(); $circle = $shapeFactory-\u0026gt;getCircle('orange'); $circle-\u0026gt;setRadius(15); $circle-\u0026gt;draw(); $shapeFactory = new ShapeFactory(); $circle = $shapeFactory-\u0026gt;getCircle('yellow'); $circle-\u0026gt;setRadius(20); $circle-\u0026gt;draw(); 我们首先创建了一个Shape接口，有一个单一的 draw 方法。然后我们定义了实现Shape接口的Circle类，接着是ShapeFactory类。在ShapeFactory中，getCircle方法根据颜色选项返回一个新Circle的实例。最后，客户端实例化多个ShapeFactory对象，向getCircle方法调用传递不同的颜色。\n代理模式 代理模式的功能是作为一个原始对象的幕后接口。它可以作为一个简单的转发包装器，甚至可以围绕它所包装的对象提供额外的功能。额外附加功能的例子可能是懒加载或缓存，这可能会补偿原始对象的资源密集操作。\n下面是一个代理模式实现的例子。\ninterface ImageInterface { public function draw(); } class Image implements ImageInterface { private $file; public function __construct($file) { $this-\u0026gt;file = $file; sleep(5); // Imagine resource intensive image load } public function draw() { echo 'image: ' . $this-\u0026gt;file; } } class ProxyImage implements ImageInterface { private $image = null; private $file; public function __construct($file) { $this-\u0026gt;file = $file; } public function draw() { if (is_null($this-\u0026gt;image)) { $this-\u0026gt;image = new Image($this-\u0026gt;file); } $this-\u0026gt;image-\u0026gt;draw(); } } // Client $image = new Image('image.png'); // 5 seconds $image-\u0026gt;draw(); $image = new ProxyImage('image.png'); // 0 seconds $image-\u0026gt;draw(); 我们首先创建了一个ImageInterface，有一个单一的draw方法。然后我们定义了Image和ProxyImage类，这两个类都是ImageInterface的扩展。在Image类的 __construct 中，我们用sleep方法调用模拟了资源紧张的操作。最后，客户端同时实例化Image和ProxyImage，显示出两者的执行时间差异。\n更多文章内容请参见\nhttps://github.com/AnyStudy/PHP-7-Real-World-Application-Development\n如果对您有所帮助希望您能点以下 star\n","id":17,"section":"posts","summary":"\u003cp\u003e结构型处理的是类和对象的组成。利用接口或抽象类和方法，它们定义了组成对象的方法，进而获得新的功能。\u003c/p\u003e","tags":["php"],"title":"使用 PHP 7 实现 GoF 设计模式之结构型","uri":"https://www.ganymedenil.com/2021/01/09/php7-gof-structural-patterns.html","year":"2021"},{"content":"有很多事情可以使一个优秀的软件开发人员成为可能。设计模式的知识和使用就是其中之一。设计模式使开发人员能够使用各种软件交互的知名名称进行交流。无论某人是PHP、Python、C#、Ruby或任何其他语言的开发者，设计模式都能为经常出现的软件问题提供语言不可知的解决方案。\n设计模式的概念出现在1994年，作为《可重用的面向对象的软件要素》一书的一部分。该书详细介绍了23种不同的设计模式，由四位作者Erich Gamma、Richard Helm、Ralph Johnson和John Vlissides撰写。作者们通常被称为四人帮（GoF），所介绍的设计模式有时也被称为GoF设计模式。在二十多年后的今天，如果不将设计模式作为实现的一部分，设计出可扩展、可重用、可维护和可适应的软件几乎是不可能的。\n有三种类型的设计模式，我们将在本章介绍。\n创建型 结构型 行为型 创建型 创建型，顾名思义就是为我们创建对象，所以我们不必直接实例化它们。实现创建型使我们的应用程序具有一定的灵活性，应用程序本身可以决定在给定时间内实例化哪些对象。以下是我们归类为创建型的模式列表。\n抽象工厂模式 生成器模式 工厂方法模式 原型模式 单例模式 关于创建模式的更多信息，请参见https://en.wikipedia.org/wiki/Creational_pattern。\n抽象工厂模式 构建可移植的应用程序需要高水平的依赖性封装。抽象工厂通过抽象化相关或依赖对象家族的创建来实现这一点。客户端从来没有直接创建这些平台对象，工厂为他们做了这些工作，使得在不改变使用它们的代码的情况下，甚至在运行时也可以互换具体实现。\n下面是一个抽象工厂模式实现的例子。\ninterface Button { public function render(); } interface GUIFactory { public function createButton(); } class SubmitButton implements Button { public function render() { echo 'Render Submit Button'; } } class ResetButton implements Button { public function render() { echo 'Render Reset Button'; } } class SubmitFactory implements GUIFactory { public function createButton() { return new SubmitButton(); } } class ResetFactory implements GUIFactory { public function createButton() { return new ResetButton(); } } // Client $submitFactory = new SubmitFactory(); $button = $submitFactory-\u0026gt;createButton(); $button-\u0026gt;render(); $resetFactory = new ResetFactory(); $button = $resetFactory-\u0026gt;createButton(); $button-\u0026gt;render(); 我们首先创建一个接口Button，之后由我们的SubmitButton和ResetButton具体类实现。GUIFactory和ResetFactory实现了GUIFactory接口，它指定了createButton方法。然后客户端只需实例化工厂并调用createButton，就会返回一个合适的按钮实例，我们调用渲染方法。\n生成器模式 生成器模式将复杂对象的构建与表示分离，使得同一个构建过程可以创建不同的表示。有些生成器模式是在一次调用中构建一个产品，而生成器模式则是在 director 的控制下逐步完成。\n下面是一个生成器模式的实现实例。\nclass Car { public function getWheels() { /* implementation... */ } public function setWheels($wheels) { /* implementation... */ } public function getColour($colour) { /* implementation... */ } public function setColour() { /* implementation... */ } } interface CarBuilderInterface { public function setColour($colour); public function setWheels($wheels); public function getResult(); } class CarBuilder implements CarBuilderInterface { private $car; public function __construct() { $this-\u0026gt;car = new Car(); } public function setColour($colour) { $this-\u0026gt;car-\u0026gt;setColour($colour); return $this; } public function setWheels($wheels) { $this-\u0026gt;car-\u0026gt;setWheels($wheels); return $this; } public function getResult() { return $this-\u0026gt;car; } } class CarBuildDirector { private $builder; public function __construct(CarBuilder $builder) { $this-\u0026gt;builder = $builder; } public function build() { $this-\u0026gt;builder-\u0026gt;setColour('Red'); $this-\u0026gt;builder-\u0026gt;setWheels(4); return $this; } public function getCar() { return $this-\u0026gt;builder-\u0026gt;getResult(); } } // Client $carBuilder = new CarBuilder(); $carBuildDirector = new CarBuildDirector($carBuilder); $car = $carBuildDirector-\u0026gt;build()-\u0026gt;getCar(); 我们首先创建了一个具体的Car类，其中有几个方法定义了汽车的一些基本特性。然后我们创建了一个CarBuilderInterface，它将控制其中的一些特性，并得到最终的结果（汽车）。然后，具体的CarBuilder类实现了CarBuilderInterface，接着是具体的CarBuildDirector类，它定义了build和getCar方法。然后，客户端简单地实例化一个新的CarBuilder实例，将其作为构造参数传递给一个新的CarBuildDirector实例。最后，我们调用CarBuildDirector的build和getCar方法来获取实际的汽车Car实例。\n工厂方法模式 工厂方法模式处理了创建对象的问题，而不必指定将要创建的对象的确切类。\n下面是一个工厂方法模式的实现例子。\ninterface Product { public function getType(); } interface ProductFactory { public function makeProduct(); } class SimpleProduct implements Product { public function getType() { return 'SimpleProduct'; } } class SimpleProductFactory implements ProductFactory { public function makeProduct() { return new SimpleProduct(); } } /* Client */ $factory = new SimpleProductFactory(); $product = $factory-\u0026gt;makeProduct(); echo $product-\u0026gt;getType(); //outputs: SimpleProduct 我们首先创建一个ProductFactory和Product接口。SimpleProductFactory实现了ProductFactory，并通过其makeProduct方法返回新的产品实例。SimpleProduct类实现Product，并返回产品类型。最后，客户端创建SimpleProductFactory的实例，对其调用makeProduct方法。makeProduct返回Product的实例，其getType方法返回SimpleProduct字符串。\n原型模式 原型模式通过使用克隆来复制其他对象。这意味着我们不是使用new关键字来实例化新的对象。PHP提供了一个clone关键字，它可以对一个对象进行浅层复制，从而提供了非常直接的原型模式实现。浅层复制不复制引用，只复制新对象的值。我们可以进一步在我们的类上利用神奇的__clone方法，以实现更强大的克隆行为。\n下面是一个原型模式实现的例子。\nclass User { public $name; public $email; } class Employee extends User { public function __construct() { $this-\u0026gt;name = 'Johhn Doe'; $this-\u0026gt;email = 'john.doe@fake.mail'; } public function info() { return sprintf('%s, %s', $this-\u0026gt;name, $this-\u0026gt;email); } public function __clone() { /* additional changes for (after)clone behavior? */ } } $employee = new Employee(); echo $employee-\u0026gt;info(); $director = clone $employee; $director-\u0026gt;name = 'Jane Doe'; $director-\u0026gt;email = 'jane.doe@fake.mail'; echo $director-\u0026gt;info(); //outputs: Jane Doe, jane.doe@fake.mail 我们先创建一个简单的User类。然后，Employee扩展了User，同时在其构造函数中设置了名称和电子邮件。然后客户端通过new关键字实例化Employee，并将其克隆到director 变量中。现在$director变量是一个新的实例，这个实例不是通过new关键字制作的，而是通过克隆，使用clone关键字制作的。改变$director上的名字和邮箱，不会影响$employee。\n单例模式 单例模式的目的是将类的实例化限制在一个对象上。它是通过在类中创建一个方法来实现的，如果一个类的实例不存在，该方法就会创建一个新的实例。如果一个对象实例已经存在，该方法只是返回一个现有对象的引用。\n下面是一个单例模式实现的例子。\nclass Logger { private static $instance; public static function getInstance() { if (!isset(self::$instance)) { self::$instance = new self; } return self::$instance; } public function logNotice($msg) { return 'logNotice: ' . $msg; } public function logWarning($msg) { return 'logWarning: ' . $msg; } public function logError($msg) { return 'logError: ' . $msg; } } // Client echo Logger::getInstance()-\u0026gt;logNotice('test-notice'); echo Logger::getInstance()-\u0026gt;logWarning('test-warning'); echo Logger::getInstance()-\u0026gt;logError('test-error'); // Outputs: // logNotice: test-notice // logWarning: test-warning // logError: test-error 我们首先创建了一个具有静态$instance成员的Logger类，以及总是返回该类的单个实例的getInstance方法。然后我们添加了一些示例方法来演示客户端在单个实例上执行各种方法。\n更多文章内容请参见\nhttps://github.com/AnyStudy/PHP-7-Real-World-Application-Development\n如果对您有所帮助希望您能点以下 star\n","id":18,"section":"posts","summary":"\u003cp\u003e有很多事情可以使一个优秀的软件开发人员成为可能。设计模式的知识和使用就是其中之一。设计模式使开发人员能够使用各种软件交互的知名名称进行交流。无论某人是PHP、Python、C#、Ruby或任何其他语言的开发者，设计模式都能为经常出现的软件问题提供语言不可知的解决方案。\u003c/p\u003e","tags":["php"],"title":"使用 PHP 7 实现 GoF 设计模式之创建型","uri":"https://www.ganymedenil.com/2021/01/09/php7-gof-creational-patterns.html","year":"2021"},{"content":"PHP 7 在开源社区掀起了一场风暴，它打破了之前版本的速度记录，也重新引起了人们对它的关注。从最根本的意义上讲，核心工程团队已经对它进行了重大重写，但仍能保持高度的向后兼容性。PHP是一门开发Web应用的好语言。它本质上是一类服务器端脚本语言，也用于通用编程。PHP 7是最新的版本，提供了主要的向后兼容性突破，并专注于提高性能和速度。这意味着你可以通过多线程网络服务器，用低成本的硬件和服务器维持网站的高流量。\n前言 PHP 7:真实世界的应用开发（中文翻译） 作者：Doug Bierer, Altaf Hussain, Branko Ajzele 原书名称：《PHP 7: Real World Application Development》 译者：金弘扬（ganymedenil@gmail.com） Gitbook地址：PHP 7:真实世界的应用开发 github：https://github.com/AnyStudy/PHP-7-Real-World-Application-Development 推荐使用 Gitbook 以获取最佳阅读体验。\n译序 作为一个使用了php多年的程序员，公司项目也经历过5到7的升级，期间项目也出现过一些因为php7功能与php5 不一致导致的bug。我一直在寻找一本能详细介绍 php 7 新特性与功能的书，后来找到了这本，虽然这本书发布到现在已经差不多4年了，但是对于想详细了解php7的朋友来说里面所讲述的内容我认为还是很有价值的。并且本书作者的一些观点我也非常认同，就想着希望能让更多人看到，趁着十一假期有时间想试着翻译一下本书。本书实际是三本独立的书，但如果单独看这三本都感觉缺点什么，把这三本书合并为一本我感觉就很相辅相成。本书的模块2也就是《高性能 php 7》部分已经由吕毅老师翻译，本人就不再对本模块进行翻译。如果我的翻译能帮助到大家，也是我最大到荣幸。\n前言 PHP 7 在开源社区掀起了一场风暴，它打破了之前版本的速度记录，也重新引起了人们对它的关注。从最根本的意义上讲，核心工程团队已经对它进行了重大重写，但仍能保持高度的向后兼容性。PHP是一门开发Web应用的好语言。它本质上是一类服务器端脚本语言，也用于通用编程。PHP 7是最新的版本，提供了主要的向后兼容性突破，并专注于提高性能和速度。这意味着你可以通过多线程网络服务器，用低成本的硬件和服务器维持网站的高流量。\n这条学习之路都涵盖了什么 模块1，PHP 7 编程指南，本模块以 PHP 7 为中心，展示了中高级的PHP技术。每个示例都是为了解决像您这样的 PHP 开发人员每天面临的实际问题。其中还介绍了只有在 PHP 7 中才有的，新的编写 PHP 代码的方法。此外，我们还讨论了向后兼容性中断的问题，并为您提供了大量指导，告诉您何时何地需要修改 PHP 5 代码，以便在 PHP 7 下运行时产生正确的结果。本模块还包含了最新的 PHP 7.x 特性。在本模块结束时，您将具备为您的网站和企业提供高效应用程序所需的工具和技能。\n模块2，学习 PHP 7 高性能，该模块是 PHP 7 的快速入门，这将提高您的生产力和编码技能。所涉及的概念将使您作为一个PHP程序员，提高你的应用程序的性能标准。我们将向您介绍 PHP 7 中的新特性，然后介绍 PHP 7 中面向对象编程（OOP）的概念。接下来，我们将阐明如何提高 PHP 7 应用程序的性能和数据库性能。通过这个模块，您将能够使用模块中讨论的各种基准测试工具来提高程序的性能。最后，模块讨论了 PHP 编程中的一些最佳实践，以帮助你提高代码的质量。\n模块3，用 PHP 7 更新旧版应用程序，此模块将向您展示如何通过提取和替换旧版组件，从实践和技术上而不是在使用框架和库之类的工具方面对应用程序进行升级。 我们将采用循序渐进的方法，有条不紊地缓慢前进，从根本上改善您的应用程序。我们将向您展示依赖注入是如何替换新的和全局依赖的。我们还将向您展示如何将表示逻辑改为视图文件，将动作逻辑改为控制器。此外，我们将使您的应用程序始终保持运行状态。在这个过程中，每一个完成的步骤都会让您的代码库以更高的质量完全正常运行。当我们完成后，您将能够像风一样轻而易举地通过您的代码。您的代码将是自动加载、依赖注入、单元测试、层级分离和前端控制。我们将添加到您的应用程序中的大多数非常有限的代码都是针对这个模块的。我们将以程序员的身份提高自己，并提高传统应用程序的质量。\n你在这条学习之路上需要什么 模块1 要成功地实现本模块中介绍的示例，你只需要一台计算机，100MB 的额外磁盘空间，和一个文本或代码编辑器（不是文字处理器！）。第一章将介绍如何设置 PHP 7 开发环境。拥有一个 Web 服务器是可选的，因为 PHP 7 包含一个开发 Web 服务器。不需 Internet 连接，但下载代码（如 PSR-7 接口集）和查看 PHP 7.x 文档可能会需要。\n模块2 任何符合运行以下软件最新版本的硬件规格，应该都足以通过本模块。\n操作系统： Debian 或 Ubuntu 软件： NGINX、PHP 7、 MySQL、 PerconaDB、 Redis、 Memcached、 Xdebug、Apache JMeter、 ApacheBench、Siege 和 Git 模块3 您需要参考本模块的“第二章，先决条件“来了解本模块所需的基本硬件和软件要求。本章将详细描述这些要求。\n这条路是为谁而设 如果您是一个有抱负的Web开发人员，移动应用开发人员或后端程序员，并且具有PHP编程的基本经验并希望开发对性能至关重要的应用程序，那么这个课程是为你准备的。它将使您的PHP编程技能更上一层楼。\n支持 课程的代码包也托管在github上 https://GitHub.com/packtpublishing/php-7-be-pro-at-applications-development 。\n法律申明 译者纯粹出于学习目的与个人兴趣翻译本书，不追求任何经济利益。\n译者保留对此版本译文的署名权，其他权利以原作者和出版社的主张为准。\n本译文只供学习研究参考之用，不得公开传播发行或用于商业用途。有能力阅读英文书籍者请购买正版支持。\nLICENSE CC-BY 4.0\n","id":19,"section":"posts","summary":"\u003cp\u003ePHP 7 在开源社区掀起了一场风暴，它打破了之前版本的速度记录，也重新引起了人们对它的关注。从最根本的意义上讲，核心工程团队已经对它进行了重大重写，但仍能保持高度的向后兼容性。PHP是一门开发Web应用的好语言。它本质上是一类服务器端脚本语言，也用于通用编程。PHP 7是最新的版本，提供了主要的向后兼容性突破，并专注于提高性能和速度。这意味着你可以通过多线程网络服务器，用低成本的硬件和服务器维持网站的高流量。\u003c/p\u003e","tags":["php"],"title":"PHP 7:真实世界的应用开发（中文翻译）","uri":"https://www.ganymedenil.com/2020/10/04/php-7-real-world-application-development.html","year":"2020"},{"content":"前面分享了 “连接到远程服务器” 让我们了解了如何连接 TCP 服务器。本文，将展示更高级别的 HTTP 服务器的通信。\ngo基础库之连接到 HTTP 服务器 Golang 版本 1.14.2\n前言 前面分享了 “连接到远程服务器” 让我们了解了如何连接 TCP 服务器。本文，将展示更高级别的 HTTP 服务器的通信。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;net/url\u0026quot; \u0026quot;strings\u0026quot; ) type StringServer string func (s StringServer) ServeHTTP(rw http.ResponseWriter, req *http.Request) { req.ParseForm() fmt.Printf(\u0026quot;Received form data: %v\\n\u0026quot;, req.Form) rw.Write([]byte(string(s))) } func createServer(addr string) http.Server { return http.Server{ Addr: addr, Handler: StringServer(\u0026quot;Hello world\u0026quot;), } } const addr = \u0026quot;localhost:9090\u0026quot; func main() { s := createServer(addr) go s.ListenAndServe() useRequest() simplePost() } func simplePost() { res, err := http.Post(\u0026quot;http://localhost:9090\u0026quot;, \u0026quot;application/x-www-form-urlencoded\u0026quot;, strings.NewReader(\u0026quot;name=test\u0026amp;surname=abc\u0026quot;)) if err != nil { panic(err) } data, err := ioutil.ReadAll(res.Body) if err != nil { panic(err) } res.Body.Close() fmt.Println(\u0026quot;Response from server:\u0026quot; + string(data)) } func useRequest() { hc := http.Client{} form := url.Values{} form.Add(\u0026quot;name\u0026quot;, \u0026quot;test\u0026quot;) form.Add(\u0026quot;surname\u0026quot;, \u0026quot;abc\u0026quot;) req, err := http.NewRequest(\u0026quot;POST\u0026quot;, \u0026quot;http://localhost:9090\u0026quot;, strings.NewReader(form.Encode())) req.Header.Add(\u0026quot;Content-Type\u0026quot;, \u0026quot;application/x-www-form-urlencoded\u0026quot;) res, err := hc.Do(req) if err != nil { panic(err) } data, err := ioutil.ReadAll(res.Body) if err != nil { panic(err) } res.Body.Close() fmt.Println(\u0026quot;Response from server:\u0026quot; + string(data)) } $ go run main.go Received form data: map[name:[test] surname:[abc]] Response from server:Hello world Received form data: map[name:[test] surname:[abc]] Response from server:Hello world 原理 连接到 HTTP 服务器可以在 net/http 包的帮助下完成。 当然，还有更多的方法可以实现这一点，但是上面的代码展示了两种最常用的方法。 第一个选项实现了 simplePost 函数，并演示了默认客户端的使用。 这里选择 POST 方法是因为它比 GET 更复杂。 Post 方法以 Reader 的形式接受 URL、内容类型和主体。 调用 Post 函数会立即请求服务器并返回结果。\nUserequest 函数实现了相同的功能，但是使用了可定制的 API 和它自己的 Client 实例。 实现利用 NewRequest 函数根据这些给定的参数创建请求: 方法、 URL 和请求主体。 内容类型必须单独设置为 Header 属性。 请求使用在 Client 上创建的 Do 方法执行。\n","id":20,"section":"posts","summary":"\u003cp\u003e前面分享了 “连接到远程服务器” 让我们了解了如何连接 TCP 服务器。本文，将展示更高级别的 HTTP 服务器的通信。\u003c/p\u003e","tags":["go"],"title":"go基础库之连接到 HTTP 服务器","uri":"https://www.ganymedenil.com/2020/05/10/go-standard-library-by-connect-to-http-server.html","year":"2020"},{"content":"golang 基础库之通过 IP 地址解析域名，本文将向你介绍如何将 IP 地址转换为主机地址，反之亦然。\ngo基础库之通过 IP 地址解析域名 Golang 版本 1.14.2\n前言 golang 基础库之通过 IP 地址解析域名，本文将向你介绍如何将 IP 地址转换为主机地址，反之亦然。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;net\u0026quot; ) func main() { // 解析 IP addrs, err := net.LookupAddr(\u0026quot;127.0.0.1\u0026quot;) if err != nil { panic(err) } for _, addr := range addrs { fmt.Println(addr) } // 解析地址 ips, err := net.LookupIP(\u0026quot;localhost\u0026quot;) if err != nil { panic(err) } for _, ip := range ips { fmt.Println(ip.String()) } } $ go run main.go localhost 127.0.0.1 ::1 原理 从 IP 地址解析域名可以通过 net 包中的 LookupAddr 函数来完成。 要从域名中查找 IP 地址，应用 LookupIP 函数。\n","id":21,"section":"posts","summary":"\u003cp\u003egolang 基础库之通过 IP 地址解析域名，本文将向你介绍如何将 IP 地址转换为主机地址，反之亦然。\u003c/p\u003e","tags":["go"],"title":"go基础库之通过 IP 地址解析域名","uri":"https://www.ganymedenil.com/2020/05/10/go-standard-library-by-domain-name-resolution-by-ip-address.html","year":"2020"},{"content":"基于TCP的协议是网络通信中最重要的协议。 提醒一下，HTTP，FTP，SMTP和其他协议也是它的一部分。 本文可让你深入了解如何连接到TCP服务器。\ngo基础库之连接到远程服务器 Golang 版本 1.14.2\n前言 基于TCP的协议是网络通信中最重要的协议。 提醒一下，HTTP，FTP，SMTP和其他协议也是它的一部分。 本文可让你深入了解如何连接到TCP服务器。\n实现 package main import ( \u0026quot;bufio\u0026quot; \u0026quot;context\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;net\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;time\u0026quot; ) type StringServer string func (s StringServer) ServeHTTP(rw http.ResponseWriter, req *http.Request) { rw.Write([]byte(string(s))) } func createServer(addr string) http.Server { return http.Server{ Addr: addr, Handler: StringServer(\u0026quot;HELLO GOPHER!\\n\u0026quot;), } } const addr = \u0026quot;localhost:9090\u0026quot; func main() { s := createServer(addr) go s.ListenAndServe() // 与普通TCP建立连接 conn, err := net.Dial(\u0026quot;tcp\u0026quot;, addr) if err != nil { panic(err) } defer conn.Close() _, err = io.WriteString(conn, \u0026quot;GET / HTTP/1.1\\r\\nHost:localhost:7070\\r\\n\\r\\n\u0026quot;) if err != nil { panic(err) } scanner := bufio.NewScanner(conn) conn.SetReadDeadline(time.Now().Add(time.Second)) for scanner.Scan() { fmt.Println(scanner.Text()) } ctx, _ := context.WithTimeout(context.Background(), 5*time.Second) s.Shutdown(ctx) } $ go run main.go HTTP/1.1 200 OK Date: Sat, 09 May 2020 21:22:56 GMT Content-Length: 14 Content-Type: text/plain; charset=utf-8 HELLO GOPHER! 原理 Net 包包含 Dial 函数，该函数需要传入网络类型和地址。 在前面的示例中，网络是 tcp，地址是 localhost:9090。\n成功执行 Dial 函数后，返回 Conn 类型，它作为打开套接字的引用。 Conn 接口还定义了 Read 和 Write 函数，因此可以将它们用作 Writer 和 Reader 函数，用于从套接字进行写入和读取。 最后，示例代码使用 Scanner 获取响应。 注意Scanner 在当前代码中生效是因为有换行。 否则，应该使用更通用的 Read 方法。 在这个例子中，读取截止日期是通过 SetReadDeadline 方法设置的。 重要的是，最后期限不是一个持续时间，而是一个 Time。 这意味着最后期限被设定为未来的一个时间点。 如果你正通过从循环中读取套接字中的数据，并且需要将读取超时设置为10秒，那么每次迭代都应该包含如下代码 conn.SetReadDeadline(time.Now().Add(10*time.Second))。\n","id":22,"section":"posts","summary":"\u003cp\u003e基于TCP的协议是网络通信中最重要的协议。 提醒一下，HTTP，FTP，SMTP和其他协议也是它的一部分。 本文可让你深入了解如何连接到TCP服务器。\u003c/p\u003e","tags":["go"],"title":"go基础库之连接到远程服务器","uri":"https://www.ganymedenil.com/2020/05/10/go-standard-library-by-connect-to-a-remote-server.html","year":"2020"},{"content":"golang 基础库之解析本地 IP 地址，介绍了如何从可用的本地端口获取对应的IP地址\ngo基础库之解析本地 IP 地址 Golang 版本 1.14.2\n前言 golang 基础库之解析本地 IP 地址，介绍了如何从可用的本地端口获取对应的IP地址\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;net\u0026quot; ) func main() { // 获取所有网络接口 interfaces, err := net.Interfaces() if err != nil { panic(err) } for _, interf := range interfaces { // 解析地址 // 遍历接口 addrs, err := interf.Addrs() if err != nil { panic(err) } fmt.Println(interf.Name) for _, add := range addrs { if ip, ok := add.(*net.IPNet); ok { fmt.Printf(\u0026quot;\\t%v\\n\u0026quot;, ip) } } } } $ go run main.go 本地连接* 4 fe80::4d29:b94e:922f:e339/64 192.168.1.57/16 WLAN 10.154.11.12/24 原理 net 包包含 Interfaces 函数，该函数将网络接口列为 Interface 结构的一个切片。而 Interface 结构具有 Addrs 方法，该方法列出可用的网络地址。 通过这种方式，就可以按照接口列出对应的地址。\n另一个选择是使用 net 包的 interfaceaddr 函数，它提供了实现 Addr 接口的结构切片。 这为你提供了获取所需信息的方法。\n","id":23,"section":"posts","summary":"\u003cp\u003egolang 基础库之解析本地 IP 地址，介绍了如何从可用的本地端口获取对应的IP地址\u003c/p\u003e","tags":["go"],"title":"go基础库之解析本地 IP 地址","uri":"https://www.ganymedenil.com/2020/05/10/go-standard-library-by-resolve-local-ip-address.html","year":"2020"},{"content":"软件不仅仅是代码。 如果你仔细想想，代码很少是我们这个职业的最终目标。 代码只是解决业务问题的媒介。 那么为什么我们要谈一种不同的语言呢？ 领域驱动设计强调确保企业和软件使用同一种语言。 一旦打破这个障碍，就不需要翻译或繁琐的同步，信息也不会丢失。 每个人都有助于发现业务领域，而不仅仅是程序员。 由此产生的软件是共同语言的唯一真理。\n为什么领域驱动设计很重要 软件不仅仅是代码。 如果你仔细想想，代码很少是我们这个职业的最终目标。 代码只是解决业务问题的媒介。 那么为什么我们要谈一种不同的语言呢？ 领域驱动设计强调确保企业和软件使用同一种语言。 一旦打破这个障碍，就不需要翻译或繁琐的同步，信息也不会丢失。 每个人都有助于发现业务领域，而不仅仅是程序员。 由此产生的软件是共同语言的唯一真理。\n领域驱动设计它还为战略和战术设计提供了一个框架 - 战略性地确定了基于业务价值开发的最重要领域，以及构建一个由经过实战考验的构件和模式组成的工作领域模型的战术。\n领域驱动设计的三大支柱 Ubiquitous Language（无处不在的语言） 领域专家和软件开发人员共同为正在开发的业务领域构建通用语言。 开发软件是一项商业投资，而不仅仅是一项成本。 构建无处不在的语言（Ubiquitous Language）可以在团队成员中传播深层的领域洞察力。\nStrategic Design（战略设计） 领域驱动设计的战略不仅仅是技术方面，而是业务方向背后的战略。 它有助于定义内部关系和早期预警反馈系统。 在技术方面，战略设计通过提供如何实现面向服务的体系结构服务的动机来保护每一项业务服务。\nTactical Design（战术设计） 领域驱动设计提供了迭代软件交付的工具和构建模块。 战术设计工具生成的软件不仅是正确的，而且是可测试的，更不容易出错。\n无处不在的语言（Ubiquitous Language） 如果我们刻意去探索和总结无处不在的语言（Ubiquitous Language），往往会有以下几个相同点：\n识别关键业务流程、它们的输入和输出 创建术语和定义的词汇表 使用某种文档来获取重要的软件概念 与团队的其他成员(开发人员和领域专家)共享和扩展所收集的知识 事件风暴（Event Storming） 事件风暴是一种用于快速探索复杂业务领域的研讨会格式:\n它很强大: 它让我和许多从业者能够在数小时而不是数周内提出完整业务流程的综合模型。 它很有吸引力：整个想法是把有问题的人和知道答案的人聚集在同一个房间里，一起建立一个模型。 它很高效：最终的模型与领域驱动设计实现风格完美一致（特别适合事件溯源法（Event Sourcing approach）），并允许快速确定上下文和聚合边界。 它很简单: 这个符号非常简单。 没有复杂的 UML 可能会切断参与者与讨论的核心的联系。 它很有趣：我总是很愉快地领导研讨会，人们充满活力，并提供比他们预期的更多。 出现了正确的问题，气氛也是正确的。 考虑使用领域驱动设计 领域驱动设计并不是万能的; 就像软件中的所有东西一样，它取决于上下文。 作为一个经验法则，只使用它来简化您的域，但绝不要增加更多的复杂性。\n如果你的应用程序是以数据为中心的，而你的用例主要是操纵数据库中的行和执行 CRUD 操作ーー即创建、读取、更新和删除ーー那么你就不需要领域驱动设计。 相反，你的公司唯一需要的是在你的数据库前面有一张花哨的脸（完善的ORM）。\n如果您的应用程序少于30个用例，那么使用 Symfony 或 Laravel 这样的框架来处理业务逻辑可能会更简单。\n然而，如果您的应用程序有超过30个用例，那么您的系统可能正朝着可怕的大泥球的方向移动。 如果你确信你的系统将会变得越来越复杂，你应该考虑使用领域驱动设计来对抗这种复杂性。\n如果您知道您的应用程序将会增长并且可能经常更改，那么领域驱动设计应用程序肯定会帮助您管理复杂性并随着时间的推移重构您的模型。\n如果您不了解您正在处理的域，而且以前没有人提出过解决方案，这可能意味着它已经足够复杂，您可以开始应用领域驱动设计。 在这种情况下，您需要与领域专家密切合作，以获得正确的模型。\n棘手的部分 应用领域驱动设计并不容易。 需要时间和精力来解决业务领域，术语，研究和与域专家的协作，而不是编写行话。 您需要拥有领域专家的承诺才能参与该过程。 这将需要开放和健康的持续对话，以将他们的口语建模为软件。 最重要的是，我们必须努力避免在技术上思考，首先认真考虑对象的行为和普适语言。\n战略概述 为了对领域驱动设计的战略方面提供一个总体概述， 考虑两个不同的空间: 问题领域（problem space）和解决方案领域（solution space）。\n在问题领域中，领域驱动设计使用域和子域来分组和组织公司想要解决的问题。 就在线旅行社（OTA）而言，问题在于处理机票和预订酒店等事宜。 可以将此类域组织到不同的子域中，例如定价，库存，用户管理等。\n在解决方案领域，领域驱动设计提供了两种模式：有界上下文和上下文映射。目标是通过定义其交互和这些交互的详细信息来定义如何为所有已识别的子域提供实现。继续OTA示例，每个子域将通过有界上下文实现来解决 - 例如，考虑由团队为定价管理子域开发的自定义Web应用程序，以及用户管理子域的现成解决方案。上下文映射将显示每个有界上下文如何与其余上下文相关联。在上下文映射中，我们可以看到两个有界上下文所具有的关系类型(例如: 客户-供应商，合作伙伴)。 理想的方法是通过一个有界上下文实现每个子域，，但这并不总是可行的。 从实现的角度来说，当你遵循领域驱动设计时，你最终会得到分布式体系结构。 正如您可能已经知道的，分布式体系结构比单块体系结构更复杂，那么为什么这种方法是有趣的，特别是对于大型和复杂的公司？ 这真的值得吗？ 是的。\n事实证明，分布式体系结构可以提高公司的整体生产力，因为它们可以为您的产品定义可由专注团队开发的边界。\n如果您的域 - 您需要解决的问题 - 并不复杂，应用领域驱动设计的战略部分可能会增加不必要的开销并降低您的开发速度。\n相关技术运动: 微型服务和自包含系统 随着领域驱动设计的推广，也促进了微服务和自包含系统的架构的诞生。\n微服务架构风格是一种将单个应用程序开发为一套小型服务的方法，每个小型服务都在自己的进程中运行，并使用轻量级通信协议（通常是HTTP REST API）。 这些服务是围绕业务功能构建的，并且可以使用完全自动化的机制进行独立部署。 这些服务只有最低限度的集中管理，可以用不同的编程语言编写，也可以使用不同的数据存储技术。\n微服务就是领域驱动设计有界上下文的实现。\n自包含系统方法是一种体系结构，它侧重于将功能分离到许多独立的系统中，使得完整的逻辑系统成为许多较小的软件系统的协作。 这避免了大型单体结构不断增长并最终变得不可维护的问题。 在过去的几年里，我们已经在许多中型和大型项目中看到了它的好处。 其思想是将一个大型系统拆分为若干个遵循某些规则的较小的独立系统(SCS)。\n该网站还阐述了SCS的八个特征：\n每个 SCS 都是一个独立的 web 应用程序。 对于 SCS 的所有数据，其处理这些数据的逻辑和呈现 web 界面的所有代码都包含在 SCS 中。 SCS 可以自己完成其主要用例，而不必依赖其他可用的系统。\n每个 SCS 由一个团队拥有。 这并不一定意味着只有一个团队可以更改代码，但拥有代码的团队对代码库中的内容拥有最终决定权，例如通过合并 pull-requests。\n与其他SCS或第三方系统的通信尽可能是异步的。 具体而言，不应在SCS自己的请求/响应周期内同步访问其他SCS或外部系统。这解耦了系统，减少故障的影响，从而支持自治。目标是关于时间的解耦：即使其他SCS暂时离线，SCS也应该正常工作。 即使在技术层面上的通信是同步的，也可以实现这一点，例如通过复制数据或缓冲请求。\nSCS可以具有可选的服务API。 因为SCS有自己的Web UI，所以它可以与用户交互。 但是，移动客户端或其他SCS对于API可能仍然需要。\n每个 SCS 必须包括数据和逻辑。 要真正实现任何有意义的特性，两者都是必需的。 一个 SCS 应该自己实现特性，因此必须同时包括这两个特性。\nSCS应该通过自己的UI使其功能对最终用户可用。 因此，SCS应该没有与其他SCS共享的UI。 SCS可能仍然具有彼此的链接。 但是，异步集成意味着即使另一个SCS的UI不可用，SCS仍应工作。\n为避免紧密耦合，SCS不应与其他SCS共享业务代码。 为SCS创建拉取请求或使用公共库可能没什么问题，例如：数据库驱动程序或oAuth客户端。\n为了使SCS更加健壮并改善解耦，可以最大限度地减少共享基础架构。 例如。 SCS使用共享数据库，其故障、安全性和可扩展性取决于其中央数据库。 但是，由于成本原因，每个SCS使用具有单独模式或数据模型的共享数据库可能是有效的替代方案。\n总结 领域驱动设计与技术无关; 它实际上是通过专注于模型来提供您正在工作的领域的价值。 每个人都参与了发现域的过程，开发人员和领域专家通过共享同一种语言 - 无所不在的语言 - 来组建知识库。\n领域驱动设计提供战术和战略建模工具来设计高质量的软件。 战略设计针对业务方向，帮助定义内部关系，并通过定义强大的边界在技术上保护每个业务服务。 战术设计为迭代设计提供了有用的构建块。\n领域驱动设计只有在特定的情况下才有意义。 它不是解决软件中所有问题的灵丹妙药，所以你是否使用它在很大程度上取决于你处理的复杂程度。\n领域驱动设计是一项长期投资，需要积极的努力。 领域专家将被要求与开发人员密切合作，开发人员将不得不从业务角度考虑问题。 最后，商业客户才是需要被满足的人。\n参考 Domain Driven Design Distilled by Vaughn Vernon\nDomain-Driven Design Reference: Definitions and Pattern Summaries by Eric Evans\nIntroducing EventStorming\nBig Ball of Mud\nApplying Domain-Driven Design and Patterns\nMicroservices Resource Guide\nBuilding Microservices\nSelf-Contained Systems\nDomain-Driven Design in PHP\n","id":24,"section":"posts","summary":"\u003cp\u003e软件不仅仅是代码。 如果你仔细想想，代码很少是我们这个职业的最终目标。 代码只是解决业务问题的媒介。 那么为什么我们要谈一种不同的语言呢？ 领域驱动设计强调确保企业和软件使用同一种语言。 一旦打破这个障碍，就不需要翻译或繁琐的同步，信息也不会丢失。 每个人都有助于发现业务领域，而不仅仅是程序员。 由此产生的软件是共同语言的唯一真理。\u003c/p\u003e","tags":["ddd"],"title":"领域驱动设计的开始","uri":"https://www.ganymedenil.com/2019/09/05/domain-driven-design-begins.html","year":"2019"},{"content":"Go 1.13 为 error 包带来了新的内容。 它们来自于 Go 2 错误检查的建议。\nGo 1.13 的 Errors Go 1.13 为 error 包带来了新的内容。 它们来自于 Go 2 错误检查的建议。\n在Go中，错误是实现 error 接口的任何值。\n// The error built-in interface type is the conventional interface for // representing an error condition, with the nil value representing no error. type error interface { Error() string } 本质上，错误是字符串，人们很容易阅读和解释，但程序很难对它们进行推理。\n目前有四种常用的方法来处理错误：\nsentinel errors type assertion ad-hoc checks substring searches Sentinel errors 一些包定义导出的错误变量并从其函数返回。sql.ErrNoRows 就是个常见的例子：\npackage sql // ErrNoRows is returned by Scan when QueryRow doesn’t return a // row. In such a case, QueryRow returns a placeholder *Row value that // defers this error until a Scan. var ErrNoRows = errors.New(“sql: no rows in result set”) 然后我们判断一下：\nif err == sql.ErrNoRows { … handle the error … } Type assertion 与 sentinel errors 类似，在这种情况下，我们希望检查返回的错误是否形成某种特定类型，以便提供更多信息。我们可以在 os 包中看到一个很好的例子:\ntype PathError struct { Op [string](https://golang.org/pkg/builtin/#string) Path [string](https://golang.org/pkg/builtin/#string) Err [error](https://golang.org/pkg/builtin/#error) } func (e *PathError) Error() string func (e *PathError) Timeout() bool 使用类型断言，我们可以访问所有可用的额外信息 PathError\nif pe, ok := err.(*os.PathError); ok { if pe.Timeout() { ... } ... } Ad-hoc checks 本方法是通过定义函数，抽象出给定的错误可能是什么。 一个明显的优点是包可以公开这些方法，并保留其内部用于错误处理的私有性。\n// IsNotExist returns a boolean indicating whether the error is known to // report that a file or directory does not exist. It is satisfied by // ErrNotExist as well as some syscall errors. func IsNotExist(err error) bool if os.IsNotExist(err) { ... } Substring searches 它的名字说明了一切，通过古老的 strings.Contains 检查错误。 总而言之，是最不受欢迎的。\nif strings.Contains(err.Error(), \u0026quot;foo bar\u0026quot;) { ... } 当我们想要添加更多的上下文/信息时: Wrapping 我们经常需要添加一些更具体的信息，例如解释故障的原因。 对于上述情况，我们无能为力。 例如，我们可能需要声明由于 sql 错误而导致获取操作失败。\nWrapping 本质上是创建一系列错误，使我们能够在保留原始错误的同时添加更多信息。它可以很容易地用任何能够容纳错误的类型和更多信息来实现。给出如下类型：\ntype myError struct { msg string err error } func Wrap(err error, msg string, args ...interface{}) error { return myError{ msg: fmt.Sprintf(msg, args...), err: err, } } 我们可以轻松地创建一些方法来遍历错误链，从 Wrapping 错误中给出下面的错误，依此类推。\nGo生态系统中有一些可靠的库。Onefootball [github.com/pkg/errors](https://github.com/pkg/errors) (如果你不知道，可以看一下;) ) 在我们的大多数微服务中使用。\n然而，这种方法存在一个缺点，我们将 vendor 锁定到任何封装错误的库。因为只能通过库的API访问展开和任何其他信息。\nGo 2 错误检查建议 建议 Go 2增加一个用于 unwrapping 错误的接口:\n// Unwrap returns the result of calling the Unwrap method on err, if err’s // type contains an Unwrap method returning error. // Otherwise, Unwrap returns nil. type Wrapper interface { Unwrap() error } [我认为它被称为 Unwrapper 而不是 Wrapper]\n这个简单的接口允许任何 Go 程序解包任何自定义错误，如果当前的包装器实现 Unwrap() ，我们可以遍历整个错误链，而不必担心有多少自定义错误可能已经混合在一起。\n更好的是，还记得 sentinel errors 和 type assertions 吗？ 现在，Go 的错误包可以为它们定义标准方法。 它们是 Is 和 As:\nfunc Is(err, target error) bool func As(err error, target interface{}) bool 更多细节：\npackage errors // Is reports whether any error in err's chain matches target. // // The chain consists of err itself followed by the sequence of errors obtained by // repeatedly calling Unwrap. // // An error is considered to match a target if it is equal to that target or if // it implements a method Is(error) bool such that Is(target) returns true. func Is(err, target error) bool // As finds the first error in err's chain that matches target, and if so, sets // target to that error value and returns true. // // An error matches target if the error's concrete value is assignable to the value // pointed to by target, or if the error has a method As(interface{}) bool such that // As(target) returns true. In the latter case, the As method is responsible for // setting target. // // As will panic if target is not a non-nil pointer to either a type that implements // error, or to any interface type. As returns false if err is nil. func As(err error, target interface{}) bool go 1.13? Go 1.13 定义 Unwrap，Is 和 As 函数如上所示。\n**Unwrap **是对类型error 的内容调用 Unwrap() 的一种简写形式。 由于这两种方法都没有添加到 error 接口中，因此 errors.Unwrap 非常方便。\nIs 和 As 将匹配或类型 assert 并将任何错误转换为目标，遍历错误链直到找到匹配错误或 nil。\n正如你可能已经注意到的，在 Go 1.13上没有定义接口，上面的三个方法都是动态检查给定的错误是否实现了其中的任何一个:\nu, ok := err.(interface { Unwrap() error }) x, ok := err.(interface { Is(error) bool }) x, ok := err.(interface { As(interface{}) bool }) 包装一个错误? 不要担心，fmt 已经为你覆盖了：\nThe [Errorf](https://tip.golang.org/pkg/fmt/#Errorf) 函数有一个新的谓词， %w，其 运算对象必须是 error。从 Errorf 返回的错误将有一个 Unwrapmethod，它返回运算对象%w.\nerr := errors.New(“my error”) err = fmt.Errorf(“1s wrapping my error with Errorf: %w”, err) err = fmt.Errorf(“2nd wrapping my error with Errorf: %w”, err) 迁移到 Go 1.13? 最后一个小贴士 注意一件事：modules 现在默认使用Google官方的镜像和校验和数据库（checksum database）。 go命令请求安装 modules 时将访问官方的镜像并与官方的校验和数据库（checksum database）进行对比校验。 因此，你需要排除你私人仓库中的modules 。 你可以这样操作，在 GOPRIVATE 中设置 modules 路径前缀以逗号分隔的glob模式列表（通过Go语言中的 path.Match 进行匹配）。 例如：\nGOPRIVATE=github.com/myOrg/*,*.corp.example.com,domain.io/private Happy coding!\nPS:我还在柏林Golang聚会上发表了关于此问题的演讲，你可以在这里找到幻灯片和代码：https://github.com/AndersonQ/go1_13_errors\n本文翻译自A Look At Go 1.13 Errors - Onefootball Locker Room - Medium\n","id":25,"section":"posts","summary":"\u003cp\u003eGo 1.13 为 \u003ccode\u003eerror\u003c/code\u003e 包带来了新的内容。 它们来自于 \u003ca href=\"https://go.googlesource.com/proposal/+/master/design/29934-error-values.md\"\u003eGo 2 错误检查\u003c/a\u003e的建议。\u003c/p\u003e","tags":["go"],"title":"Go 1.13 的 Errors","uri":"https://www.ganymedenil.com/2019/09/04/A-Look-At-Go-1.13-Errors.html","year":"2019"},{"content":"程序知道用户的主目录是非常有用的，例如，如果需要存储自定义用户配置或与用户相关的任何其他数据。本文将介绍如何找出当前用户的主目录。\n解析用户主目录 Golang 版本 1.12.1\n前言 程序知道用户的主目录是非常有用的，例如，如果需要存储自定义用户配置或与用户相关的任何其他数据。本文将介绍如何找出当前用户的主目录。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os/user\u0026quot; ) func main() { usr, err := user.Current() if err != nil { log.Fatal(err) } fmt.Println(\u0026quot;用户主目录是: \u0026quot; + usr.HomeDir) } $ go run main.go 用户主目录是: C:\\Users\\GanymedeNil 原理 os/user包包含Current函数，它提供os.User类型指针。 User包含HomeDir属性，该属性包含当前用户主目录的路径。\n请注意，这对交叉编译的代码不起作用，因为实现取决于本机代码。\n","id":26,"section":"posts","summary":"\u003cp\u003e程序知道用户的主目录是非常有用的，例如，如果需要存储自定义用户配置或与用户相关的任何其他数据。本文将介绍如何找出当前用户的主目录。\u003c/p\u003e","tags":["go"],"title":"go基础库之解析用户主目录","uri":"https://www.ganymedenil.com/2019/06/09/go-standard-library-by-parse-the-user-is-home-directory.html","year":"2019"},{"content":"本文将介绍如何列出匹配给定模式的文件路径。该列表不必来自同一文件夹。\n过滤文件列表 Golang 版本 1.12.1\n前言 本文将介绍如何列出匹配给定模式的文件路径。该列表不必来自同一文件夹。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;path/filepath\u0026quot; ) func main() { for i := 1; i \u0026lt;= 6; i++ { _, err := os.Create(fmt.Sprintf(\u0026quot;./test.file%d\u0026quot;, i)) if err != nil { fmt.Println(err) } } m, err := filepath.Glob(\u0026quot;./test.file[1-3]\u0026quot;) if err != nil { panic(err) } for _, val := range m { fmt.Println(val) } // Cleanup for i := 1; i \u0026lt;= 6; i++ { err := os.Remove(fmt.Sprintf(\u0026quot;./test.file%d\u0026quot;, i)) if err != nil { fmt.Println(err) } } } $ go run main.go test.file1 test.file2 test.file3 原理 要获取与给定模式对应的过滤文件列表，可以使用filepath包中的Glob函数。 有关模式语法，请参阅filepath.Match函数的文档（https://golang.org/pkg/path/filepath/#Match）。\n请注意，filepath.Glob的返回结果是具有匹配路径的字符串切片。\n","id":27,"section":"posts","summary":"\u003cp\u003e本文将介绍如何列出匹配给定模式的文件路径。该列表不必来自同一文件夹。\u003c/p\u003e","tags":["go"],"title":"go基础库之过滤文件列表","uri":"https://www.ganymedenil.com/2019/06/09/go-standard-library-by-filter-file-list.html","year":"2019"},{"content":"本文描述了一些在代码中创建文件和目录的通常方法。\n创建文件和目录 Golang 版本 1.12.1\n前言 本文描述了一些在代码中创建文件和目录的通常方法。\n实现 package main import ( \u0026quot;os\u0026quot; ) func main() { f, err := os.Create(\u0026quot;created.file\u0026quot;) if err != nil { panic(err) } f.Close() f, err = os.OpenFile(\u0026quot;created.byopen\u0026quot;, os.O_CREATE|os.O_APPEND, os.ModePerm) if err != nil { panic(err) } f.Close() err = os.Mkdir(\u0026quot;createdDir\u0026quot;, 0777) if err != nil { panic(err) } err = os.MkdirAll(\u0026quot;sampleDir/path1/path2\u0026quot;, 0777) if err != nil { panic(err) } } $ go run main.go . ├── main.go ├── created.byopen ├── created.file ├── createdDir └── sampleDir └── path1 └── path2 原理 前面的示例展示了可以创建文件或目录的四种方法。 os.Create函数是创建文件的最简单方法。 通过使用此功能，将创建具有0666权限的文件。\n如果需要自定义权限创建文件，则os包的OpenFile函数可以满足。\n使用os包的Mkdir函数创建目录。 这样，就会创建一个具有给定权限的目录。 第二个选项是使用MkdirAll函数。 此函数还会创建目录，但如果给定路径包含不存在的目录，则会创建路径中的所有目录（它的工作方式与Unix的mkdir程序的-p选项相同）。\n","id":28,"section":"posts","summary":"\u003cp\u003e本文描述了一些在代码中创建文件和目录的通常方法。\u003c/p\u003e","tags":["go"],"title":"go基础库之创建文件和目录","uri":"https://www.ganymedenil.com/2019/06/09/go-standard-library-by-create-files-and-directories.html","year":"2019"},{"content":"本文将向你展示如何快速确定两个文件是否相同。还将为你提供一种找到两者之间差异的方法。\n比较两个文件 Golang 版本 1.12.1\n前言 本文将向你展示如何快速确定两个文件是否相同。还将为你提供一种找到两者之间差异的方法。\n实现 package main import ( \u0026quot;bufio\u0026quot; \u0026quot;crypto/md5\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;os\u0026quot; ) var data = []struct { name string cont string perm os.FileMode }{ {\u0026quot;test1.file\u0026quot;, \u0026quot;Hello\\nGolang is great\u0026quot;, 0666}, {\u0026quot;test2.file\u0026quot;, \u0026quot;Hello\\nGolang is great\u0026quot;, 0666}, {\u0026quot;test3.file\u0026quot;, \u0026quot;Not matching\\nGolang is great\\nLast line\u0026quot;, 0666}, } func main() { files := []*os.File{} for _, fData := range data { f, err := os.Create(fData.name) if err != nil { panic(err) } defer f.Close() _, err = io.WriteString(f, fData.cont) if err != nil { panic(err) } files = append(files, f) } // 通过校验和比较 checksums := []string{} for _, f := range files { f.Seek(0, 0) // 重置文件的开头 sum, err := getMD5SumString(f) if err != nil { panic(err) } checksums = append(checksums, sum) } fmt.Println(\u0026quot;### 通过校验和比较 ###\u0026quot;) compareCheckSum(checksums[0], checksums[1]) compareCheckSum(checksums[0], checksums[2]) fmt.Println(\u0026quot;### 逐行比较 ###\u0026quot;) files[0].Seek(0, 0) files[2].Seek(0, 0) compareFileByLine(files[0], files[2]) // 清理 for _, val := range data { os.Remove(val.name) } } func getMD5SumString(f *os.File) (string, error) { file1Sum := md5.New() _, err := io.Copy(file1Sum, f) if err != nil { return \u0026quot;\u0026quot;, err } return fmt.Sprintf(\u0026quot;%X\u0026quot;, file1Sum.Sum(nil)), nil } func compareCheckSum(sum1, sum2 string) { match := \u0026quot;match\u0026quot; if sum1 != sum2 { match = \u0026quot; does not match\u0026quot; } fmt.Printf(\u0026quot;Sum: %s and Sum: %s %s\\n\u0026quot;, sum1, sum2, match) } func compareLines(line1, line2 string) { sign := \u0026quot;o\u0026quot; if line1 != line2 { sign = \u0026quot;x\u0026quot; } fmt.Printf(\u0026quot;%s | %s | %s \\n\u0026quot;, sign, line1, line2) } func compareFileByLine(f1, f2 *os.File) { sc1 := bufio.NewScanner(f1) sc2 := bufio.NewScanner(f2) for { sc1Bool := sc1.Scan() sc2Bool := sc2.Scan() if !sc1Bool \u0026amp;\u0026amp; !sc2Bool { break } compareLines(sc1.Text(), sc2.Text()) } } $ go run main.go ### 通过校验和比较 ### Sum: 5A07C1538087CD5B5C365DE52970E0A3 and Sum: 5A07C1538087CD5B5C365DE52970E0A3 match Sum: 5A07C1538087CD5B5C365DE52970E0A3 and Sum: FED2EADA5D1D1EBF745DFDC7D1385E6C does not match ### 逐行比较 ### x | Hello | Not matching o | Golang is great | Golang is great x | | Last line 原理 两个文件的比较可以通过几种方式完成。 本文介绍了两种基本的方法。 第一个是通过创建文件的校验来比较整个文件。\n第二种方法逐行比较文件（在本例中为字符串内容）。 如果不匹配，则标记x符号。 这与比较二进制内容的方式相同，但需要按字节块（字节切片）扫描文件。\n","id":29,"section":"posts","summary":"\u003cp\u003e本文将向你展示如何快速确定两个文件是否相同。还将为你提供一种找到两者之间差异的方法。\u003c/p\u003e","tags":["go"],"title":"go基础库之比较两个文件","uri":"https://www.ganymedenil.com/2019/06/08/go-standard-library-by-compare-two-files.html","year":"2019"},{"content":"本文将介绍如何以编程的方式更改文件权限。\n更改文件权限 Golang 版本 1.12.1\n前言 本文将介绍如何以编程的方式更改文件权限。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { f, err := os.Create(\u0026quot;testfile\u0026quot;) if err != nil { panic(err) } defer f.Close() // 获取当前权限 fi, err := f.Stat() if err != nil { panic(err) } fmt.Printf(\u0026quot;文件权限 %v\\n\u0026quot;, fi.Mode()) // 更改权限 err = f.Chmod(0777) if err != nil { panic(err) } fi, err = f.Stat() if err != nil { panic(err) } fmt.Printf(\u0026quot;文件权限 %v\\n\u0026quot;, fi.Mode()) } $ go run main.go 文件权限 -rw-rw-rw- 文件权限 -rwxrwxrwx 原理 os包中的File类型的Chmod方法可用于更改文件权限。 上面的示例只是创建文件并将权限更改为0777。\n请注意，fi.Mode()被调用两次，因为它提取了文件当前状态的权限（os.FileMode）。\n更改权限的最短方法是使用os.Chmod函数，该函数也是如此，但不需要在代码中获取文件类型。\n","id":30,"section":"posts","summary":"\u003cp\u003e本文将介绍如何以编程的方式更改文件权限。\u003c/p\u003e","tags":["go"],"title":"go基础库之更改文件权限","uri":"https://www.ganymedenil.com/2019/06/07/go-standard-library-by-change-file-permissions.html","year":"2019"},{"content":"本文将展示如何列出目录内容。\n列出目录 Golang 版本 1.12.1\n前言 本文将展示如何列出目录内容。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; \u0026quot;path/filepath\u0026quot; ) func main() { fmt.Println(\u0026quot;List by ReadDir\u0026quot;) listDirByReadDir(\u0026quot;.\u0026quot;) fmt.Println() fmt.Println(\u0026quot;List by Walk\u0026quot;) listDirByWalk(\u0026quot;.\u0026quot;) } func listDirByWalk(path string) { filepath.Walk(path, func(wPath string, info os.FileInfo, err error) error { if wPath == path { return nil } if info.IsDir() { fmt.Printf(\u0026quot;[%s]\\n\u0026quot;, wPath) return filepath.SkipDir } if wPath != path { fmt.Println(wPath) } return nil }) } func listDirByReadDir(path string) { lst, err := ioutil.ReadDir(path) if err != nil { panic(err) } for _, val := range lst { if val.IsDir() { fmt.Printf(\u0026quot;[%s]\\n\u0026quot;, val.Name()) } else { fmt.Println(val.Name()) } } } $ go run main.go List by ReadDir [folder] main.go List by Walk [folder] main.go 原理 列出上述示例的文件夹使用了两种方法。 第一个简单的方法是使用listDirByReadDir函数实现，并使用ioutil包中的ReadDir函数。 此函数返回实际目录内容的FileInfo结构片。 请注意，ReadDir函数不会递归读取文件夹。 实际上，ReadDir函数在内部使用os包中的File类型的Readdir方法。\n另一种方法，更复杂，listDirByWalk使用filepath.Walk函数，该函数遍历路径并具有处理任何给定路径中的每个文件或文件夹的函数。 主要区别在于Walk函数以递归方式读取目录。 这种方法的核心部分是WalkFunc类型，其功能是使用列表的结果。 请注意，该函数通过返回filepath.SkipDir错误来阻止对基础文件夹的递归调用。 Walk函数也首先处理被调用的路径，所以你也需要处理它（在这种情况下，我们跳过打印并返回nil，因为我们需要递归处理这个文件夹）。\n","id":31,"section":"posts","summary":"\u003cp\u003e本文将展示如何列出目录内容。\u003c/p\u003e","tags":["go"],"title":"go基础库之列出目录","uri":"https://www.ganymedenil.com/2019/06/07/go-standard-library-by-list-directory.html","year":"2019"},{"content":"Go支持多种方式来进行写文件操作。\n写文件 Golang 版本 1.12.1\n前言 Go支持多种方式来进行写文件操作。\n实现 package main import ( \u0026quot;io\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strings\u0026quot; ) func main() { f, err := os.Create(\u0026quot;sample.file\u0026quot;) if err != nil { panic(err) } defer f.Close() _, err = f.WriteString(\u0026quot;Go is awesome!\\n\u0026quot;) if err != nil { panic(err) } _, err = io.Copy(f, strings.NewReader(\u0026quot;Yeah! Go is great.\\n\u0026quot;)) if err != nil { panic(err) } } $ go run main.go $ cat sample.file Go is awesome! Yeah! Go is great. 原理 os.File类型实现了Writer接口，因此可以通过任何使用Writer接口的选项来写入文件。 前面的示例使用os.File类型的WriteString方法。 一般来说，io.WriteString方法也可以使用。\n","id":32,"section":"posts","summary":"\u003cp\u003eGo支持多种方式来进行写文件操作。\u003c/p\u003e","tags":["go"],"title":"go基础库之写文件","uri":"https://www.ganymedenil.com/2019/06/06/go-standard-library-by-write-file.html","year":"2019"},{"content":"本文将演示如果从多个goroutine安全地写入文件。\n多个goroutine写文件 Golang 版本 1.12.1\n前言 本文将演示如果从多个goroutine安全地写入文件。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;os\u0026quot; \u0026quot;sync\u0026quot; ) type SyncWriter struct { m sync.Mutex Writer io.Writer } func (w *SyncWriter) Write(b []byte) (n int, err error) { w.m.Lock() defer w.m.Unlock() return w.Writer.Write(b) } var data = []string{ \u0026quot;Hello!\u0026quot;, \u0026quot;Ola!\u0026quot;, \u0026quot;Ahoj!\u0026quot;, } func main() { f, err := os.Create(\u0026quot;sample.file\u0026quot;) if err != nil { panic(err) } wr := \u0026amp;SyncWriter{sync.Mutex{}, f} wg := sync.WaitGroup{} for _, val := range data { wg.Add(1) go func(greetings string) { fmt.Fprintln(wr, greetings) wg.Done() }(val) } wg.Wait() } $ go run main.go $ cat sample.file Hello! Ahoj! Ola! 原理 并发写入文件是一个问题，最终可能会导致文件内容不一致。 最好使用Mutex或任何其他同步原语同步写入文件。 这样，可以确保一次只能有一个goroutine能够写入文件。\n上面的代码创建了一个带有Mutex的Writer，它嵌入了Writer（在本例中为os.File），对于每个Write调用，内部锁定Mutex以提供独占性。 写操作完成后，Mutex原语自然解锁。\n","id":33,"section":"posts","summary":"\u003cp\u003e本文将演示如果从多个goroutine安全地写入文件。\u003c/p\u003e","tags":["go"],"title":"go基础库之多个goroutine写文件","uri":"https://www.ganymedenil.com/2019/06/06/go-standard-library-by-multiple-goroutine-write-files.html","year":"2019"},{"content":"如果需要获取访问文件的基本信息，Go标准库提供了相关的方法。\n获取文件信息 Golang 版本 1.12.1\n前言 如果需要获取访问文件的基本信息，Go标准库提供了相关的方法。\n实现 创建文件testfile，内容如下：\nThis is test file. 创建文件fileinfo.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { f, err := os.Open(\u0026quot;testfile\u0026quot;) if err != nil { panic(err) } fi, err := f.Stat() if err != nil { panic(err) } fmt.Printf(\u0026quot;File name: %v\\n\u0026quot;, fi.Name()) fmt.Printf(\u0026quot;Is Directory: %t\\n\u0026quot;, fi.IsDir()) fmt.Printf(\u0026quot;Size: %d\\n\u0026quot;, fi.Size()) fmt.Printf(\u0026quot;Mode: %v\\n\u0026quot;, fi.Mode()) } $ go run fileinfo.go File name: testfile Is Directory: false Size: 18 Mode: -rw-rw-rw- 原理 os.File类型通过Stat方法提供对FileInfo类型的访问。 FileInfo结构包含有关该文件的所有基本信息。\n","id":34,"section":"posts","summary":"\u003cp\u003e如果需要获取访问文件的基本信息，Go标准库提供了相关的方法。\u003c/p\u003e","tags":["go"],"title":"go基础库之获取文件信息","uri":"https://www.ganymedenil.com/2019/06/05/go-standard-library-by-get-file-information.html","year":"2019"},{"content":"临时文件通常在运行测试用例时使用，或者如果你的应用需要存储短期内容（如用户上传的临时数据）。\n创建临时文件 Golang 版本 1.12.1\n前言 临时文件通常在运行测试用例时使用，或者如果你的应用需要存储短期内容（如用户上传的临时数据）。\n实现 package main import \u0026quot;io/ioutil\u0026quot; import \u0026quot;os\u0026quot; import \u0026quot;fmt\u0026quot; func main() { tFile, err := ioutil.TempFile(\u0026quot;\u0026quot;, \u0026quot;gostandardlibrary\u0026quot;) if err != nil { panic(err) } // The called is responsible for handling // the clean up. defer os.Remove(tFile.Name()) fmt.Println(tFile.Name()) // TempDir returns // the path in string. tDir, err := ioutil.TempDir(\u0026quot;\u0026quot;, \u0026quot;gostandardlibrary\u0026quot;) if err != nil { panic(err) } defer os.Remove(tDir) fmt.Println(tDir) } $ go run main.go C:\\Users\\Ganymedenil\\AppData\\Local\\Temp\\gostandardlibrary308359067 C:\\Users\\Ganymedenil\\AppData\\Local\\Temp\\gostandardlibrary531728446 原理 ioutil包中包含TempFile和TempDir函数。 TempFile函数参数为目录和文件前缀。 它返回带有临时文件的os.File。 请注意，调用者负责清除文件。 前面的示例使用os.Remove函数来执行此操作。\nTempDir函数的工作方式与TempFile相同。 不同之处在于它返回包含目录路径的字符串。\n临时file/dir名称由前缀和随机后缀组成。 使用相同参数调用TempFile/Dir函数的多个程序将不会得到相同的结果。\n","id":35,"section":"posts","summary":"\u003cp\u003e临时文件通常在运行测试用例时使用，或者如果你的应用需要存储短期内容（如用户上传的临时数据）。\u003c/p\u003e","tags":["go"],"title":"go基础库之创建临时文件","uri":"https://www.ganymedenil.com/2019/06/05/go-standard-library-by-create-a-temporary-file.html","year":"2019"},{"content":"本文将讲解一个实例，你的程序从不可靠的源中使用JSON，而JSON包含一个对象数组，这些对象具有开始标记[但数组中的项目数非常大，并且JSON的结尾可能被破坏。\n从不完整的JSON数组中提取数据 Golang 版本 1.12.1\n前沿 本文将讲解一个实例，你的程序从不可靠的源中使用JSON，而JSON包含一个对象数组，这些对象具有开始标记[但数组中的项目数非常大，并且JSON的结尾可能被破坏。\n实现 package main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const js = ` [ { \u0026quot;name\u0026quot;:\u0026quot;Axel\u0026quot;, \u0026quot;lastname\u0026quot;:\u0026quot;Fooley\u0026quot; }, { \u0026quot;name\u0026quot;:\u0026quot;Tim\u0026quot;, \u0026quot;lastname\u0026quot;:\u0026quot;Burton\u0026quot; }, { \u0026quot;name\u0026quot;:\u0026quot;Tim\u0026quot;, \u0026quot;lastname\u0026quot;:\u0026quot;Burton\u0026quot; ` type User struct { Name string `json:\u0026quot;name\u0026quot;` LastName string `json:\u0026quot;lastname\u0026quot;` } func main() { userSlice := make([]User, 0) r := strings.NewReader(js) dec := json.NewDecoder(r) for { tok, err := dec.Token() if err != nil { break } if tok == nil { break } switch tp := tok.(type) { case json.Delim: str := tp.String() if str == \u0026quot;[\u0026quot; || str == \u0026quot;{\u0026quot; { for dec.More() { u := User{} err := dec.Decode(\u0026amp;u) if err == nil { userSlice = append(userSlice, u) } else { break } } } } } fmt.Println(userSlice) } $go run main.go [{Axel Fooley} {Tim Burton}] 原理 除了Unmarshall函数，json包还包含Decoder API。 使用NewDecoder，可以创建Decoder 。 通过在解码器上调用Token方法，读取底层Reader并返回Token接口。 这可能包含多个值。\n其中一个是Delim类型，它是一个包含{，[，]，}字符之一的rune。 基于此，检测到JSON数组的开头。 利用解码器上的More方法，可以检测到更多要解码的对象。\n","id":36,"section":"posts","summary":"\u003cp\u003e本文将讲解一个实例，你的程序从不可靠的源中使用JSON，而JSON包含一个对象数组，这些对象具有开始标记\u003ccode\u003e[\u003c/code\u003e但数组中的项目数非常大，并且JSON的结尾可能被破坏。\u003c/p\u003e","tags":["go"],"title":"go基础库之从不完整的JSON数组中提取数据","uri":"https://www.ganymedenil.com/2019/06/04/go-standard-library-by-extract-data-from-an-incomplete-json-array.html","year":"2019"},{"content":"XML是一种非常常见的数据交换格式。Go库包含对以与JSON相同的方式解析XML文件的支持。通常，使用与XML方案对应的结构，并且在此帮助下，一次解析XML内容。问题是当XML文件太大而无法容纳到内存中时，需要以块的形式解析文件。本文将展示如何处理大型XML文件并解析所需信息。\n有效地解析大型XML文件 Golang 版本 1.12.1\n前沿 XML是一种非常常见的数据交换格式。Go库包含对以与JSON相同的方式解析XML文件的支持。通常，使用与XML方案对应的结构，并且在此帮助下，一次解析XML内容。问题是当XML文件太大而无法容纳到内存中时，需要以块的形式解析文件。本文将展示如何处理大型XML文件并解析所需信息。\n实现 创建文件data.xml，内容如下：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;catalog\u0026gt; \u0026lt;book id=\u0026quot;bk101\u0026quot;\u0026gt; \u0026lt;author\u0026gt;Gambardella, Matthew\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;XML Developer's Guide\u0026lt;/title\u0026gt; \u0026lt;genre\u0026gt;Computer\u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;44.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2000-10-01\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;An in-depth look at creating applications with XML.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book id=\u0026quot;bk112\u0026quot;\u0026gt; \u0026lt;author\u0026gt;Galos, Mike\u0026lt;/author\u0026gt; \u0026lt;title\u0026gt;Visual Studio 7: A Comprehensive Guide\u0026lt;/title\u0026gt; \u0026lt;genre\u0026gt;Computer\u0026lt;/genre\u0026gt; \u0026lt;price\u0026gt;49.95\u0026lt;/price\u0026gt; \u0026lt;publish_date\u0026gt;2001-04-16\u0026lt;/publish_date\u0026gt; \u0026lt;description\u0026gt;Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C++, C#, and ASP+ are integrated into a comprehensive development environment.\u0026lt;/description\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/catalog\u0026gt; 创建文件xml.go，代码如下：\npackage main import ( \u0026quot;encoding/xml\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) type Book struct { Title string `xml:\u0026quot;title\u0026quot;` Author string `xml:\u0026quot;author\u0026quot;` } func main() { f, err := os.Open(\u0026quot;data.xml\u0026quot;) if err != nil { panic(err) } defer f.Close() decoder := xml.NewDecoder(f) // 逐一阅读本书 books := make([]Book, 0) for { tok, _ := decoder.Token() if tok == nil { break } switch tp := tok.(type) { case xml.StartElement: if tp.Name.Local == \u0026quot;book\u0026quot; { // 将元素解码为struct var b Book decoder.DecodeElement(\u0026amp;b, \u0026amp;tp) books = append(books, b) } } } fmt.Println(books) } $ go run xml.go [{XML Developer's Guide Gambardella, Matthew} {Visual Studio 7: A Comprehensive Guide Galos, Mike}] 原理 使用xml包的NewDecoder函数，可以创建XML内容的Decoder。\n通过在Decoder上调用Token方法，接收xml.Token。 xml.Token是保存令牌类型的接口。 可以根据类型定义代码的行为。 示例代码测试解析的xml.StartElement是否是book元素之一。 然后它将数据部分解析为Book结构。 这样，Decoder中底层Reader中指针的位置被struct数据移位，并且解析可以继续。\n","id":37,"section":"posts","summary":"\u003cp\u003eXML是一种非常常见的数据交换格式。Go库包含对以与JSON相同的方式解析XML文件的支持。通常，使用与XML方案对应的结构，并且在此帮助下，一次解析XML内容。问题是当XML文件太大而无法容纳到内存中时，需要以块的形式解析文件。本文将展示如何处理大型XML文件并解析所需信息。\u003c/p\u003e","tags":["go"],"title":"go基础库之有效地解析大型XML文件","uri":"https://www.ganymedenil.com/2019/06/04/go-standard-library-by-effectively-parse-large-xml-files.html","year":"2019"},{"content":"除了众所周知的JSON和XML之外，Go还提供二进制格式 gob。本文将介绍如何使用gob包。\n将对象序列化为二进制格式 Golang 版本 1.12.1\n前沿 除了众所周知的JSON和XML之外，Go还提供二进制格式 gob。本文将介绍如何使用gob包。\n实现 package main import ( \u0026quot;bytes\u0026quot; \u0026quot;encoding/gob\u0026quot; \u0026quot;fmt\u0026quot; ) type User struct { FirstName string LastName string Age int Active bool } func (u User) String() string { return fmt.Sprintf(`{\u0026quot;FirstName\u0026quot;:%s,\u0026quot;LastName\u0026quot;:%s, \u0026quot;Age\u0026quot;:%d,\u0026quot;Active\u0026quot;:%v }`, u.FirstName, u.LastName, u.Age, u.Active) } type SimpleUser struct { FirstName string LastName string } func (u SimpleUser) String() string { return fmt.Sprintf(`{\u0026quot;FirstName\u0026quot;:%s,\u0026quot;LastName\u0026quot;:%s}`, u.FirstName, u.LastName) } func main() { var buff bytes.Buffer // Encode value enc := gob.NewEncoder(\u0026amp;buff) user := User{ \u0026quot;Radomir\u0026quot;, \u0026quot;Sohlich\u0026quot;, 30, true, } enc.Encode(user) fmt.Printf(\u0026quot;%X\\n\u0026quot;, buff.Bytes()) // Decode value out := User{} dec := gob.NewDecoder(\u0026amp;buff) dec.Decode(\u0026amp;out) fmt.Println(out.String()) enc.Encode(user) out2 := SimpleUser{} dec.Decode(\u0026amp;out2) fmt.Println(out2.String()) } $ go run main.go 40FF81030101045573657201FF82000104010946697273744E616D65010C0001084C6173744E616D65010C0001034167650104000106416374697665010200000019FF8201075261646F6D69720107536F686C696368013C010100 {\u0026quot;FirstName\u0026quot;:Radomir,\u0026quot;LastName\u0026quot;:Sohlich,\u0026quot;Age\u0026quot;:30,\u0026quot;Active\u0026quot;:true } {\u0026quot;FirstName\u0026quot;:Radomir,\u0026quot;LastName\u0026quot;:Sohlich} 原理 gob序列化和反序列化需要编码器和解码器。 gob.NewEncoder函数使用底层Writer创建Encoder。 每次调用Encode方法都会将对象序列化为gob格式。 gob格式本身就是自描述的二进制格式。 这意味着每个序列化结构前面都有其描述。\n要解码序列化形式的数据，必须通过使用底层Reader调用gob.NewDecoder来创建解码器。 然后，Decode接受指向该反序列化数据的结构指针。\n请注意，gob格式不需要源和目标类型完全匹配。 有关规则，请参阅encoding/gob包。\n","id":38,"section":"posts","summary":"\u003cp\u003e除了众所周知的JSON和XML之外，Go还提供二进制格式 \u003ccode\u003egob\u003c/code\u003e。本文将介绍如何使用\u003ccode\u003egob\u003c/code\u003e包。\u003c/p\u003e","tags":["go"],"title":"go基础库之将对象序列化为二进制格式","uri":"https://www.ganymedenil.com/2019/06/03/go-standard-library-by-serialize-objects-into-binary-format.html","year":"2019"},{"content":"ZIP压缩是一种广泛使用的压缩格式。通常使用场景是将文件集打包为ZIP格式，或者，将压缩文件解压缩。本文将展示如何使用标准库以编程方式处理ZIP文件。\n读写ZIP文件 Golang 版本 1.12.1\n前沿 ZIP压缩是一种广泛使用的压缩格式。通常使用场景是将文件集打包为ZIP格式，或者，将压缩文件解压缩。本文将展示如何使用标准库以编程方式处理ZIP文件。\n实现 package main import ( \u0026quot;archive/zip\u0026quot; \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; ) func main() { var buff bytes.Buffer // 压缩内容 zipW := zip.NewWriter(\u0026amp;buff) f, err := zipW.Create(\u0026quot;newfile.txt\u0026quot;) if err != nil { panic(err) } _, err = f.Write([]byte(\u0026quot;This is my file content\u0026quot;)) if err != nil { panic(err) } err = zipW.Close() if err != nil { panic(err) } // 将输出写入文件 err = ioutil.WriteFile(\u0026quot;data.zip\u0026quot;, buff.Bytes(), os.ModePerm) if err != nil { panic(err) } // 解压缩内容 zipR, err := zip.OpenReader(\u0026quot;data.zip\u0026quot;) if err != nil { panic(err) } for _, file := range zipR.File { fmt.Println(\u0026quot;File \u0026quot; + file.Name + \u0026quot; contains:\u0026quot;) r, err := file.Open() if err != nil { log.Fatal(err) } _, err = io.Copy(os.Stdout, r) if err != nil { panic(err) } err = r.Close() if err != nil { panic(err) } fmt.Println() } } $ go run main.go File newfile.txt contains: This is my file content 原理 内置包zip包含NewWriter和NewReader函数，用于创建zip.Writer以进行压缩，zip.Reader用于解压缩。\nZIP文件的每个记录都是使用zip.Writer的Create方法创建的。 然后返回Writer编写内容正文。\n要解压缩文件，OpenReader函数用于创建压缩文件中记录的ReadCloser。 创建的ReaderCloser的File字段是zip.File指针的一部分。 通过调用Open方法并读取返回的ReadCloser来获取文件的内容。\n可以通过Create方法中添加斜杠来创建文件夹。 例如folder/newfile.txt。\n","id":39,"section":"posts","summary":"\u003cp\u003eZIP压缩是一种广泛使用的压缩格式。通常使用场景是将文件集打包为ZIP格式，或者，将压缩文件解压缩。本文将展示如何使用标准库以编程方式处理ZIP文件。\u003c/p\u003e","tags":["go"],"title":"go基础库之读写ZIP文件","uri":"https://www.ganymedenil.com/2019/06/03/go-standard-library-by-read-and-write-zip-files.html","year":"2019"},{"content":"进程之间的管道是使用第一个进程的输出作为其他进程的输入的简单方法。这可以在Go中执行相同的概念，例如，将数据从一个套接字传输到另一个套接字，以创建隧道连接。本文将向你展示如何使用Go内置库创建管道。\nwriter和reader之间的管道 Golang 版本 1.12.1\n前言 进程之间的管道是使用第一个进程的输出作为其他进程的输入的简单方法。这可以在Go中执行相同的概念，例如，将数据从一个套接字传输到另一个套接字，以创建隧道连接。本文将向你展示如何使用Go内置库创建管道。\n实现 package main import ( \u0026quot;io\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/exec\u0026quot; ) func main() { pReader, pWriter := io.Pipe() cmd := exec.Command(\u0026quot;echo\u0026quot;, \u0026quot;Hello Go!\\nThis is example\u0026quot;) cmd.Stdout = pWriter go func() { defer pReader.Close() if _, err := io.Copy(os.Stdout, pReader); err != nil { log.Fatal(err) } }() if err := cmd.Run(); err != nil { log.Fatal(err) } } $ go run main.go Hello Go! This is example 原理 io.Pipe函数创建内存管道并返回管道的两端，一侧是PipeReader，另一侧是PipeWriter。 每个Write到PipeWriter都被阻塞，直到另一端被Read消耗为止。\n该示例显示从执行的命令到父程序的标准输出的管道输出。通过将pWriter分配给cmd.Stdout，子进程的标准输出被写入管道，goroutine中的io.Copy通过将数据复制到os.Stdout来消耗写入的数据。\n","id":40,"section":"posts","summary":"\u003cp\u003e进程之间的管道是使用第一个进程的输出作为其他进程的输入的简单方法。这可以在Go中执行相同的概念，例如，将数据从一个套接字传输到另一个套接字，以创建隧道连接。本文将向你展示如何使用Go内置库创建管道。\u003c/p\u003e","tags":["go"],"title":"go基础库之writer和reader之间的管道","uri":"https://www.ganymedenil.com/2019/06/02/go-standard-library-by-pipe-between-writer-and-reader.html","year":"2019"},{"content":"当您需要将相同的输出写入多个目标时，内置包中可以提供帮助。本文展示了如何同时实现多个目标的写入。\n一次写入多个writers Golang 版本 1.12.1\n前言 当您需要将相同的输出写入多个目标时，内置包中可以提供帮助。本文展示了如何同时实现多个目标的写入。\n实现 package main import \u0026quot;io\u0026quot; import \u0026quot;bytes\u0026quot; import \u0026quot;os\u0026quot; import \u0026quot;fmt\u0026quot; func main() { buf := bytes.NewBuffer([]byte{}) f, err := os.OpenFile(\u0026quot;sample.txt\u0026quot;, os.O_CREATE|os.O_RDWR, os.ModePerm) if err != nil { panic(err) } wr := io.MultiWriter(buf, f) _, err = io.WriteString(wr, \u0026quot;Hello, Go is awesome!\u0026quot;) if err != nil { panic(err) } fmt.Println(\u0026quot;Content of buffer: \u0026quot; + buf.String()) } $ go run main.go Content of buffer: Hello, Go is awesome! 原理 io包中包含MultiWriter函数它具有可变参数的Writers。 当调用Writer上的Write方法时，数据将写入所有底层Writer。\n","id":41,"section":"posts","summary":"\u003cp\u003e当您需要将相同的输出写入多个目标时，内置包中可以提供帮助。本文展示了如何同时实现多个目标的写入。\u003c/p\u003e","tags":["go"],"title":"go基础库之一次写入多个writers","uri":"https://www.ganymedenil.com/2019/06/02/go-standard-library-by-write-multiple-writers-at-once.html","year":"2019"},{"content":"本文讲解了如何以二进制形式编写和读取任何类型。\n读写二进制数据 Golang 版本 1.12.1\n前言 本文讲解了如何以二进制形式编写和读取任何类型。\n实现 package main import ( \u0026quot;bytes\u0026quot; \u0026quot;encoding/binary\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { // Writing binary values buf := bytes.NewBuffer([]byte{}) if err := binary.Write(buf, binary.BigEndian, 1.004); err != nil { panic(err) } if err := binary.Write(buf, binary.BigEndian, []byte(\u0026quot;Hello\u0026quot;)); err != nil { panic(err) } // Reading the written values var num float64 if err := binary.Read(buf, binary.BigEndian, \u0026amp;num); err != nil { panic(err) } fmt.Printf(\u0026quot;float64: %.3f\\n\u0026quot;, num) greeting := make([]byte, 5) if err := binary.Read(buf, binary.BigEndian, \u0026amp;greeting); err != nil { panic(err) } fmt.Printf(\u0026quot;string: %s\\n\u0026quot;, string(greeting)) } $ go run main.go float64: 1.004 string: Hello 原理 可以使用encoding/binary包写入二进制数据。 Write函数使用Writer写入数据的位置，字节顺序（BigEndian/LittleEndian），最后写入要写入Writer的值。\n为了模拟读取二进制数据，可以使用read函数。注意，从二进制源读取数据并没有什么神奇之处。你需要确定从Reader中获取的是什么数据。如果没有，则可以将数据获取到适合该大小的任何类型。\n","id":42,"section":"posts","summary":"\u003cp\u003e本文讲解了如何以二进制形式编写和读取任何类型。\u003c/p\u003e","tags":["go"],"title":"go基础库之读写二进制数据","uri":"https://www.ganymedenil.com/2019/06/02/go-standard-library-by-read-and-write-binary-data.html","year":"2019"},{"content":"在某些情况下，需要从文件中的特定位置读取或写入，例如索引文件。本文将向你展示如何在平面文件操作上下文中使用位置搜索。\n在文件中寻找位置 Golang 版本 1.12.1\n前言 在某些情况下，需要从文件中的特定位置读取或写入，例如索引文件。本文将向你展示如何在平面文件操作上下文中使用位置搜索。\n实现 创建文件flatfile.txt，内容如下：\n123.Jun.......Wong...... 12..Novak.....Jurgen.... 10..Thomas....Sohlich... 创建文件fileseek.go，代码如下：\npackage main import ( \u0026quot;errors\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) const lineLegth = 25 func main() { f, e := os.OpenFile(\u0026quot;flatfile.txt\u0026quot;, os.O_RDWR|os.O_CREATE, os.ModePerm) if e != nil { panic(e) } defer f.Close() fmt.Println(readRecords(2, \u0026quot;last\u0026quot;, f)) if err := writeRecord(2, \u0026quot;first\u0026quot;, \u0026quot;Radomir\u0026quot;, f); err != nil { panic(err) } fmt.Println(readRecords(2, \u0026quot;first\u0026quot;, f)) if err := writeRecord(10, \u0026quot;first\u0026quot;, \u0026quot;Andrew\u0026quot;, f); err != nil { panic(err) } fmt.Println(readRecords(10, \u0026quot;first\u0026quot;, f)) fmt.Println(readLine(2, f)) } func readLine(line int, f *os.File) (string, error) { lineBuffer := make([]byte, 24) f.Seek(int64(line*lineLegth), 0) _, err := f.Read(lineBuffer) return string(lineBuffer), err } func writeRecord(line int, column, dataStr string, f *os.File)error { definedLen := 10 position := int64(line * lineLegth) switch column { case \u0026quot;id\u0026quot;: definedLen = 4 case \u0026quot;first\u0026quot;: position += 4 case \u0026quot;last\u0026quot;: position += 14 default: return errors.New(\u0026quot;Column not defined\u0026quot;) } if len([]byte(dataStr)) \u0026gt; definedLen { return fmt.Errorf(\u0026quot;Maximum length for '%s' is %d\u0026quot;, column, definedLen) } data := make([]byte, definedLen) for i := range data { data[i] = '.' } copy(data, []byte(dataStr)) _, err := f.WriteAt(data, position) return err } func readRecords(line int, column string, f *os.File)(string, error) { lineBuffer := make([]byte, 24) f.ReadAt(lineBuffer, int64(line*lineLegth)) var retVal string switch column { case \u0026quot;id\u0026quot;: return string(lineBuffer[:3]), nil case \u0026quot;first\u0026quot;: return string(lineBuffer[4:13]), nil case \u0026quot;last\u0026quot;: return string(lineBuffer[14:23]), nil } return retVal, errors.New(\u0026quot;Column not defined\u0026quot;) } $ go run fileseek.go Sohlich.. \u0026lt;nil\u0026gt; Radomir.. \u0026lt;nil\u0026gt; Andrew... \u0026lt;nil\u0026gt; 10..Radomir...Sohlich... \u0026lt;nil\u0026gt; 我们可以使用十六进制看一下flatfile.txt，使用xxd flatfile.txt。\n$ xxd flatfile.txt 00000000: 3132 332e 4a75 6e2e 2e2e 2e2e 2e2e 576f 123.Jun.......Wo 00000010: 6e67 2e2e 2e2e 2e2e 0a31 322e 2e4e 6f76 ng.......12..Nov 00000020: 616b 2e2e 2e2e 2e4a 7572 6765 6e2e 2e2e ak.....Jurgen... 00000030: 2e0a 3130 2e2e 5261 646f 6d69 722e 2e2e ..10..Radomir... 00000040: 536f 686c 6963 682e 2e2e 0000 0000 0000 Sohlich......... 00000050: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000060: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000070: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000080: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000090: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 000000a0: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 000000b0: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 000000c0: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 000000d0: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 000000e0: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 000000f0: 0000 0000 0000 0000 0000 0000 0000 416e ..............An 00000100: 6472 6577 2e2e 2e2e drew.... 原理 前面的示例使用平面文件展示了如何在文件中进行位置查找、读取和写入。通常，要移动File当前指针的位置，可以使用Seek方法。它有两个参数，分别是位置和如何计算位置，0 -相对于文件原点，1 -相对于当前位置，2 -相对于文件结束。这样就可以在文件中移动光标。在前面代码中的readLine函数的实现中使用了Seek方法。\n平面文件是存储数据的最基本形式。其记录格式一般具有固定的长度，并且每一条记录的格式也是相同的。示例中的平面文件的结构是：ID-4个字符，FirstName-10个字符，LastName-10个字符。 整个记录长24个字符，以第25个字符的换行符结束。\nos.File还包含ReadAt和WriteAt方法。这些方法将字节数据写入/读取从何处开始的偏移量。这样可以将写和读简化到文件中的某个位置。\n注意，本例假设每个rune只有一个字节，对于特殊字符，不必为true，以此类推。\n","id":43,"section":"posts","summary":"\u003cp\u003e在某些情况下，需要从文件中的特定位置读取或写入，例如索引文件。本文将向你展示如何在平面文件操作上下文中使用位置搜索。\u003c/p\u003e","tags":["go"],"title":"go基础库之在文件中寻找位置","uri":"https://www.ganymedenil.com/2019/06/02/go-standard-library-by-find-the-location-in-the-file.html","year":"2019"},{"content":"不同的输入源可以使用不同的字符集，用Go开发的应用中也不例外。现在许多用户都使用的Windows系统，当然也有其他的系统。默认情况下，Go希望程序中使用的字符编码都为UTF-8。如果不是，则必须对给定的字符集进行解码，以便能够正确处理字符串。本文将介绍非UTF-8的字符集如何进行文件读写。\n读/写不同的字符集 Golang 版本 1.12.1\n前言 不同的输入源可以使用不同的字符集，用Go开发的应用中也不例外。现在许多用户都使用的Windows系统，当然也有其他的系统。默认情况下，Go希望程序中使用的字符编码都为UTF-8。如果不是，则必须对给定的字符集进行解码，以便能够正确处理字符串。本文将介绍非UTF-8的字符集如何进行文件读写。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;golang.org/x/text/encoding/charmap\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; ) func main() { // 将字符串编码为Windows-1252并写入文件 encoder := charmap.Windows1252.NewEncoder() s, e := encoder.String(\u0026quot;This is sample text with runes Š\u0026quot;) if e != nil { panic(e) } ioutil.WriteFile(\u0026quot;example.txt\u0026quot;, []byte(s), os.ModePerm) // 解码为UTF-8 f, e := os.Open(\u0026quot;example.txt\u0026quot;) if e != nil { panic(e) } defer f.Close() decoder := charmap.Windows1252.NewDecoder() reader := decoder.Reader(f) b, err := ioutil.ReadAll(reader) if err != nil { panic(err) } fmt.Println(string(b)) } $ go run main.go This is sample text with runes Š 原理 golang.org/x/text/encoding/charmap包中包含广泛使用的字符集的Charmap类型指针常量。 Charmap类型提供了为给定字符集创建编码器和解码器的方法。 Encoder创建编码Writer，它将写入的字节编码到所选的字符集。 类似地，Decoder可以创建解码Reader，其将读取到的所有数据解码到所选的字符集。\n","id":44,"section":"posts","summary":"\u003cp\u003e不同的输入源可以使用不同的字符集，用Go开发的应用中也不例外。现在许多用户都使用的Windows系统，当然也有其他的系统。默认情况下，Go希望程序中使用的字符编码都为UTF-8。如果不是，则必须对给定的字符集进行解码，以便能够正确处理字符串。本文将介绍非UTF-8的字符集如何进行文件读写。\u003c/p\u003e","tags":["go"],"title":"go基础库之读/写不同的字符集","uri":"https://www.ganymedenil.com/2019/05/31/go-standard-library-by-read-write-different-character-sets.html","year":"2019"},{"content":"在前面的文章中，我们使用Stdin来读数据还有如何读取文件中的内容。在本文中我们将把两者结合起来，给大家展示如何从文件读入字符串。\n从文件读入字符串 Golang 版本 1.12.1\n前言 在前面的文章中，我们使用Stdin来读数据还有如何读取文件中的内容。在本文中我们将把两者结合起来，给大家展示如何从文件读入字符串。\n实现 创建tmp目录，在tmp目录中创建file.txt文件，并在文件内写入如下内容：\n这是文件内容 创建文件readfile.go，代码如下：\npackage main import ( \u0026quot;bufio\u0026quot; \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; ) func main() { fmt.Println(\u0026quot;### 用reader读取文件 ###\u0026quot;) f, err := os.Open(\u0026quot;temp/file.txt\u0026quot;) if err != nil { panic(err) } defer f.Close() // 用reader读取文件 wr := bytes.Buffer{} sc := bufio.NewScanner(f) for sc.Scan() { wr.WriteString(sc.Text()) } fmt.Println(wr.String()) fmt.Println(\u0026quot;### ReadFile ###\u0026quot;) // 对于较小的文件 fContent, err := ioutil.ReadFile(\u0026quot;temp/file.txt\u0026quot;) if err != nil { panic(err) } fmt.Println(string(fContent)) } $ go run readfile.go ### 用reader读取文件 ### 这是文件内容 ### ReadFile ### 这是文件内容 原理 从文件中读取很简单，因为File类型实现了Reader 和Writer 接口。这样，所有适用于Reader接口的函数和方法都适用于File类型。上面的示例展示了如何使用Scanner读取文件，并将内容写入字节缓冲区(这比直接通过字符串连接性能更好)。这样，就可以控制从文件读取的内容量了。\n使用ioutil.ReadFile的第二种方法更简单，但应谨慎使用，因为它会读取整个文件。 请记住，文件可能很大，可能会威胁到应用程序的稳定性。\n","id":45,"section":"posts","summary":"\u003cp\u003e在前面的文章中，我们使用\u003ccode\u003eStdin\u003c/code\u003e来读数据还有如何读取文件中的内容。在本文中我们将把两者结合起来，给大家展示如何从文件读入字符串。\u003c/p\u003e","tags":["go"],"title":"go基础库之从文件读入字符串","uri":"https://www.ganymedenil.com/2019/05/31/go-standard-library-by-read-string-from-file.html","year":"2019"},{"content":"存储或读取数据的文件访问是一种非常常见的操作。本文展示了如何使用标准库按名称和路径打开文件。\n按名称打开文件 Golang 版本 1.12.1\n前言 存储或读取数据的文件访问是一种非常常见的操作。本文展示了如何使用标准库按名称和路径打开文件。\n实现 创建tmp目录，在tmp目录中创建file.txt文件，并在文件内写入如下内容：\n这是文件内容 创建文件openfile.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; ) func main() { f, err := os.Open(\u0026quot;temp/file.txt\u0026quot;) if err != nil { panic(err) } c, err := ioutil.ReadAll(f) if err != nil { panic(err) } fmt.Printf(\u0026quot;### 文件内容 ###\\n%s\\n\u0026quot;, string(c)) f.Close() f, err = os.OpenFile(\u0026quot;temp/test.txt\u0026quot;, os.O_CREATE|os.O_RDWR, os.ModePerm) if err != nil { panic(err) } io.WriteString(f, \u0026quot;Test string\u0026quot;) f.Close() } $ go run openfile.go ### 文件内容 ### 这是文件内容 原理 os包提供了一种打开文件的简单方法。Open函数以只读模式按路径打开文件。另一个函数OpenFile功能更强大，它可以使用文件的路径、标志和权限来打开文件。\n标志常量在os包中定义，你可以使用二进制或操作符|组合它们。权限由os包常量(例如os.ModePerm)或者使用数字表示法，如0777(权限:-rwxrwxrwx)来设置。\n","id":46,"section":"posts","summary":"\u003cp\u003e存储或读取数据的文件访问是一种非常常见的操作。本文展示了如何使用标准库按名称和路径打开文件。\u003c/p\u003e","tags":["go"],"title":"go基础库之按名称打开文件","uri":"https://www.ganymedenil.com/2019/05/30/go-standard-library-by-open-file-by-name.html","year":"2019"},{"content":"每个进程都拥有自己的标准输入、输出和错误文件描述符。stdin作为进程的输入。本文将介绍如何从stdin读取数据。\n读取标准输入 Golang 版本 1.12.1\n前言 每个进程都拥有自己的标准输入、输出和错误文件描述符。stdin作为进程的输入。本文将介绍如何从stdin读取数据。\n实现 1.创建文件fmt.go，代码如下：\npackage main import \u0026quot;fmt\u0026quot; func main() { var name string fmt.Println(\u0026quot;你叫什么名字？\u0026quot;) fmt.Scanf(\u0026quot;%s\\n\u0026quot;, \u0026amp;name) var age int fmt.Println(\u0026quot;你几岁？\u0026quot;) fmt.Scanf(\u0026quot;%d\\n\u0026quot;, \u0026amp;age) fmt.Printf(\u0026quot;你好! %s, 你的年龄是 %d\\n\u0026quot;, name, age) } $ go run fmt.go 你叫什么名字？ GanymedeNil 你几岁？ 25 你好! GanymedeNil, 你的年龄是 25 2.创建文件scanner.go，代码如下：\npackage main import ( \u0026quot;bufio\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { // scan能够按行扫描输入 sc := bufio.NewScanner(os.Stdin) for sc.Scan() { txt := sc.Text() fmt.Printf(\u0026quot;Echo: %s\\n\u0026quot;, txt) } } $ go run scanner.go Hello Echo: Hello 3.创建文件reader.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { for { data := make([]byte, 8) n, err := os.Stdin.Read(data) if err == nil \u0026amp;\u0026amp; n \u0026gt; 0 { process(data) } else { break } } } func process(data []byte) { fmt.Printf(\u0026quot;Received: %X %s\\n\u0026quot;, data, string(data)) } $ echo 'Go is awesome!' | go run reader.go Received: 476F206973206177 Go is aw Received: 65736F6D65210A00 esome! 原理 Go进程的stdin可以通过os包的Stdin获取。 实际上，它是一个实现Reader接口的File类型。 从Reader里读取是非常容易的。 前面的代码展示了如何从Stdin读取的三种非常常见的方法。\n第一个例子演示了fmt包的使用，它提供了Scan、Scanf和Scanln函数。Scanf函数将输入写入给定变量。Scanf的优点是你可以确定扫描值的格式。Scan函数只是将输入写入变量（没有预定义格式），Scanln顾名思义，读取以换行符结束的输入。\nScanner是第二个例子，它提供了扫描较大输入的便捷方式。Scanner 包含了Split功能，通过该功能可以自定义分割功能。 例如，要扫描stdin中的单词，可以使用bufio.ScanWords作为预定义的SplitFunc。\n通过Reader API读取是最后提出的方法。 这个可以让你更好地控制输入的读取方式。\n","id":47,"section":"posts","summary":"\u003cp\u003e每个进程都拥有自己的标准输入、输出和错误文件描述符。\u003ccode\u003estdin\u003c/code\u003e作为进程的输入。本文将介绍如何从\u003ccode\u003estdin\u003c/code\u003e读取数据。\u003c/p\u003e","tags":["go"],"title":"go基础库之读取标准输入","uri":"https://www.ganymedenil.com/2019/05/30/go-standard-library-by-read-standard-input.html","year":"2019"},{"content":"每个进程都各有一个stdin，stdout和 stderr文件描述符。使用的标准方法是stdout作为进程输出，stderr作为进程错误输出。由于这些是文件描述符，因此写入数据的目标可以是从控制台到套接字的任何内容。本文将告诉你如何编写stdout和stderr。\n编写标准输出和错误 Golang 版本 1.12.1\n前言 每个进程都各有一个stdin，stdout和 stderr文件描述符。使用的标准方法是stdout作为进程输出，stderr作为进程错误输出。由于这些是文件描述符，因此写入数据的目标可以是从控制台到套接字的任何内容。本文将告诉你如何编写stdout和stderr。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;os\u0026quot; ) func main() { // 只需写字符串 io.WriteString(os.Stdout, \u0026quot;这是标准输出的字符串。\\n\u0026quot;) io.WriteString(os.Stderr, \u0026quot;这是标准错误输出的字符串。\\n\u0026quot;) // Stdout/err实现了writer接口 buf := []byte{0xAF, 0xFF, 0xFE} for i := 0; i \u0026lt; 200; i++ { if _, e := os.Stdout.Write(buf); e != nil { panic(e) } } // fmt包也可以使用 fmt.Fprintln(os.Stdout, \u0026quot;\\n\u0026quot;) } $ go run main.go 这是标准错误输出的字符串。 这是标准输出的字符串。 ������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������ 原理 与前文中的Stdin一样，Stdout和Stderr是文件描述符。这些实现了Writer接口。\n上面的示例展示了几种方法展示了如何通过io.WriteString函数写入这些内容，分别是使用Writer API以及fmt包和FprintXX函数。\n","id":48,"section":"posts","summary":"\u003cp\u003e每个进程都各有一个\u003ccode\u003estdin\u003c/code\u003e，\u003ccode\u003estdout\u003c/code\u003e和 \u003ccode\u003estderr\u003c/code\u003e文件描述符。使用的标准方法是\u003ccode\u003estdout\u003c/code\u003e作为进程输出，\u003ccode\u003estderr\u003c/code\u003e作为进程错误输出。由于这些是文件描述符，因此写入数据的目标可以是从控制台到套接字的任何内容。本文将告诉你如何编写\u003ccode\u003estdout\u003c/code\u003e和\u003ccode\u003estderr\u003c/code\u003e。\u003c/p\u003e","tags":["go"],"title":"go基础库之编写标准输出和错误","uri":"https://www.ganymedenil.com/2019/05/29/go-standard-library-by-write-standard-output-and-errors.html","year":"2019"},{"content":"在某些情况下，输出(通常是数据输出)是通过选项卡文本完成的，该文本在排列良好的单元格中格式化。这种格式可以通过text/tabwriter包来实现。该包提供了Writer过滤器，它将带有制表符的文本转换为格式正确的输出。\n将文本与tabwriter对齐 Golang 版本 1.12.1\n前言 在某些情况下，输出(通常是数据输出)是通过选项卡文本完成的，该文本在排列良好的单元格中格式化。这种格式可以通过text/tabwriter包来实现。该包提供了Writer过滤器，它将带有制表符的文本转换为格式正确的输出。\n实现 创建文件tabwriter.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;text/tabwriter\u0026quot; ) func main() { w := tabwriter.NewWriter(os.Stdout, 15, 0, 1, ' ', tabwriter.AlignRight) fmt.Fprintln(w, \u0026quot;username\\tfirstname\\tlastname\\t\u0026quot;) fmt.Fprintln(w, \u0026quot;sohlich\\tRadomir\\tSohlich\\t\u0026quot;) fmt.Fprintln(w, \u0026quot;novak\\tJohn\\tSmith\\t\u0026quot;) w.Flush() } $ go run tabwriter.go username firstname lastname sohlich Radomir Sohlich novak John Smith 原理 NewWriter函数调用配置的参数创建Writer过滤器。 此Writer写入的所有数据都根据参数进行格式化。 os.Stdout在这里用于演示目的。\ntext/tabwriter包还提供了一些配置选项，例如flag参数。 最有用的是tabwriter.AlignRight，它将编写器配置为在每列中将内容对齐。\n","id":49,"section":"posts","summary":"\u003cp\u003e在某些情况下，输出(通常是数据输出)是通过选项卡文本完成的，该文本在排列良好的单元格中格式化。这种格式可以通过\u003ccode\u003etext/tabwriter\u003c/code\u003e包来实现。该包提供了\u003ccode\u003eWriter\u003c/code\u003e过滤器，它将带有制表符的文本转换为格式正确的输出。\u003c/p\u003e","tags":["go"],"title":"go基础库之将文本与tabwriter对齐","uri":"https://www.ganymedenil.com/2019/05/29/go-standard-library-by-align-text-with-tabwriter.html","year":"2019"},{"content":"本文将指导你完成文本文档的缩进和取消注释 。\n缩进文本文档 Golang 版本 1.12.1\n前言 本文将指导你完成文本文档的缩进和取消注释 。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;strings\u0026quot; \u0026quot;unicode\u0026quot; ) func main() { text := \u0026quot;Hi! Go is awesome.\u0026quot; text = Indent(text, 6) fmt.Println(text) text = Unindent(text, 3) fmt.Println(text) text = Unindent(text, 10) fmt.Println(text) text = IndentByRune(text, 10, '.') fmt.Println(text) } // 通过给定的缩进和rune缩进缩进输入 func IndentByRune(input string, indent int, r rune) string { return strings.Repeat(string(r), indent) + input } // 通过给定缩进缩进缩进输入 func Indent(input string, indent int) string { padding := indent + len(input) return fmt.Sprintf(\u0026quot;% \u0026quot;+strconv.Itoa(padding)+\u0026quot;s\u0026quot;, input) } // Unindent unindenting输入字符串。如果输入缩进小于“缩进”空格，则删除两者的最小值。 func Unindent(input string, indent int) string { count := 0 for _, val := range input { if unicode.IsSpace(val) { count++ } if count == indent || !unicode.IsSpace(val) { break } } return input[count:] } $ go run main.go Hi! Go is awesome. Hi! Go is awesome. Hi! Go is awesome. ..........Hi! Go is awesome. 原理 缩进和填充一样简单。在本例中，使用了相同的格式化选项。缩进实现的更具可读性的形式可以使用strings包的Repeat函数。前面代码中的IndentByRune函数应用了这种方法。\n在本例中，取消缩进意味着删除给定的前导空格数。前面代码中的Unindent实现删除了最小的前导空格数或给定的缩进。\n","id":50,"section":"posts","summary":"\u003cp\u003e本文将指导你完成文本文档的缩进和取消注释 。\u003c/p\u003e","tags":["go"],"title":"go基础库之缩进文本文档","uri":"https://www.ganymedenil.com/2019/05/28/go-standard-library-by-indented-text-document.html","year":"2019"},{"content":"字符串输入可能包含太多的空格，太少的空格或不适合的空格字符。此篇包含有关如何管理这些内容并根据需要格式化字符串的提示。\n管理字符串中的空格 Golang 版本 1.12.1\n前言 字符串输入可能包含太多的空格，太少的空格或不适合的空格字符。此篇包含有关如何管理这些内容并根据需要格式化字符串的提示。\n实现 创建文件whitespace.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;math\u0026quot; \u0026quot;regexp\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;strings\u0026quot; ) func main() { stringToTrim := \u0026quot;\\t\\t\\n Go \\tis\\t Awesome \\t\\t\u0026quot; trimResult := strings.TrimSpace(stringToTrim) fmt.Println(trimResult) stringWithSpaces := \u0026quot;\\t\\t\\n Go \\tis\\n Awesome \\t\\t\u0026quot; r := regexp.MustCompile(\u0026quot;\\\\s+\u0026quot;) replace := r.ReplaceAllString(stringWithSpaces, \u0026quot; \u0026quot;) fmt.Println(replace) needSpace := \u0026quot;need space\u0026quot; fmt.Println(pad(needSpace, 14, \u0026quot;CENTER\u0026quot;)) fmt.Println(pad(needSpace, 14, \u0026quot;LEFT\u0026quot;)) } func pad(input string, padLen int, align string) string { inputLen := len(input) if inputLen \u0026gt;= padLen { return input } repeat := padLen - inputLen var output string switch align { case \u0026quot;RIGHT\u0026quot;: output = fmt.Sprintf(\u0026quot;% \u0026quot;+strconv.Itoa(-padLen)+\u0026quot;s\u0026quot;, input) case \u0026quot;LEFT\u0026quot;: output = fmt.Sprintf(\u0026quot;% \u0026quot;+strconv.Itoa(padLen)+\u0026quot;s\u0026quot;, input) case \u0026quot;CENTER\u0026quot;: bothRepeat := float64(repeat) / float64(2) left := int(math.Floor(bothRepeat)) + inputLen right := int(math.Ceil(bothRepeat)) output = fmt.Sprintf(\u0026quot;% \u0026quot;+strconv.Itoa(left)+\u0026quot;s%\u0026quot;+strconv.Itoa(right)+\u0026quot;s\u0026quot;, input, \u0026quot;\u0026quot;) } return output } $ go run whitespace.go Go is\tAwesome Go is Awesome need space need space 原理 在代码处理字符串之前对其进行修剪是非常常见的实践，正如前面的代码所演示的，这很容易由标准的Go库完成。strings库还提供了TrimXXX函数的更多变体，它还允许从字符串中修剪其他字符。\n要修剪前边和结尾的空白，可以使用strings包的TrimSpace函数。这代表了代码的以下部分，这也包括在前面的例子中:\nstringToTrim := \u0026quot;\\t\\t\\n Go \\tis\\t Awesome \\t\\t\u0026quot; stringToTrim = strings.TrimSpace(stringToTrim) regex包适合替换多个空格和制表符，并且可以用这种方式为进一步处理字符串做好准备。注意，使用此方法，中断行被替换为单个空格。\n这部分代码表示使用正则表达式将所有多个空格替换为一个空格:\nr := regexp.MustCompile(\u0026quot;\\\\s+\u0026quot;) replace := r.ReplaceAllString(stringToTrim, \u0026quot; \u0026quot;) 填充不是string包的显式函数，但是可以通过fmt包的Sprintf函数来实现。代码中的pad函数使用格式化模式% \u0026lt;+/-padding\u0026gt;s和一些简单的数学运算来查找填充。最后，填充数字前的负号作为右pad，而正数作为左pad。\n","id":51,"section":"posts","summary":"\u003cp\u003e字符串输入可能包含太多的空格，太少的空格或不适合的空格字符。此篇包含有关如何管理这些内容并根据需要格式化字符串的提示。\u003c/p\u003e","tags":["go"],"title":"go基础库之管理字符串中的空格","uri":"https://www.ganymedenil.com/2019/05/28/go-standard-library-by-manage-spaces-in-strings.html","year":"2019"},{"content":"有多种表格数据格式。CSV（逗号分隔值）是主要用于数据传输和导出的最基本格式之一。没有定义CSV的标准，但RFC 4180中描述了格式本身。\n解析以逗号分隔的数据 Golang 版本 1.12.1\n前言 有多种表格数据格式。CSV（逗号分隔值）是主要用于数据传输和导出的最基本格式之一。没有定义CSV的标准，但RFC 4180中描述了格式本身。\n实现 创建文件data.csv，内容如下：\n\u0026quot;Name\u0026quot;,\u0026quot;Surname\u0026quot;,\u0026quot;Age\u0026quot; # this is comment in data \u0026quot;John\u0026quot;,\u0026quot;Mnemonic\u0026quot;,20 Maria,Tone,21 创建文件data.go，代码如下：\npackage main import ( \u0026quot;encoding/csv\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { file, err := os.Open(\u0026quot;data.csv\u0026quot;) if err != nil { panic(err) } defer file.Close() reader := csv.NewReader(file) reader.FieldsPerRecord = 3 reader.Comment = '#' for { record, e := reader.Read() if e != nil { fmt.Println(e) break } fmt.Println(record) } } $ go run data.go [Name Surname Age] [John Mnemonic 20] [Maria Tone 21] EOF 创建文件data_uncommon.csv，内容如下：\nName;Surname;Age \u0026quot;John\u0026quot;;Mnemonic;20 \u0026quot;Maria\u0026quot;;Tone;21 创建文件data_uncommon.go，代码如下：\npackage main import ( \u0026quot;encoding/csv\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { file, err := os.Open(\u0026quot;data_uncommon.csv\u0026quot;) if err != nil { panic(err) } defer file.Close() reader := csv.NewReader(file) reader.Comma = ';' for { record, e := reader.Read() if e != nil { fmt.Println(e) break } fmt.Println(record) } } $ go run data_uncommon.go [Name Surname Age] [John Mnemonic 20] [Maria Tone 21] EOF 原理 而不是简单地逐行扫描输入并使用strings.Split等方法解析CSV格式，Go提供了更好的方法。encoding/csv包中的NewReader函数返回Reader结构体，该结构提供了读取csv文件的API。Reader结构体根据你的需要保留变量来配置read参数。\nReader 的FieldsPerRecord参数是一个重要的设置。这样就可以验证每一行的单元格计数。默认情况下，当设置为0时，它被设置为第一行中的记录数。如果设置为正值，则记录的数量必须匹配。如果设置了负值，则没有单元格计数验证。\n另一个有趣的配置是注释参数，它允许您在已解析的数据中定义注释字符。在本例中，以这种方式忽略整行。\nGo 1.10现在禁止使用无意义的逗号和注释设置。这意味着null、回车、换行符、无效的符文和Unicode替换字符。此外，禁止将逗号和注释设置为相等。\n","id":52,"section":"posts","summary":"\u003cp\u003e有多种表格数据格式。\u003cstrong\u003eCSV\u003c/strong\u003e（\u003cstrong\u003e逗号分隔值\u003c/strong\u003e）是主要用于数据传输和导出的最基本格式之一。没有定义CSV的标准，但RFC 4180中描述了格式本身。\u003c/p\u003e","tags":["go"],"title":"go基础库之解析以逗号分隔的数据","uri":"https://www.ganymedenil.com/2019/05/27/go-standard-library-by-parse-data-separated-by-commas.html","year":"2019"},{"content":"在很多实际工作中，文本样式转换是最常用的方法，比如大小写转换，首字母大写，蛇形命名法，驼峰命名法等。\n文本样式转换 Golang 版本 1.12.1\n前言 在很多实际工作中，文本样式转换是最常用的方法，比如大小写转换，首字母大写，蛇形命名法，驼峰命名法等。\n实现 创建文件case.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; \u0026quot;unicode\u0026quot; ) const email = \u0026quot;ExamPle@domain.com\u0026quot; const name = \u0026quot;isaac newton\u0026quot; const upc = \u0026quot;upc\u0026quot; const i = \u0026quot;i\u0026quot; const snakeCase = \u0026quot;first_name\u0026quot; func main() { // 为了比较用户输入，有时最好在相同的情况下比较输入 input := \u0026quot;Example@domain.com\u0026quot; input = strings.ToLower(input) emailToCompare := strings.ToLower(email) matches := input == emailToCompare fmt.Printf(\u0026quot;Email matches: %t\\n\u0026quot;, matches) upcCode := strings.ToUpper(upc) fmt.Println(\u0026quot;UPPER case: \u0026quot; + upcCode) // 这个有向图有不同的大写字母和标题 str := \u0026quot;ǳ\u0026quot; fmt.Printf(\u0026quot;%s in upper: %s and title: %s \\n\u0026quot;, str, strings.ToUpper(str), strings.ToTitle(str)) // 使用XXXSpecial功能 title := strings.ToTitle(i) titleTurk := strings.ToTitleSpecial(unicode.TurkishCase, i) if title != titleTurk { fmt.Printf(\u0026quot;ToTitle is defferent: %#U vs. %#U \\n\u0026quot;, title[0], []rune(titleTurk)[0]) } // 在某些情况下，需要纠正输入以防万一 correctNameCase := strings.Title(name) fmt.Println(\u0026quot;Corrected name: \u0026quot; + correctNameCase) // 使用Title和ToLower函数将蛇形命名法转换为驼峰命名法 firstNameCamel := toCamelCase(snakeCase) fmt.Println(\u0026quot;Camel case: \u0026quot; + firstNameCamel) } func toCamelCase(input string) string { titleSpace := strings.Title(strings.Replace(input, \u0026quot;_\u0026quot;, \u0026quot; \u0026quot;, -1)) camel := strings.Replace(titleSpace, \u0026quot; \u0026quot;, \u0026quot;\u0026quot;, -1) return strings.ToLower(camel[:1]) + camel[1:] } $ go run case.go Email matches: true UPPER case: UPC ǳ in upper: Ǳ and title: ǲ ToTitle is defferent: U+0049 'I' vs. U+0130 'İ' Corrected name: Isaac Newton Camel case: firstName 原理 注意Unicode中的标题大小写映射与大写字母映射不同。不同之处在于字符的数量需要特殊处理。这些主要是连接符和有向图，如 fl, dz, and lj，加上一些多音体希腊字符。例如，U+01C7 (LJ)映射到U+01C8 (Lj) 而不是U+01C9 (lj)。\n为了正确区分大小写，应该使用string包中的EqualFold函数。这个函数使用case折叠对字符串进行规范化并比较它们。\n","id":53,"section":"posts","summary":"\u003cp\u003e在很多实际工作中，文本样式转换是最常用的方法，比如大小写转换，首字母大写，蛇形命名法，驼峰命名法等。\u003c/p\u003e","tags":["go"],"title":"go基础库之文本样式转换","uri":"https://www.ganymedenil.com/2019/05/27/go-standard-library-by-text-style-conversion.html","year":"2019"},{"content":"一个鲜为人知的事实是.go文件中的所有内容都是用UTF-8编码的。信不信由你，Unicode不是世界上唯一的字符集。例如，Windows-1250编码在Windows用户中广泛使用。\n在处理非Unicode字符串时，需要将内容转换为Unicode。本篇将演示如何解码和编码非unicode字符串。\n解码非Unicode字符集中的字符串 Golang 版本 1.12.1\n前言 一个鲜为人知的事实是.go文件中的所有内容都是用UTF-8编码的。信不信由你，Unicode不是世界上唯一的字符集。例如，Windows-1250编码在Windows用户中广泛使用。\n在处理非Unicode字符串时，需要将内容转换为Unicode。本篇将演示如何解码和编码非unicode字符串。\n实现 创建文件encode.go，代码如下： package main import ( \u0026quot;io\u0026quot; \u0026quot;os\u0026quot; \u0026quot;golang.org/x/text/encoding/charmap\u0026quot; ) func main() { f, err := os.OpenFile(\u0026quot;out.txt\u0026quot;, os.O_CREATE|os.O_RDWR, os.ModePerm|os.ModeAppend) if err != nil { panic(err) } defer f.Close() // 解码unicode encoder := charmap.Windows1250.NewEncoder() writer := encoder.Writer(f) io.WriteString(writer, \u0026quot;Gdańsk\u0026quot;) } 运行go run encode.go\nout.txt以Windows-1250编码进行编码\n创建文件decode.go，代码如下： package main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strings\u0026quot; \u0026quot;golang.org/x/text/encoding/charmap\u0026quot; ) func main() { // 打开 windows-1250 文件 f, err := os.Open(\u0026quot;out.txt\u0026quot;) if err != nil { panic(err) } defer f.Close() // 全部以原始内容读入 b, err := ioutil.ReadAll(f) if err != nil { panic(err) } content := string(b) fmt.Println(\u0026quot;Without decode: \u0026quot; + content) // unicode 解码 decoder := charmap.Windows1250.NewDecoder() reader := decoder.Reader(strings.NewReader(content)) b, err = ioutil.ReadAll(reader) if err != nil { panic(err) } fmt.Println(\u0026quot;Decoded: \u0026quot; + string(b)) } $ go run decode.go Without decode: Gda�sk Decoded: Gdańsk 原理 软件包golang.org/x/text/encoding/charmap包含用于简单编码和解码的Charset类型。该类型实现创建解码器结构的NewDecoder方法。\n编码工作类似。创建编码Writer，然后将由该Writer 编写的每个字符串编码为Windows-1250编码。\n注意，选择Windows-1250作为示例。这个包golang.org/x/text/encoding/charmap包含许多其他字符集选项。\n","id":54,"section":"posts","summary":"\u003cp\u003e一个鲜为人知的事实是\u003ccode\u003e.go\u003c/code\u003e文件中的所有内容都是用UTF-8编码的。信不信由你，Unicode不是世界上唯一的字符集。例如，Windows-1250编码在Windows用户中广泛使用。\u003c/p\u003e\n\u003cp\u003e在处理非Unicode字符串时，需要将内容转换为Unicode。本篇将演示如何解码和编码非unicode字符串。\u003c/p\u003e","tags":["go"],"title":"go基础库之解码非Unicode字符集中的字符串","uri":"https://www.ganymedenil.com/2019/05/26/go-standard-library-by-decode-strings-in-non-unicode-character-sets.html","year":"2019"},{"content":"总是有一些任务，例如输入验证，在文档中搜索任何信息，甚至从不需要的转义字符中清除给定的字符串。对于这些情况，通常可以使用正则表达式。\n通过正则表达式模式查找文本中的子字符串 Golang 版本 1.12.1\n前言 总是有一些任务，例如输入验证，在文档中搜索任何信息，甚至从不需要的转义字符中清除给定的字符串。对于这些情况，通常可以使用正则表达式。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;regexp\u0026quot; ) const refString = `[{ \\\u0026quot;email\\\u0026quot;: \\\u0026quot;email@example.com\\\u0026quot; \\ \u0026quot;phone\\\u0026quot;: 555467890}, { \\\u0026quot;email\\\u0026quot;: \\\u0026quot;other@domain.com\\\u0026quot; \\ \u0026quot;phone\\\u0026quot;: 555467890}]` func main() { // 为简洁起见，简化了这种模式 emailRegexp := regexp.MustCompile(\u0026quot;[a-zA-Z0-9]{1,}@[a-zA-Z0-9]{1,}\\\\.[a-z]{1,}\u0026quot;) first := emailRegexp.FindString(refString) fmt.Println(\u0026quot;First: \u0026quot;) fmt.Println(first) all := emailRegexp.FindAllString(refString, -1) fmt.Println(\u0026quot;All: \u0026quot;) for _, val := range all { fmt.Println(val) } } $ go run regexp.go First: email@example.com All: email@example.com other@domain.com 原理 FindString或FindAllString函数是查找给定字符串中匹配模式的最简单方法。唯一的区别是Regexp的FindString方法只返回首个。另一方面，FindAllString，顾名思义，返回所有出现的字符串片段。\nRegexp类型提供了一组丰富的FindXXX方法。本篇只描述通常最有用的字符串变体。注意，前面的代码使用regexp包的MustCompile函数，如果正则表达式的编译失败，该函数将引发恐慌。\n","id":55,"section":"posts","summary":"\u003cp\u003e总是有一些任务，例如输入验证，在文档中搜索任何信息，甚至从不需要的转义字符中清除给定的字符串。对于这些情况，通常可以使用正则表达式。\u003c/p\u003e","tags":["go"],"title":"go基础库之通过正则表达式模式查找文本中的子字符串","uri":"https://www.ganymedenil.com/2019/05/26/go-standard-library-by-find-substrings-in-text-through-regular-expression-patterns.html","year":"2019"},{"content":"与字符串处理相关的另一个非常常见的任务是替换字符串中的子字符串。Go标准库提供了一次替换多个字符串的 Replace功能和Replacer类型。\n替换部分字符串 Golang 版本 1.12.1\n前言 与字符串处理相关的另一个非常常见的任务是替换字符串中的子字符串。Go标准库提供了一次替换多个字符串的 Replace功能和Replacer类型。\n实现 创建文件replace.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const refString = \u0026quot;Mary had a little lamb\u0026quot; const refStringTwo = \u0026quot;lamb lamb lamb lamb\u0026quot; func main() { out := strings.Replace(refString, \u0026quot;lamb\u0026quot;, \u0026quot;wolf\u0026quot;, -1) fmt.Println(out) out = strings.Replace(refStringTwo, \u0026quot;lamb\u0026quot;, \u0026quot;wolf\u0026quot;, 2) fmt.Println(out) } $ go run replace.go Mary had a little wolf wolf wolf lamb lamb 创建文件replacer.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const refString = \u0026quot;Mary had a little lamb\u0026quot; func main() { replacer := strings.NewReplacer(\u0026quot;lamb\u0026quot;, \u0026quot;wolf\u0026quot;, \u0026quot;Mary\u0026quot;, \u0026quot;Jack\u0026quot;) out := replacer.Replace(refString) fmt.Println(out) } $ go run replacer.go Jack had a little wolf 创建文件regexp.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;regexp\u0026quot; ) const refString = \u0026quot;Mary had a little lamb\u0026quot; func main() { regex := regexp.MustCompile(\u0026quot;l[a-z]+\u0026quot;) out := regex.ReplaceAllString(refString, \u0026quot;replacement\u0026quot;) fmt.Println(out) } $ go run regexp.go Mary had a replacement replacement 原理 strings包的Replace函数被广泛用于简单的替换。最后一个integer参数定义将执行多少次替换(在-1情况下，替换所有字符串。参见Replace的第二种用法，其中只替换前两种情况。)替换函数的使用在步骤1中给出。\n除了Replace函数外，Replacer结构体还具有WriteString方法。 此方法将写入给定的编写器，并在Replacer中定义所有替换。这种类型的主要目的是可重用性。它可以同时替换多个字符串，并发使用安全;参见步骤2。\n替换子字符串甚至匹配模式的更复杂的方法自然是使用正则表达式。 可以利用Regex类型指针方法ReplaceAllString来实现此目的。 步骤3说明了regexp包的使用。\n","id":56,"section":"posts","summary":"\u003cp\u003e与字符串处理相关的另一个非常常见的任务是替换字符串中的子字符串。Go标准库提供了一次替换多个字符串的  Replace功能和Replacer类型。\u003c/p\u003e","tags":["go"],"title":"go基础库之替换部分字符串","uri":"https://www.ganymedenil.com/2019/05/26/go-standard-library-by-replace-part-of-the-string.html","year":"2019"},{"content":"除了内置的+运算符之外，还有更多的方法可以连接字符串。本篇将用bytes包和内置copy函数，作为连接字符串的更有效的方法。\n将字符串与writer连接 Golang 版本 1.12.1\n前言 除了内置的+运算符之外，还有更多的方法可以连接字符串。本篇将用bytes包和内置copy函数，作为连接字符串的更有效的方法。\n实现 创建文件concat_buffer.go，代码如下：\npackage main import ( \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; ) func main() { strings := []string{\u0026quot;This \u0026quot;, \u0026quot;is \u0026quot;, \u0026quot;even \u0026quot;, \u0026quot;more \u0026quot;, \u0026quot;performant \u0026quot;} buffer := bytes.Buffer{} for _, val := range strings { buffer.WriteString(val) } fmt.Println(buffer.String()) } $ go run concat_buffer.go This is even more performant 创建文件concat_copy.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; ) func main() { strings := []string{\u0026quot;This \u0026quot;, \u0026quot;is \u0026quot;, \u0026quot;even \u0026quot;, \u0026quot;more \u0026quot;, \u0026quot;performant \u0026quot;} bs := make([]byte, 100) bl := 0 for _, val := range strings { bl += copy(bs[bl:], []byte(val)) } fmt.Println(string(bs[:])) } $ go run concat_copy.go This is even more performant 原理 步骤1使用bytes包的Buffer作为字符串连接性能友好的解决方案。Buffer结构体实现WriteString方法，该方法可用于有效地将字符串连接到底层字节片中。\n没有必要在所有情况下都使用这种改进，只要考虑一下程序将连接大量字符串的情况(例如，内存中的CSV导出和其他)。\n步骤2中提供的内置copy 函数可用于完成string的连接。这种方法需要对最终字符串长度做一些假设，或者可以动态地完成。但是，如果写入结果的缓冲区的容量小于已经写入的部分和要追加的字符串的总和，则必须扩展缓冲区(通常通过分配容量更大的新片)。\n延伸 仅作比较，有一个基准代码，用于比较内置+运算符bytes.Buffer和内置copy方法的性能：\n创建文件夹bench ，并创建文件bench_test.go，代码如下：\npackage main import ( \u0026quot;bytes\u0026quot; \u0026quot;testing\u0026quot; ) const testString = \u0026quot;test\u0026quot; func BenchmarkConcat(b *testing.B) { var str string b.ResetTimer() for n := 0; n \u0026lt; b.N; n++ { str += testString } b.StopTimer() } func BenchmarkBuffer(b *testing.B) { var buffer bytes.Buffer b.ResetTimer() for n := 0; n \u0026lt; b.N; n++ { buffer.WriteString(testString) } b.StopTimer() } func BenchmarkCopy(b *testing.B) { bs := make([]byte, b.N) bl := 0 b.ResetTimer() for n := 0; n \u0026lt; b.N; n++ { bl += copy(bs[bl:], testString) } b.StopTimer() } $ go test -bench=. goos: windows goarch: amd64 pkg: Go-Standard-library/Concatenating-a-string-with-writer/bench BenchmarkConcat-4 300000 95719 ns/op BenchmarkBuffer-4 100000000 12.6 ns/op BenchmarkCopy-4 300000000 4.36 ns/op PASS ok Go-Standard-library/Concatenating-a-string-with-writer/bench 32.345s ","id":57,"section":"posts","summary":"\u003cp\u003e除了内置的+运算符之外，还有更多的方法可以连接字符串。本篇将用\u003ccode\u003ebytes\u003c/code\u003e包和内置\u003ccode\u003ecopy\u003c/code\u003e函数，作为连接字符串的更有效的方法。\u003c/p\u003e","tags":["go"],"title":"go基础库之将字符串与writer连接","uri":"https://www.ganymedenil.com/2019/05/26/go-standard-library-by-connect-the-string-to-the-writer.html","year":"2019"},{"content":"本片将分享如何将多个字符串连接成一个字符串，并将给定的字符串作为分隔符。\n一个真实的用例是动态构建SQL select语句。\n使用分隔符连接字符串切片 Golang 版本 1.12.1\n前言 本片将分享如何将多个字符串连接成一个字符串，并将给定的字符串作为分隔符。\n一个真实的用例是动态构建SQL select语句。\n实现 创建文件join.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const selectBase = \u0026quot;SELECT * FROM user WHERE %s \u0026quot; var refStringSlice = []string{ \u0026quot; FIRST_NAME = 'Jack' \u0026quot;, \u0026quot; INSURANCE_NO = 333444555 \u0026quot;, \u0026quot; EFFECTIVE_FROM = SYSDATE \u0026quot;} func main() { sentence := strings.Join(refStringSlice, \u0026quot;AND\u0026quot;) fmt.Printf(selectBase+\u0026quot;\\n\u0026quot;, sentence) } $ go run join.go SELECT * FROM user WHERE FIRST_NAME = 'Jack' AND INSURANCE_NO = 333444555 AND EFFECTIVE_FROM = SYSDATE 创建文件join_manually.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const selectBase = \u0026quot;SELECT * FROM user WHERE \u0026quot; var refStringSlice = []string{ \u0026quot; FIRST_NAME = 'Jack' \u0026quot;, \u0026quot; INSURANCE_NO = 333444555 \u0026quot;, \u0026quot; EFFECTIVE_FROM = SYSDATE \u0026quot;} type JoinFunc func(piece string) string func main() { jF := func(p string) string { if strings.Contains(p, \u0026quot;INSURANCE\u0026quot;) { return \u0026quot;OR\u0026quot; } return \u0026quot;AND\u0026quot; } result := JoinWithFunc(refStringSlice, jF) fmt.Println(selectBase + result) } func JoinWithFunc(refStringSlice []string, joinFunc JoinFunc) string { concatenate := refStringSlice[0] for _, val := range refStringSlice[1:] { concatenate = concatenate + joinFunc(val) + val } return concatenate } $ go run join_manually.go SELECT * FROM user WHERE FIRST_NAME = 'Jack' OR INSURANCE_NO = 333444555 AND EFFECTIVE_FROM = SYSDATE 原理 为了将字符串切片连接成单个字符串，这里有string包的Join函数。简单地说，需要为切片提供需要连接的字符串。这样，就可以轻松地连接字符串切片。Join函数的使用如步骤1所示。\n当然，连接可以通过在切片上迭代来手动实现。通过这种方式，可以通过一些更复杂的逻辑定制分隔符。步骤2只是表示如何根据当前处理的字符串将手动连接用于更复杂的逻辑。\n延伸 该 Join 函数由bytes包提供，它自然地用于连接字节片。\n","id":58,"section":"posts","summary":"\u003cp\u003e本片将分享如何将多个字符串连接成一个字符串，并将给定的字符串作为分隔符。\u003c/p\u003e\n\u003cp\u003e一个真实的用例是动态构建SQL select语句。\u003c/p\u003e","tags":["go"],"title":"go基础库之使用分隔符连接字符串切片","uri":"https://www.ganymedenil.com/2019/05/24/go-standard-library-by-use-a-separator-to-connect-a-string-slice.html","year":"2019"},{"content":"将字符串分解为单词可能很棘手。首先，确定单词是什么，以及分隔符是什么，以及是否有任何空格或任何其他字符。做出这些决定后，你可以从strings包中选择适当的功能。\n将字符串分解为单词 Golang 版本 1.12.1\n前言 将字符串分解为单词可能很棘手。首先，确定单词是什么，以及分隔符是什么，以及是否有任何空格或任何其他字符。做出这些决定后，你可以从strings包中选择适当的功能。\n实现 创建文件whitespace.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const refString = \u0026quot;Mary had a little lamb\u0026quot; func main() { words := strings.Fields(refString) for idx, word := range words { fmt.Printf(\u0026quot;Word %d is: %s\\n\u0026quot;, idx, word) } } $ go run whitespace.go 单词 0 是: Mary 单词 1 是: had 单词 2 是: a 单词 3 是: little 单词 4 是: lamb 创建文件anyother.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const refString = \u0026quot;Mary_had a little_lamb\u0026quot; func main() { words := strings.Split(refString, \u0026quot;_\u0026quot;) for idx, word := range words { fmt.Printf(\u0026quot;单词 %d 是: %s\\n\u0026quot;, idx, word) } } $ go run anyother.go 单词 0 是: Mary 单词 1 是: had a little 单词 2 是: lamb 创建文件specfunction.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const refString = \u0026quot;Mary*had,a%little_lamb\u0026quot; func main() { // 为字符串中的每个符文调用splitFunc。如果符文等于“*％,_”中的任何字符，则拆分refString splitFunc := func(r rune) bool { return strings.ContainsRune(\u0026quot;*%,_\u0026quot;, r) } words := strings.FieldsFunc(refString, splitFunc) for idx, word := range words { fmt.Printf(\u0026quot;单词 %d 是: %s\\n\u0026quot;, idx, word) } } $ go run specfunction.go 单词 0 是: Mary 单词 1 是: had 单词 2 是: a 单词 3 是: little 单词 4 是: lamb 创建文件regex.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;regexp\u0026quot; ) const refString = \u0026quot;Mary*had,a%little_lamb\u0026quot; func main() { words := regexp.MustCompile(\u0026quot;[*,%_]{1}\u0026quot;).Split(refString, -1) for idx, word := range words { fmt.Printf(\u0026quot;单词 %d 是: %s\\n\u0026quot;, idx, word) } } $ go run regex.go 单词 0 是: Mary 单词 1 是: had 单词 2 是: a 单词 3 是: little 单词 4 是: lamb 原理 将字符串分割成单词的最简单形式是将任何空格作为分隔符。其中空格由unicode包中的IsSpace函数定义:\n\u0026lsquo;\\t\u0026rsquo;, \u0026lsquo;\\n\u0026rsquo;, \u0026lsquo;\\v\u0026rsquo;, \u0026lsquo;\\f\u0026rsquo;, \u0026lsquo;\\r\u0026rsquo;, \u0026rsquo; \u0026lsquo;, U+0085 (NEL), U+00A0 (NBSP).\n如前所述，string包的Fields函数可用于空格字符分割句子。步骤1涵盖了第一个简单的案例。\n如果需要其他分隔符，则使用Split函数。在步骤2中讨论了用另一个分隔符进行分割。请注意，字符串中的空格被省略了。\n如果需要一个更复杂的函数来决定是否在给定的位置拆分字符串，FieldsFunc可以为你提供帮助。该函数的一个参数是使用给定字符串的符文并返回true(如果该字符串在该点应该分割)的函数。这个选项包含在步骤3中。\n正则表达式是示例中提到的最后一个选项。Regexp包的Regexp结构体包含Split方法，其工作方式与您所期望的一样。它将字符串分割到匹配组的位置。此方法在步骤4中使用。\n延伸 该strings包还提供各种SplitXXX功能，可以帮助你实现更具体的任务。\n","id":59,"section":"posts","summary":"\u003cp\u003e将字符串分解为单词可能很棘手。首先，确定单词是什么，以及分隔符是什么，以及是否有任何空格或任何其他字符。做出这些决定后，你可以从strings包中选择适当的功能。\u003c/p\u003e","tags":["go"],"title":"go基础库之将字符串分解为单词","uri":"https://www.ganymedenil.com/2019/05/24/go-standard-library-by-decompose-a-string-into-words.html","year":"2019"},{"content":"在字符串中查找子字符串是开发人员最常见的任务之一。大多数主流语言都是在标准库中实现的。Go也不例外。\n在字符串中查找子字符串 Golang 版本 1.12.1\n前言 在字符串中查找子字符串是开发人员最常见的任务之一。大多数主流语言都是在标准库中实现的。Go也不例外。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;strings\u0026quot; ) const refString = \u0026quot;Mary had a little lamb\u0026quot; func main() { lookFor := \u0026quot;lamb\u0026quot; contain := strings.Contains(refString, lookFor) fmt.Printf(\u0026quot;\\\u0026quot;%s\\\u0026quot; 包含 \\\u0026quot;%s\\\u0026quot;: %t \\n\u0026quot;, refString, lookFor, contain) lookFor = \u0026quot;wolf\u0026quot; contain = strings.Contains(refString, lookFor) fmt.Printf(\u0026quot;\\\u0026quot;%s\\\u0026quot; 包含 \\\u0026quot;%s\\\u0026quot;: %t \\n\u0026quot;, refString, lookFor, contain) startsWith := \u0026quot;Mary\u0026quot; starts := strings.HasPrefix(refString, startsWith) fmt.Printf(\u0026quot;\\\u0026quot;%s\\\u0026quot; 从 \\\u0026quot;%s\\\u0026quot; 开始: %t \\n\u0026quot;, refString, startsWith, starts) endWith := \u0026quot;lamb\u0026quot; ends := strings.HasSuffix(refString, endWith) fmt.Printf(\u0026quot;\\\u0026quot;%s\\\u0026quot; 到 \\\u0026quot;%s\\\u0026quot; 结束: %t \\n\u0026quot;, refString, endWith, ends) } $ go run main.go \u0026quot;Mary had a little lamb\u0026quot; 包含 \u0026quot;lamb\u0026quot;: true \u0026quot;Mary had a little lamb\u0026quot; 包含 \u0026quot;wolf\u0026quot;: false \u0026quot;Mary had a little lamb\u0026quot; 从 \u0026quot;Mary\u0026quot; 开始: true \u0026quot;Mary had a little lamb\u0026quot; 到 \u0026quot;lamb\u0026quot; 结束: true 原理 Go的strings库包含处理字符串操作的函数。这次Contains函数就可以使用 。该Contains函数只是检查字符串是否具有给定的子字符串。实际上，Contains函数中使用了Index函数。\n要检查字符串是否以子字符串开头，HasPrefix函数就在那里。要检查字符串是否以子字符串结尾，HasSuffix函数将起作用。\n实际上，该Contains函数是通过使用来自同一包的Index函数来实现的 。你可以猜到，实际的实现是这样的：如果给定子字符串的索引大于-1，则Contains函数返回true。\nHasPrefix和HasSuffix函数的工作方式不同:内部实现只检查字符串和子字符串的长度，如果它们相等或字符串更长，则比较字符串所需的部分。\n","id":60,"section":"posts","summary":"\u003cp\u003e在字符串中查找子字符串是开发人员最常见的任务之一。大多数主流语言都是在标准库中实现的。Go也不例外。\u003c/p\u003e","tags":["go"],"title":"go基础库之在字符串中查找子字符串","uri":"https://www.ganymedenil.com/2019/05/23/go-standard-library-by-find-a-substring-in-a-string.html","year":"2019"},{"content":"服务和守护程序是运行很长时间（通常是几天甚至几周）的程序。这些长时间运行的程序通常在开始时分配资源（数据库连接，网络sock）并保留这些资源，只要它们存在，就不会释放。如果此类进程被终止并且未正确处理关闭，则可能发生资源泄漏。为了避免这种行为，应该实现所谓的正常关闭。\n在这种情况下，优雅 意味着应用程序捕获终止信号（如果可能），并尝试在终止之前清理和释放分配的资源。本篇将向你展示如何实现正常关闭。\n正常关闭应用程序 Golang 版本 1.12.1\n前言 服务和守护程序是运行很长时间（通常是几天甚至几周）的程序。这些长时间运行的程序通常在开始时分配资源（数据库连接，网络sock）并保留这些资源，只要它们存在，就不会释放。如果此类进程被终止并且未正确处理关闭，则可能发生资源泄漏。为了避免这种行为，应该实现所谓的正常关闭。\n在这种情况下，优雅 意味着应用程序捕获终止信号（如果可能），并尝试在终止之前清理和释放分配的资源。本篇将向你展示如何实现正常关闭。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/signal\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;time\u0026quot; ) var writer *os.File func main() { // 该文件作为要写入的日志文件打开。这样我们就代表了资源分配。 var err error writer, err = os.OpenFile(fmt.Sprintf(\u0026quot;test_%d.log\u0026quot;, time.Now().Unix()), os.O_RDWR|os.O_CREATE, os.ModePerm) if err != nil { panic(err) } // 代码独立地在goroutine中运行。因此，如果程序从外部终止，我们需要通过closeChan让goroutine知道 closeChan := make(chan bool) go func() { for { time.Sleep(time.Second) select { case \u0026lt;-closeChan: log.Println(\u0026quot;Goroutine 关闭...\u0026quot;) return default: log.Println(\u0026quot;写入日志\u0026quot;) io.WriteString(writer, fmt.Sprintf(\u0026quot;记录写入 %s\\n\u0026quot;, time.Now().String())) } } }() sigChan := make(chan os.Signal, 1) signal.Notify(sigChan, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGINT) // 堵塞从sigChan读取Notify函数发送的信号 \u0026lt;-sigChan // 收到信号后，通道读取后面的所有代码都可以视为清理。清洁部分 close(closeChan) releaseAllResources() fmt.Println(\u0026quot;应用程序正常关闭\u0026quot;) } func releaseAllResources() { io.WriteString(writer, \u0026quot;应用程序释放所有资源 \\n\u0026quot;) writer.Close() } $ go run main.go 2019/05/22 20:16:00 写入日志 2019/05/22 20:16:01 写入日志 2019/05/22 20:16:02 写入日志 ^C应用程序正常关闭 $ cat test_1558509359.log 记录写入 2019-05-22 20:16:00.2506194 +0800 CST m=+1.017343401 记录写入 2019-05-22 20:16:01.2513848 +0800 CST m=+2.018108801 记录写入 2019-05-22 20:16:02.2527773 +0800 CST m=+3.019501301 应用程序释放所有资源 原理 从sigChan读取的数据被阻塞，因此程序一直运行，直到信号通过通道发送。sigChan是Notify函数发送信号的通道。\n程序的主代码在一个新的goroutine中运行。这样，当sigChan上的主函数被阻塞时，工作将继续进行。一旦操作系统的信号被发送到进程中，sigChan将接收信号并且执行从sigChan通道读取的代码。这段代码可以看作是清理部分。\n注意，终端输出包含的最终日志，应用程序释放所有资源，这是清理部分的一部分。\n","id":61,"section":"posts","summary":"\u003cp\u003e服务和守护程序是运行很长时间（通常是几天甚至几周）的程序。这些长时间运行的程序通常在开始时分配资源（数据库连接，网络sock）并保留这些资源，只要它们存在，就不会释放。如果此类进程被终止并且未正确处理关闭，则可能发生资源泄漏。为了避免这种行为，应该实现所谓的正常关闭。\u003c/p\u003e\n\u003cp\u003e在这种情况下，优雅 意味着应用程序捕获终止信号（如果可能），并尝试在终止之前清理和释放分配的资源。本篇将向你展示如何实现正常关闭。\u003c/p\u003e","tags":["go"],"title":"go基础库之正常关闭应用程序","uri":"https://www.ganymedenil.com/2019/05/23/go-standard-library-by-close-the-application-gracefully.html","year":"2019"},{"content":"本篇将介绍如何处理应用程序的可选配置，并在具有文件配置的实际案例中使用功能选项模式。\n带功能选项的文件配置 Golang 版本 1.12.1\n前言 本篇将介绍如何处理应用程序的可选配置，并在具有文件配置的实际案例中使用功能选项模式。\n实现 创建文件main.go，代码如下：\npackage main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) type Client struct { consulIP string connString string } func (c *Client) String() string { return fmt.Sprintf(\u0026quot;ConsulIP：%s，connString：%s\u0026quot;, c.consulIP, c.connString) } var defaultClient = Client{ consulIP: \u0026quot;localhost:9000\u0026quot;, connString: \u0026quot;postgres://localhost:5432\u0026quot;, } // ConfigFunc用作要在功能选项中使用的类型 type ConfigFunc func(opt *Client) // FromFile func返回ConfigFunc类型。这样它就可以从json读取配置 func FromFile(path string) ConfigFunc { return func(opt *Client) { f, err := os.Open(path) if err != nil { panic(err) } defer f.Close() decoder := json.NewDecoder(f) fop := struct { ConsulIP string `json:\u0026quot;consul_ip\u0026quot;` }{} err = decoder.Decode(\u0026amp;fop) if err != nil { panic(err) } opt.consulIP = fop.ConsulIP } } // FromEnv从环境变量读取配置并将它们与现有变量组合 func FromEnv() ConfigFunc { return func(opt *Client) { connStr, exist := os.LookupEnv(\u0026quot;CONN_DB\u0026quot;) if exist { opt.connString = connStr } } } func NewClient(opts ...ConfigFunc) *Client { client := defaultClient for _, val := range opts { val(\u0026amp;client) } return \u0026amp;client } func main() { client := NewClient(FromFile(\u0026quot;config.json\u0026quot;), FromEnv()) fmt.Println(client.String()) } 创建文件config.json，内容如下：\n{ \u0026quot;consul_ip\u0026quot;:\u0026quot;127.0.0.1\u0026quot; } $ export CONN_DB=oracle://local:5921 \u0026amp;\u0026amp; go run main.go ConsulIP：127.0.0.1，connString：oracle://local:5921 原理 函数选项模式的核心概念是配置API包含函数参数。在本例中，NewClient函数接受不同数量的ConfigFunc参数，然后在defaultClient结构上逐一应用这些参数。通过这种方式，可以非常灵活地修改默认配置。\n请参阅FromFile和FromEnv函数，它们返回ConfigFunc，实际上是访问文件或环境变量。\n最后，可以检查输出，其中包含来自文件和环境变量的值。\n","id":62,"section":"posts","summary":"\u003cp\u003e本篇将介绍如何处理应用程序的可选配置，并在具有文件配置的实际案例中使用功能选项模式。\u003c/p\u003e","tags":["go"],"title":"go基础库之带功能选项的文件配置","uri":"https://www.ganymedenil.com/2019/05/22/go-standard-library-by-file-configuration-with-function-options.html","year":"2019"},{"content":"信号是操作系统与正在运行的进程进行通信的基本方式。其中两种最常见的信号是SIGINT和SIGTERM。这两个信号将导致程序终止。\n还有信号如SIGHUP。SIGHUP表示调用该进程的终端已经关闭，例如，程序可以通过该信号决定是否移动到后台执行。\nGo提供了一种在应用程序收到信号时处理行为的方法。\n处理操作系统信号 Golang 版本 1.12.1\n前言 信号是操作系统与正在运行的进程进行通信的基本方式。其中两种最常见的信号是SIGINT和SIGTERM。这两个信号将导致程序终止。\n还有信号如SIGHUP。SIGHUP表示调用该进程的终端已经关闭，例如，程序可以通过该信号决定是否移动到后台执行。\nGo提供了一种在应用程序收到信号时处理行为的方法。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/signal\u0026quot; \u0026quot;syscall\u0026quot; ) func main() { // 创建将发送接收信号的通道。 // 发送信号且通道未就绪时， // 通知不会阻止。因此最好创建 // 缓冲通道。 sChan := make(chan os.Signal, 1) // Notify 将捕获给定的信号并通过 sChan // 发送 os.Signal 值。如果参数中未指定 // 信号，则匹配所有信号。 signal.Notify(sChan, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT) // 创建要等待信号处理的通道 exitChan := make(chan int) go func() { signal := \u0026lt;-sChan switch signal { case syscall.SIGHUP: fmt.Println(\u0026quot;终端已经关闭\u0026quot;) exitChan \u0026lt;- 0 case syscall.SIGINT: fmt.Println(\u0026quot;该程序已被 CTRL+C 中断\u0026quot;) exitChan \u0026lt;- 1 case syscall.SIGTERM: fmt.Println(\u0026quot;通过 SIGTERM 信号关闭\u0026quot;) exitChan \u0026lt;- 1 case syscall.SIGQUIT: fmt.Println(\u0026quot;通过 SIGQUIT 信号关闭\u0026quot;) exitChan \u0026lt;- 1 } }() code := \u0026lt;-exitChan os.Exit(code) } 运行 go run main.go，然后执行 CTRL + C 发送 SIGINT 信号\n$ go run main.go ^C该程序已被 CTRL+C 中断 原理 应用在获取资源的时候，如果这个时候中断会发生资源泄漏。这个时候最好通过信号来采取一些必要的措施来释放资源。\nsignal包中的Notify方法将帮助我们处理接收到的信号。\n如果在Notify方法中没有指定信号作为参数，那么该方法将捕获所有可能的信号。\n注意，signal包的Notify方法通过sChan通道与goroutine通信。Notify然后捕获定义的信号并将其发送到goroutine进行处理。最后，使用exitChan解析进程的退出代码。\n重要的是，如果指定的通道没有准备好，Notify方法不会阻塞信号。这样信号就会被错过。为了避免丢失信号，最好创建缓冲通道。\n注意，SIGKILL和SIGSTOP信号可能不会被Notify方法捕获，因此无法处理这些信号。\n","id":63,"section":"posts","summary":"\u003cp\u003e信号是操作系统与正在运行的进程进行通信的基本方式。其中两种最常见的信号是\u003ccode\u003eSIGINT\u003c/code\u003e和\u003ccode\u003eSIGTERM\u003c/code\u003e。这两个信号将导致程序终止。\u003c/p\u003e\n\u003cp\u003e还有信号如\u003ccode\u003eSIGHUP\u003c/code\u003e。\u003ccode\u003eSIGHUP\u003c/code\u003e表示调用该进程的终端已经关闭，例如，程序可以通过该信号决定是否移动到后台执行。\u003c/p\u003e\n\u003cp\u003eGo提供了一种在应用程序收到信号时处理行为的方法。\u003c/p\u003e","tags":["go"],"title":"go基础库之处理操作系统信号","uri":"https://www.ganymedenil.com/2019/05/22/go-standard-library-by-handling-operating-system-signals.html","year":"2019"},{"content":"Go二进制文件还可以用作各种实用程序的工具，并且go run也可以用作bash脚本的代替品。\n调用外部进程 Golang 版本 1.12.1\n前言 Go二进制文件还可以用作各种实用程序的工具，并且go run也可以用作bash脚本的代替品。\n实现 创建文件run.go文件，代码如下：\npackage main import ( \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os/exec\u0026quot; ) func main() { prc := exec.Command(\u0026quot;ls\u0026quot;, \u0026quot;-a\u0026quot;) out := bytes.NewBuffer([]byte{}) prc.Stdout = out err := prc.Run() if err != nil { fmt.Println(err) } if prc.ProcessState.Success() { fmt.Println(\u0026quot;执行成功：\u0026quot;) fmt.Println(out.String()) } } $ go run run.go 执行成功： . .. run.go 创建文件start.go文件，代码如下：\npackage main import ( \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os/exec\u0026quot; ) func main() { prc := exec.Command(\u0026quot;ls\u0026quot;, \u0026quot;-a\u0026quot;) out := bytes.NewBuffer([]byte{}) prc.Stdout = out err := prc.Start() if err != nil { fmt.Println(err) } prc.Wait() if prc.ProcessState.Success() { fmt.Println(\u0026quot;执行成功：\u0026quot;) fmt.Println(out.String()) } } $ go run start.go 执行成功： . .. run.go start.go 原理 Go标准库提供了一种简单的调用外部进程的方法，可以通过os/exec包中的Command方法实现。\n最简单的方法是创建Cmd结构体并调用Run方法。Run方法执行进程并等待它完成。如果命令错误退出，则err值不为空。\n这更适合调用OS utils和工具，因为程序不会挂起太久。\n外部进程也可以异步执行。通过调用Cmd结构体的Start方法来实现。在这种情况下，外部进程执行，但是主goroutine不会等到它结束。Wait方法可用于等待进程结束。等待方法完成后，进程的资源将被释放。\n这种方法更适用于执行程序的外部依赖存在耗时的流程和服务。\n","id":64,"section":"posts","summary":"\u003cp\u003eGo二进制文件还可以用作各种实用程序的工具，并且\u003ccode\u003ego run\u003c/code\u003e也可以用作bash脚本的代替品。\u003c/p\u003e","tags":["go"],"title":"go基础库之调用外部进程","uri":"https://www.ganymedenil.com/2019/05/21/go-standard-library-by-calling-an-external-process.html","year":"2019"},{"content":"获取到运行进程的PID是非常有用的。操作系统应用可以使用PID来查找关于进程本身的信息。当进程失败时获取到的PID就非常有价值，这样就可以使用PID跟踪整个系统中的系统日志，如/var/log/messages、/var/log/syslog。\n获取当前进程PID Golang 版本 1.12.1\n前言 获取到运行进程的PID是非常有用的。操作系统应用可以使用PID来查找关于进程本身的信息。当进程失败时获取到的PID就非常有价值，这样就可以使用PID跟踪整个系统中的系统日志，如/var/log/messages、/var/log/syslog。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;strconv\u0026quot; ) func main() { pid := os.Getpid() fmt.Printf(\u0026quot;进程 PID: %d \\n\u0026quot;, pid) prc := exec.Command(\u0026quot;ps\u0026quot;, \u0026quot;-p\u0026quot;, strconv.Itoa(pid), \u0026quot;-v\u0026quot;) out, err := prc.Output() if err != nil { panic(err) } fmt.Println(string(out)) } 进程 PID: 28259 PID TTY STAT TIME MAJFL TRS DRS RSS %MEM COMMAND 28259 pts/0 Sl+ 0:00 0 648 102535 1224 0.0 ./main 原理 os包中的Getpid方法返回当前进程的PID。上述例子演示了如何通过系统应用ps命令获取该进程的更多信息。\n在应用开始时打印PID可能很有用，在应用崩溃时，获取到的PID就可以调查相应的问题。\n","id":65,"section":"posts","summary":"\u003cp\u003e获取到运行进程的PID是非常有用的。操作系统应用可以使用PID来查找关于进程本身的信息。当进程失败时获取到的PID就非常有价值，这样就可以使用PID跟踪整个系统中的系统日志，如\u003ccode\u003e/var/log/messages\u003c/code\u003e、\u003ccode\u003e/var/log/syslog\u003c/code\u003e。\u003c/p\u003e","tags":["go"],"title":"go基础库之获取当前进程PID","uri":"https://www.ganymedenil.com/2019/05/21/go-standard-library-by-get-the-current-process-PID.html","year":"2019"},{"content":"本篇将介绍如何在程序终止后获取有关子进程的PID和基本信息。\n有关正在运行的进程信息只能通过syscall包获取，并且与平台高度相关。\n获取子进程信息 Golang 版本 1.12.1\n前言 本篇将介绍如何在程序终止后获取有关子进程的PID和基本信息。\n有关正在运行的进程信息只能通过syscall包获取，并且与平台高度相关。\n实现 创建文件main_running.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;runtime\u0026quot; ) func main() { var cmd string if runtime.GOOS == \u0026quot;windows\u0026quot; { cmd = \u0026quot;timeout\u0026quot; } else { cmd = \u0026quot;sleep\u0026quot; } proc := exec.Command(cmd, \u0026quot;1\u0026quot;) proc.Start() // 在进程结束之前不会返回任何进程状态 fmt.Printf(\u0026quot;运行进程的进程状态：%v\\n\u0026quot;, proc.ProcessState) // 获取正在运行进程的PID fmt.Printf(\u0026quot;运行进程的PID：%d\\n\\n\u0026quot;, proc.Process.Pid) } $ go run main_running.go 运行进程的进程状态：\u0026lt;nil\u0026gt; 运行进程的PID：45 创建文件main.go，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;runtime\u0026quot; \u0026quot;time\u0026quot; ) func main() { var cmd string if runtime.GOOS == \u0026quot;windows\u0026quot; { cmd = \u0026quot;timeout\u0026quot; } else { cmd = \u0026quot;sleep\u0026quot; } proc := exec.Command(cmd, \u0026quot;1\u0026quot;) proc.Start() // Wait功能将等待，直到进程结束 proc.Wait() // 在进程终止后，*os.ProcessState 包含有关进程运行的简单信息 fmt.Printf(\u0026quot;PID: %d\\n\u0026quot;, proc.ProcessState.Pid()) fmt.Printf(\u0026quot;进程耗费时间: %dms\\n\u0026quot;, proc.ProcessState.SystemTime()/time.Microsecond) fmt.Printf(\u0026quot;成功退出: %t\\n\u0026quot;, proc.ProcessState.Success()) } $ go run main.go PID: 51 进程耗费时间: 15625ms 成功退出: true 原理 os/exec标准库提供了执行进程的方法。使用Command，返回Cmd结构体。Cmd提供了处理表示的访问权。当进程运行时，只能找到PID。\n关于这个进程，只能获取到很少的信息。但是通过获取到的进程PID，还可以通过系统方法来获取更多信息。\n请记住，即使子进程正在运行，也可以获得它的PID。另一方面，只有在进程终止之后，os包的ProcessState结构体才可用。\n","id":66,"section":"posts","summary":"\u003cp\u003e本篇将介绍如何在程序终止后获取有关子进程的PID和基本信息。\u003c/p\u003e\n\u003cp\u003e有关正在运行的进程信息只能通过\u003ccode\u003esyscall\u003c/code\u003e包获取，并且与平台高度相关。\u003c/p\u003e","tags":["go"],"title":"go基础库之获取子进程信息","uri":"https://www.ganymedenil.com/2019/05/20/go-standard-library-by-get-child-process-information.html","year":"2019"},{"content":"每个执行进程都具有标准输出、输入和错误输出。Go标准库提供了对这些进行读写的方法。\n从子进程读写 Golang 版本 1.12.1\n前言 每个执行进程都具有标准输出、输入和错误输出。Go标准库提供了对这些进行读写的方法。\n实现 创建文件main_read_output.go，代码如下： package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;runtime\u0026quot; ) func main() { var cmd string if runtime.GOOS == \u0026quot;windows\u0026quot; { cmd = \u0026quot;dir\u0026quot; } else { cmd = \u0026quot;ls\u0026quot; } proc := exec.Command(cmd) // 进程终止并返回标准输出 buff, err := proc.Output() if err != nil { panic(err) } // 子进程的输出以字节切片的形式存在打印为字符串 fmt.Println(string(buff)) } $ go run main_read_output.go main_read_output.go 创建文件main_read_stdout.go，代码如下： package main import ( \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;runtime\u0026quot; ) func main() { var cmd string if runtime.GOOS == \u0026quot;windows\u0026quot; { cmd = \u0026quot;dir\u0026quot; } else { cmd = \u0026quot;ls\u0026quot; } proc := exec.Command(cmd) buf := bytes.NewBuffer([]byte{}) // 实现io.Writer接口的缓冲区被分配给进程的Stdout proc.Stdout = buf // 在这个例子中避免竞争条件。我们等到进程退出 proc.Run() // 该过程将输出写入缓冲区，我们使用字节来打印输出 fmt.Println(string(buf.Bytes())) } $ go run main_read_stdout.go main_read_output.go main_read_stdout.go 创建文件main_read_read.go，代码如下： package main import ( \u0026quot;bufio\u0026quot; \u0026quot;context\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;time\u0026quot; ) func main() { cmd := \u0026quot;ping\u0026quot; timeout := 2 * time.Second // 命令行工具“ping”执行2秒 ctx, _ := context.WithTimeout(context.TODO(), timeout) proc := exec.CommandContext(ctx, cmd, \u0026quot;example.com\u0026quot;) // 进程输出以io.ReadCloser的形式获得。底层实现使用os.Pipe stdout, _ := proc.StdoutPipe() defer stdout.Close() proc.Start() // 为了更舒适地阅读，使用了bufio.Scanner。 s := bufio.NewScanner(stdout) for s.Scan() { fmt.Println(s.Text()) } } $ go run main_read_read.go PING example.com (93.184.216.34) 56(84) bytes of data. 64 bytes from 93.184.216.34 (93.184.216.34): icmp_seq=1 ttl=52 time=211 ms 64 bytes from 93.184.216.34 (93.184.216.34): icmp_seq=2 ttl=52 time=257 ms 创建文件sample.go，代码如下：\npackage main import ( \u0026quot;bufio\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { sc := bufio.NewScanner(os.Stdin) for sc.Scan() { fmt.Println(sc.Text()) } } 创建文件main.go，代码如下：\npackage main import ( \u0026quot;bufio\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;os/exec\u0026quot; \u0026quot;time\u0026quot; ) func main() { cmd := []string{\u0026quot;go\u0026quot;, \u0026quot;run\u0026quot;, \u0026quot;sample.go\u0026quot;} proc := exec.Command(cmd[0], cmd[1], cmd[2]) stdin, _ := proc.StdinPipe() defer stdin.Close() // 出于调试目的，我们会监视已执行进程的输出 stdout, _ := proc.StdoutPipe() defer stdout.Close() go func() { s := bufio.NewScanner(stdout) for s.Scan() { fmt.Println(\u0026quot;程序输出:\u0026quot; + s.Text()) } }() proc.Start() // 现在，以下行被写入子进程标准输入 fmt.Println(\u0026quot;写入\u0026quot;) io.WriteString(stdin, \u0026quot;Hello\\n\u0026quot;) io.WriteString(stdin, \u0026quot;Golang\\n\u0026quot;) io.WriteString(stdin, \u0026quot;is awesome\\n\u0026quot;) time.Sleep(time.Second * 2) proc.Process.Kill() } $ go run main.go 写入 程序输出:Hello 程序输出:Golang 程序输出:is awesome 原理 os/exec 包中的Cmd结构体提供了访问进程输入/输出的功能。有几种方法可以读取进程的输出。\n读取进程输出的最简单方法之一是使用Cmd结构体的Output或CombinedOutput(获取Stderr和Stdout)。在调用此方法时，程序同步地等待子进程终止，然后将输出返回到字节缓冲区。\n除了Output和OutputCombined方法之外，Cmd结构体还提供了Stdout属性，可以为其分配io.Writer。然后，分配的写入器作为进程输出的目标。它可以是文件、字节缓冲区或实现io.Writer接口的任何类型。\n读取进程输出的最后一种方法是通过调用StdoutPipe方法从Cmd结构体中获取io.Reader。 StdoutPipe方法在Stdout之间创建管道，进程写入输出，并提供Reader作为程序接口以读取进程输出。 这样，进程的输出通过管道传输到取回的io.Reader。\n写入进程stdin的工作方式相同。 在所有选项中，将演示使用io.Writer的选项。\n可以看出，有几种方法可以从子进程读取和写入。 stderr和stdin的使用几乎与步骤2中描述的相同。 最后，如何访问输入/输出的方法可以这样划分：\n同步（等待进程结束并获取字节）：使用Cmd的Output和CombinedOutput方法。 IO：输出或输入以io.Writer/Reader的形式提供。 XXXPipe和StdXXX属性是此方法的正确属性。 IO类型更灵活，也可以异步使用。\n","id":67,"section":"posts","summary":"\u003cp\u003e每个执行进程都具有标准输出、输入和错误输出。Go标准库提供了对这些进行读写的方法。\u003c/p\u003e","tags":["go"],"title":"go基础库之从子进程读写","uri":"https://www.ganymedenil.com/2019/05/20/go-standard-library-by-read-and-write-from-child-processes.html","year":"2019"},{"content":"golang 基础库之go获取命令行参数，介绍了如何获取当前工作目录\n获取当前工作目录 Golang 版本 1.12.1\n前言 应用的另一个有用的信息是程序二进制文件所在的目录。使用此信息，程序可以快速获取到相关的资源文件的路径。\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;path/filepath\u0026quot; ) func main(){ ex,err:=os.Executable() if err!=nil{ panic(err) } // 可执行文件的路径 fmt.Println(ex) //\t获取执行文件所在目录 exPath := filepath.Dir(ex) fmt.Println(\u0026quot;可执行文件路径 :\u0026quot; + exPath) // 使用EvalSymlinks获取真是路径 realPath, err := filepath.EvalSymlinks(exPath) if err != nil { panic(err) } fmt.Println(\u0026quot;符号链接真实路径:\u0026quot; + realPath) } 编译二进制文件go build -o build/binary 创建build文件夹的软连接buid2 ln -s build build2 执行./build2/binary /Users/GanymedeNil/GoglandProjects/go-standard-library/current-working-directory/build2/binary 可执行文件路径 :/Users/GanymedeNil/GoglandProjects/go-standard-library/current-working-directory/build2 符号链接真实路径:/Users/GanymedeNil/GoglandProjects/go-standard-library/current-working-directory/build 原理 从Go 1.8 起，os 包中的Executable方法是解析可执行文件路径的首选方法。该方法返回执行的二进制文件的绝对路径（除非返回错误）。\n要获取二进制文件目录的路径可以使用filepath包中的Dir方法。但是使用该方法有一个缺陷就是返回的路径可能是symlink指向的路径。\n为了避免这种问题，可以使用filepath包中的EvalSymlinks方法，来进行转换。有了这个hack，返回的值就是二进制文件的真实路径。\n注意如果使用go run执行，则实际的可执行文件会在临时目录中。\n","id":68,"section":"posts","summary":"\u003cp\u003egolang 基础库之go获取命令行参数，介绍了如何获取当前工作目录\u003c/p\u003e","tags":["go"],"title":"go基础库之获取当前工作目录","uri":"https://www.ganymedenil.com/2019/05/18/go-standard-library-by-get-current-working-directory.html","year":"2019"},{"content":"golang 基础库之go获取命令行参数，介绍了环境变量的获取与设置以及如何使用默认值\n环境变量的获取与设置以及如何使用默认值 Golang 版本 1.12.1\n前言 环境变量作为配置选项可以显著简化应用的部署，并且这些在云基础架构中也是很常见的。\n通常，本地和自动构建环境的数据库连接配置是不同的。\n如果配置由环境变量定义，则无需更改应用的配置文件或者程序代码。如果环境变量没有设置，则默认配置也是可以使用的。这样对于开发人员就容易多了。\n实现 创建get.go文件，代码如下：\npackage main import ( \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; ) func main(){ conStr := os.Getenv(\u0026quot;DB_CONN\u0026quot;) log.Printf(\u0026quot;连接：%s\\n\u0026quot;,conStr) } 运行命令export DB_CONN=db:/user@example \u0026amp;\u0026amp; go run get.go\n$ export DB_CONN=db:/user@example \u0026amp;\u0026amp; go run get.go 2019/05/18 21:33:39 连接：db:/user@example 创建lookup.go文件，代码如下：\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; ) func main() { key := \u0026quot;DB_CONN\u0026quot; connStr, ex := os.LookupEnv(key) if !ex { log.Printf(\u0026quot;环境变量 %s 没有设置\\n\u0026quot;, key) } fmt.Println(connStr) } 运行命令unset DB_CONN \u0026amp;\u0026amp; go run lookup.go\n$ unset DB_CONN \u0026amp;\u0026amp; go run lookup.go 2019/05/18 21:39:33 环境变量 DB_CONN 没有设置 创建main.go文件，代码如下：\npackage main import ( \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; ) func main() { key := \u0026quot;DB_CONN\u0026quot; // 设置环境变量 os.Setenv(key, \u0026quot;postgres://as:as@example.com/pg?sslmode=verify-full\u0026quot;) val := GetEnvDefault(key, \u0026quot;postgres://as:as@localhost/pg?sslmode=verify-full\u0026quot;) log.Println(\u0026quot;值是 :\u0026quot; + val) os.Unsetenv(key) val = GetEnvDefault(key, \u0026quot;postgres://as:as@127.0.0.1/pg?sslmode=verify-full\u0026quot;) log.Println(\u0026quot;默认值是 :\u0026quot; + val) } func GetEnvDefault(key, defVal string) string { val, ex := os.LookupEnv(key) if !ex { return defVal } return val } 运行命令go run main.go\n$ go run main.go 2019/05/18 21:42:58 值是 :postgres://as:as@example.com/pg?sslmode=verify-full 2019/05/18 21:42:58 默认值是 :postgres://as:as@127.0.0.1/pg?sslmode=verify-full 原理 环境变量的获取和设置分别可以通过os包中Getenv和Setenv方法实现。方法名称已经很明确说明了自身的功能。\n但Getenv方法有个缺点，即使在未设置环境变量的情况下，它也返回一个空的字符串。\nos包中还有一个很有用的方法，LookupEnv，该方法返回两个值，一个是变量的值，另一个则是变量在环境中是否设置的布尔值。而LookupEnv方法则可以克服上面Getenv的缺点。\n当我们要判断是否设置了环境变量以及实现一个默认环境变量的方法，都应该使用LookupEnv。因为如果未设置环境变量，则第二个值会返回false。\n","id":69,"section":"posts","summary":"\u003cp\u003egolang 基础库之go获取命令行参数，介绍了环境变量的获取与设置以及如何使用默认值\u003c/p\u003e","tags":["go"],"title":"go基础库之环境变量的获取与设置以及如何使用默认值","uri":"https://www.ganymedenil.com/2019/05/18/go-standard-library-by-environment%20variables.html","year":"2019"},{"content":"golang 基础库之go获取命令行参数，介绍了如何使用flag包创建程序交互操作\n使用flag包创建程序交互操作 Golang 版本 1.12.1\n前言 通过flag定义程序交互接口的方法主导了基于GNU/Linux、BSD和macOS的系统。比如ls -l在*NIX系统上列出当前目录中的文件就是一个典型的例子。 Go版本的flag包不支持flag的组合，例如ls -ll，所以每个flag必须分开。还有就是Go flag包也不区分长短选项。最后，-flag和--flag是等价的。\n实现 package main import ( \u0026quot;flag\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strings\u0026quot; ) // 自定义类型需要实现flag.Value // 接口才能在flag.Var函数中使用它 type ArrayValue []string func (s *ArrayValue) String() string { return fmt.Sprintf(\u0026quot;%v\u0026quot;, *s) } func (a *ArrayValue) Set(s string) error { *a = strings.Split(s, \u0026quot;,\u0026quot;) return nil } func main() { // 使用返回指针的方法提取flag值 retry := flag.Int(\u0026quot;retry\u0026quot;, -1, \u0026quot;定义最大重试次数\u0026quot;) // 使用XXXVar方法读取flag值 // 在这种情况下，必须在标志之前定义变量 var logPrefix string flag.StringVar(\u0026amp;logPrefix, \u0026quot;prefix\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;Logger 前缀\u0026quot;) var arr ArrayValue flag.Var(\u0026amp;arr, \u0026quot;array\u0026quot;, \u0026quot;输入数组迭代\u0026quot;) // 执行flag.Parse函数， // 读取已定义变量的flag。 // 没有这个调用，flag变量保持为空。 flag.Parse() // 与flag功能无关，只是例子逻辑的一部分 logger := log.New(os.Stdout, logPrefix, log.LstdFlags) retryCount := 0 for retryCount \u0026lt; *retry { logger.Println(\u0026quot;连接重试...\u0026quot;) logger.Printf(\u0026quot;发送的数组 %v\\n\u0026quot;, arr) retryCount++ } } 通过 go build -o util 编译为二进制文件\n在命令行中执行 ./util -retry 2 -prefix=test -array=1,2,3\n返回如下结果\n$ ./util -retry 2 -prefix test -array=1,2,3 test2019/05/14 08:52:45 连接重试... test2019/05/14 08:52:45 发送的数组 [1 2 3] test2019/05/14 08:52:45 连接重试... test2019/05/14 08:52:45 发送的数组 [1 2 3] 原理 对于在程序中获取flag值，flag包定义了两种类型的函数。\n第一种类型是简单名称，比如Int。此函数将返回指向已解析flag值的整数变量的指针。\n第二种是xxxVar这种类型的方法。它们提供相同的功能，但你需要提供指向变量的指针，以便于将解析的flag值存储在给定的变量中。\nGo 库还支持自定义flag类型，函数是Var。自定义类型必须实现flag包中value的接口。上述代码中ArrayValue变量就是实现了flag包中value的String和Set接口。\n上面代码最重要部分是parse()解析flag的函数。在定义所有flag之后并且在访问值之前，必须进行调用，否则将获取不到传入的值。\n延伸 flag包中还包含flag处理的底层函数，以满足不同的需求，推荐阅读一下FlagSet的文档。\n","id":70,"section":"posts","summary":"\u003cp\u003egolang 基础库之go获取命令行参数，介绍了如何使用flag包创建程序交互操作\u003c/p\u003e","tags":["go"],"title":"go基础库之使用flag包创建程序交互操作","uri":"https://www.ganymedenil.com/2019/05/14/go-standard-library-by-flag.html","year":"2019"},{"content":"golang 基础库之go获取命令行参数，介绍了如何获取命令行参数\n获取命令行参数 Golang 版本 1.12.1\n实现 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { args := os.Args // 打印所有命令行参数 fmt.Println(args) // 第一个参数，即slice中的零项，是被调用二进制文件的名称 programName := args[0] fmt.Printf(\u0026quot;二进制名称是: %s \\n\u0026quot;, programName) // 其余的参数可以通过省略第一个参数来获得 otherArgs := args[1:] fmt.Println(otherArgs) for idx, arg := range otherArgs { fmt.Printf(\u0026quot;参数 %d = %s \\n\u0026quot;, idx, arg) } } 原理 Go标准库提供了一些访问程序调用参数的方法。最通用的方法是通过os包中的Args变量访问参数。\n这样，可以从字符串切片中获取命令行所有参数。 这种方法的优点是参数的数量是动态的。\n详细地说，os.Args[0]将返回程序名称。os.Args[1:]没有二进制名称的其余参数。 在现实世界中，最好不要依赖传递给程序的参数数量，而是始终检查参数数组的长度。否则，如果给定索引上的参数不在范围内，程序就会恐慌。\n","id":71,"section":"posts","summary":"\u003cp\u003egolang 基础库之go获取命令行参数，介绍了如何获取命令行参数\u003c/p\u003e","tags":["go"],"title":"go基础库之go获取命令行参数","uri":"https://www.ganymedenil.com/2019/05/13/go-standard-library-by-os-args.html","year":"2019"},{"content":"golang 基础库之golang版本，介绍了如何获取Golang的运行时版本，以及通过源码解析版本是如何获取的\n获取Golang版本 Golang 版本 1.12.1\n实现 package main import ( \u0026quot;log\u0026quot; \u0026quot;runtime\u0026quot; ) const info = ` 程序 %s 运行... 由 Go：%s 版本编译 ` func main() { log.Printf(info, \u0026quot;Example\u0026quot;, runtime.Version()) } 原理 runtime包中包含了许多有用的功能，要找出Go的运行时版本，我们就可以使用Version函数。它可以是提交时的哈希值或者是构建时的日期，也可以是“go1.3”之类的发布标记。\npackage runtime import \u0026quot;runtime/internal/sys\u0026quot; // Version returns the Go tree's version string. // It is either the commit hash and date at the time of the build or, // when possible, a release tag like \u0026quot;go1.3\u0026quot;. func Version() string { return sys.TheVersion } 但Version函数事实上只是返回了runtime/internal/sys的TheVersion常量。常量位于$GOROOT/src/runtime/internal/sys/zversion.go中。\n// Code generated by go tool dist; DO NOT EDIT. package sys const TheVersion = `go1.12.1` const Goexperiment = `` const StackGuardMultiplierDefault = 1 通过该文件的注释我们可以了解到，该文件是由go tool dist生成，然后我们可以在$GOROOT/src/cmd/dist/buildruntime.go 这个文件中找到生成该文件的方法mkzversion。进而我们找到了常量TheVersion的赋值方法findgoversion。\npackage main // mkzversion writes zversion.go: // //\tpackage sys // //\tconst TheVersion = \u0026lt;version\u0026gt; //\tconst Goexperiment = \u0026lt;goexperiment\u0026gt; //\tconst StackGuardMultiplier = \u0026lt;multiplier value\u0026gt; // func mkzversion(dir, file string) { var buf bytes.Buffer fmt.Fprintf(\u0026amp;buf, \u0026quot;// Code generated by go tool dist; DO NOT EDIT.\\n\u0026quot;) fmt.Fprintln(\u0026amp;buf) fmt.Fprintf(\u0026amp;buf, \u0026quot;package sys\\n\u0026quot;) fmt.Fprintln(\u0026amp;buf) fmt.Fprintf(\u0026amp;buf, \u0026quot;const TheVersion = `%s`\\n\u0026quot;, findgoversion()) fmt.Fprintf(\u0026amp;buf, \u0026quot;const Goexperiment = `%s`\\n\u0026quot;, os.Getenv(\u0026quot;GOEXPERIMENT\u0026quot;)) fmt.Fprintf(\u0026amp;buf, \u0026quot;const StackGuardMultiplierDefault = %d\\n\u0026quot;, stackGuardMultiplierDefault()) writefile(buf.String(), file, writeSkipSame) } 而findgoversion方法所在文件是$GOROOT/src/cmd/dist/build.go。\npackage main // findgoversion determines the Go version to use in the version string. func findgoversion() string { // The $GOROOT/VERSION file takes priority, for distributions // without the source repo. path := pathf(\u0026quot;%s/VERSION\u0026quot;, goroot) if isfile(path) { b := chomp(readfile(path)) // Commands such as \u0026quot;dist version \u0026gt; VERSION\u0026quot; will cause // the shell to create an empty VERSION file and set dist's // stdout to its fd. dist in turn looks at VERSION and uses // its content if available, which is empty at this point. // Only use the VERSION file if it is non-empty. if b != \u0026quot;\u0026quot; { // Some builders cross-compile the toolchain on linux-amd64 // and then copy the toolchain to the target builder (say, linux-arm) // for use there. But on non-release (devel) branches, the compiler // used on linux-amd64 will be an amd64 binary, and the compiler // shipped to linux-arm will be an arm binary, so they will have different // content IDs (they are binaries for different architectures) and so the // packages compiled by the running-on-amd64 compiler will appear // stale relative to the running-on-arm compiler. Avoid this by setting // the version string to something that doesn't begin with devel. // Then the version string will be used in place of the content ID, // and the packages will look up-to-date. // TODO(rsc): Really the builders could be writing out a better VERSION file instead, // but it is easier to change cmd/dist than to try to make changes to // the builder while Brad is away. if strings.HasPrefix(b, \u0026quot;devel\u0026quot;) { if hostType := os.Getenv(\u0026quot;META_BUILDLET_HOST_TYPE\u0026quot;); strings.Contains(hostType, \u0026quot;-cross\u0026quot;) { fmt.Fprintf(os.Stderr, \u0026quot;warning: changing VERSION from %q to %q\\n\u0026quot;, b, \u0026quot;builder \u0026quot;+hostType) b = \u0026quot;builder \u0026quot; + hostType } } return b } } // The $GOROOT/VERSION.cache file is a cache to avoid invoking // git every time we run this command. Unlike VERSION, it gets // deleted by the clean command. path = pathf(\u0026quot;%s/VERSION.cache\u0026quot;, goroot) if isfile(path) { return chomp(readfile(path)) } // Show a nicer error message if this isn't a Git repo. if !isGitRepo() { fatalf(\u0026quot;FAILED: not a Git repo; must put a VERSION file in $GOROOT\u0026quot;) } // Otherwise, use Git. // What is the current branch? branch := chomp(run(goroot, CheckExit, \u0026quot;git\u0026quot;, \u0026quot;rev-parse\u0026quot;, \u0026quot;--abbrev-ref\u0026quot;, \u0026quot;HEAD\u0026quot;)) // What are the tags along the current branch? tag := \u0026quot;devel\u0026quot; precise := false // If we're on a release branch, use the closest matching tag // that is on the release branch (and not on the master branch). if strings.HasPrefix(branch, \u0026quot;release-branch.\u0026quot;) { tag, precise = branchtag(branch) } if !precise { // Tag does not point at HEAD; add hash and date to version. tag += chomp(run(goroot, CheckExit, \u0026quot;git\u0026quot;, \u0026quot;log\u0026quot;, \u0026quot;-n\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;--format=format: +%h %cd\u0026quot;, \u0026quot;HEAD\u0026quot;)) } // Cache version. writefile(tag, path, 0) return tag } 注释有很多但我们只需要理解版本的获取流程即可，首先$GOROOT/VERSION文件是优先级最高的，如果该文件不存在或者为空，则使用$GOROOT/VERSION.cache文件。如果$GOROOT/VERSION.cache也没有，则工具开始尝试使用Git信息来解析版本，但在这种情况下，Go的源码必须是通过git的方式下载的。\n","id":72,"section":"posts","summary":"\u003cp\u003egolang 基础库之golang版本，介绍了如何获取Golang的运行时版本，以及通过源码解析版本是如何获取的\u003c/p\u003e","tags":["go"],"title":"go基础库之go版本获取","uri":"https://www.ganymedenil.com/2019/05/11/go-standard-library-by-runtime-version.html","year":"2019"},{"content":"rust的基础部分，变量、常量、数据类型、函数、注释和控制流\n变量与可变性 变量使用let关键字，默认不可变\n但在变量名之前加mut关键字来使其可变\n常量使用const关键字，并且必须注明值类型\nconst MAX_POINTS: u32 = 100_000; 变量隐藏，重复使用let关键字来多次隐藏。当再次使用let时，实际上创建了一个新变量，我们可以改变值的类型，但复用这个名字\nfn main(){ let x =5; let x = x + 1; let x = x * 2; println!(\u0026quot;x值是:{}\u0026quot;,x); // x值是:12 } 使用mut创建的变量，二次赋值必须是同类型\n数据类型 标量类型 整数 长度 有符号 无符号 8-bit i8 u8 16-bit i16 u16 32-bit i32 u32 64-bit i64 u64 arch isize usize 每一个有符号的变体可以储存包含从 -(2^(n-1)) 到 2^(n-1)-1 在内的数字，这里 n 是变体使用的位数。所以 i8 可以储存从 -(2^(7)) 到 2^(7)-1 在内的数字，也就是从 -128 到 127。无符号的变体可以储存从 0 到 2^(n)-1 的数字，所以 u8 可以储存从 0 到 2^(8)-1 的数字，也就是从 0 到 255。 另外，isize 和 usize 类型依赖运行程序的计算机架构：64 位架构上它们是 64 位的， 32 位架构上它们是 32 位的。\nRust中的整型字面值\n数字字面值 例子 Decimal 98_222 Hex 0xff Octal 0o77 Binary 0b1111_0000 Byte(u8 only) b'A' 那么该使用哪种类型的数字呢？如果拿不定主意，Rust 的默认类型通常就很好，数字类型默认是 i32：它通常是最快的，甚至在 64 位系统上也是。isize 或 usize 主要作为某些集合的索引。\n整型溢出\n当在 debug 模式编译时，Rust 检查这类问题并使程序 panic，这个术语被 Rust 用来表明程序因错误而退出。 在 release 构建中，Rust 不检测溢出，相反会进行一种被称为 “two’s complement wrapping” 的操作。简而言之，256 变成 0，257 变成 1，依此类推。依赖溢出被认为是一种错误，即便可能出现这种行为。如果你确实需要这种行为，标准库中有一个类型显式提供此功能，Wrapping。\n浮点型 Rust 的浮点数类型是 f32 和 f64，分别占 32 位和 64 位。默认类型是 f64，因为在现代 CPU 中，它与 f32 速度几乎一样，不过精度更高。\n布尔型 Rust 中的布尔类型有两个可能的值：true 和 false。Rust 中的布尔类型使用 bool 表示。\n字符类型 Rust 的 char 类型是语言中最原生的字母类型（注意 char 由单引号指定，不同于字符串使用双引号。）\n符合类型 元组类型 fn main() { let tup: (i32, f64, u8) = (500, 6.4, 1); } fn main() { let tup = (500, 6.4, 1); let (x, y, z) = tup; println!(\u0026quot;The value of y is: {}\u0026quot;, y); } fn main() { let x: (i32, f64, u8) = (500, 6.4, 1); let five_hundred = x.0; let six_point_four = x.1; let one = x.2; } 数组类型 与元组不同，数组中的每个元素的类型必须相同。Rust 中的数组是固定长度的：一旦声明，它们的长度不能增长或缩小。\nfn main() { let a = [1, 2, 3, 4, 5]; } let a: [i32; 5] = [1, 2, 3, 4, 5]; fn main() { let a = [1, 2, 3, 4, 5]; let first = a[0]; let second = a[1]; } 当访问数组越界，编译并不会产生任何错误，不过程序会出现一个运行时（runtime）错误并且不会成功退出。\n函数 fn main() { another_function(5, 6); } fn another_function(x: i32, y: i32) { println!(\u0026quot;The value of x is: {}\u0026quot;, x); println!(\u0026quot;The value of y is: {}\u0026quot;, y); } 语句（Statements）是执行一些操作但不返回值的指令。表达式（Expressions）计算并产生一个值。\nfn main() { let x = 5; let y = { let x = 3; x + 1 }; println!(\u0026quot;The value of y is: {}\u0026quot;, y); // The value of y is: 4 } 具有返回值的函数 函数可以向调用它的代码返回值。我们并不对返回值命名，但要在箭头（-\u0026gt;）后声明它的类型。在 Rust 中，函数的返回值等同于函数体最后一个表达式的值。使用 return 关键字和指定值，可从函数中提前返回；但大部分函数隐式的返回最后的表达式。\nfn five() -\u0026gt; i32 { 5 } fn main() { let x = five(); println!(\u0026quot;The value of x is: {}\u0026quot;, x); } 注释 只允许 // 这种写法。\n控制流 if 表达式 fn main() { let number = 3; if number \u0026lt; 5 { println!(\u0026quot;condition was true\u0026quot;); } else { println!(\u0026quot;condition was false\u0026quot;); } } fn main() { // 我们要判断 number 不为零 let number = 3; // if 表达式只允许条件返回 bool 类型 // 这里改为 number != 0 才能编译通过 if number { println!(\u0026quot;number was three\u0026quot;); } } fn main() { let number = 6; if number % 4 == 0 { println!(\u0026quot;number is divisible by 4\u0026quot;); } else if number % 3 == 0 { println!(\u0026quot;number is divisible by 3\u0026quot;); } else if number % 2 == 0 { println!(\u0026quot;number is divisible by 2\u0026quot;); } else { println!(\u0026quot;number is not divisible by 4, 3, or 2\u0026quot;); } } 在 let 语句中使用 if fn main() { let condition = true; let number = if condition { 5 } else { 6 }; println!(\u0026quot;The value of number is: {}\u0026quot;, number); // The value of number is: 5 } 在这种使用场景中，if 和 else 分支的值类型必须一致，不然编译会提示错误。\n##使用循环重复执行\nloop fn main() { let mut counter = 0; let result = loop { counter += 1; if counter == 10 { break counter * 2; } }; assert_eq!(result, 20); } while 当条件为真，执行循环。当条件不再为真，调用 break 停止循环。\nfn main() { let mut number = 3; while number != 0 { println!(\u0026quot;{}!\u0026quot;, number); number = number - 1; } println!(\u0026quot;LIFTOFF!!!\u0026quot;); } for fn main() { let a = [10, 20, 30, 40, 50]; for element in a.iter() { println!(\u0026quot;the value is: {}\u0026quot;, element); } } ","id":73,"section":"posts","summary":"\u003cp\u003erust的基础部分，变量、常量、数据类型、函数、注释和控制流\u003c/p\u003e","tags":["rust"],"title":"rust语言学习（一）","uri":"https://www.ganymedenil.com/2019/04/07/stady-rust-01.html","year":"2019"},{"content":"虽然hexo生成的静态博客很安全，也不需要像Wordpress 那样运维服务器，但是基于本地的静态文件生成和发布还是比较麻烦的，尤其是多个电脑的切换，你每台电脑都需要安装一整套的nodejs 环境和hexo执行环境，通过git服务的hook进行hexo博客生成与部署，就是为了解决这个问题。\n创建git服务 安装git 我使用的 CentOS 执行 yum install git 即可安装git\n为git创建用户和群组 添加组 groupadd git\n添加用户并将用户加入组 useradd git -g git\n创建证书登录 cd /home/git\nmkdir .ssh\nchmod 700 .ssh\ntouch .ssh/authorized_keys\nchmod 600 .ssh/authorized_keys\n收集所有需要登录的用户的公钥，公钥位于id_rsa.pub文件中，把我们的公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。\n这里有一个坑就是在CentOS里ssh生效必须满足两个条件\n.ssh目录的权限必须是700 .ssh/authorized_keys文件权限必须是600 创建git用户的密钥 ssh-keygen -t rsa -C \u0026quot;willard_liu@XXXX.com\u0026quot;,同样的把刚创建的公钥id_rsa.pub加入到 authorized_keys 中\n配置一下 git 用户下的git 信息\n$ git config --global user.name author #将用户名设为author $ git config --global user.email author@corpmail.com #将用户邮箱设为author@corpmail.com 初始化Git仓库 首先我们选定一个目录作为Git仓库，假定是/data/gitrepo/test.git，在/data/gitrepo目录下输入命令：\ncd /data\nmkdir gitrepo\nchown git:git gitrepo/\ncd gitrepo\ngit init --bare test.git\n以上命令Git创建一个空仓库，服务器上的Git仓库通常都以.git结尾。然后，把仓库所属用户改为git：\nchown -R git:git test.git\n测试一下仓库是否有问题\n$ git clone git@xxx.xxx.xxx.xxx:/data/gitrepo/test.git Cloning into 'test'... warning: You appear to have cloned an empty repository. Checking connectivity... done. 到这我们的git仓库就搭建完成了\n然后我们把 hexo 项目下的source 里面的内容全丢到这个git项目下就行了\nhexo 项目部署 安装 nodejs这个不再这里展开\n安装 hexo 执行npm install hexo-cli -g\n软链 hexo 到 /usr/bin 下方便等下在 git 用户下使用\nsudo ln -s /usr/local/lib/nodejs/node-v**.**.**-linux-x64/bin/hexo /usr/bin/hexo\n我们在 data 下再创建一个 hexo 项目目录 mkdir blog\n然后我们把本地完整的hexo项目除了node_modules 和 source 目录外的所有文件和文件夹都上传到 /data/blog下\n切换用户到git su git，然后克隆刚才我们的仓库 到 source 目录\ngit clone git@xxx.xxx.xxx.xxx:/data/gitrepo/test.git /data/blog/source\n进入/data/blog安装项目组件npm install\n执行hexo g 和 hexo d,看与本地执行的是否一致\n如果上述步骤都没问题我们就需要把上面的步骤配置到仓库的hook上了\n进入 cd /data/gitrepo/test.git/hooks/，如果没有post-receive这个文件，就创建一个 touch post-receive，再 配置一下权限 chmod 755 post-receive，具体各个hook的含义参考git的文档\n配置 post-receive\n# 进入source 目录 cd /data/blog/source pwd echo \u0026quot;==========拉取最新的文章==========\u0026quot; unset GIT_DIR # 强制拉取覆盖本地内容 git fetch --all git reset --hard origin/master git pull echo \u0026quot;==========拉取结束==========\u0026quot; # 进入blog 目录 cd /data/blog pwd echo \u0026quot;==========清除html==========\u0026quot; hexo clean echo \u0026quot;==========开始生成html==========\u0026quot; hexo g echo \u0026quot;==========生成html完成==========\u0026quot; echo \u0026quot;==========开始部署==========\u0026quot; hexo d echo \u0026quot;==========部署完毕==========\u0026quot; 在本地 push 看一下是否有以上远程执行的操作输出\n如果上述步骤都ok了，那么我们出于安全考虑需要禁用git的远程登录\n通过编辑/etc/passwd文件完成。找到类似下面的一行：\ngit❌1001:1001:,,,:/home/git:/bin/bash 改为：\ngit❌1001:1001:,,,:/home/git:/usr/bin/git-shell 这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。\n至此我们就完成了所有步骤，以后我们需要写博客只需要在本地安装git，如果是首次还需将公钥 id_rsa.pub的内容配置到服务器git用户下的 .ssh/authorized_keys文件中，然后拉取发布 source 也就是我们的markdown的git仓库地址就可以完成整个博客发布流程了。\n","id":74,"section":"posts","summary":"\u003cp\u003e虽然hexo生成的静态博客很安全，也不需要像Wordpress 那样运维服务器，但是基于本地的静态文件生成和发布还是比较麻烦的，尤其是多个电脑的切换，你每台电脑都需要安装一整套的nodejs 环境和hexo执行环境，通过git服务的hook进行hexo博客生成与部署，就是为了解决这个问题。\u003c/p\u003e","tags":["hexo"],"title":"使用git hook 部署 hexo 静态博客","uri":"https://www.ganymedenil.com/2019/01/13/Build-hexo-git.html","year":"2019"},{"content":"主要内容：通过包安装和编译安装的方式对 NGINX 进行安装。\nRHEL/CentOS 通过包（Packages）安装 NGINX 要安装最新的 NGINX 版本，请在 /etc/yum.repos.d/nginx.repo 中添加以下内容，以添加 NGINX 主线仓库（mainline repository）\n[nginx] name=nginx repo baseurl=http://nginx.org/packages/mainline/OS/OSRELEASE/$basearch/ gpgcheck=0 enabled=1 OS 部分用 rhel 或 centos 替换，OSRELEASE 部分替换为 5 , 6 或 7 ，以便对应正确的版本。\n不知道自己是什么系统版本的，可以通过运行 cat /etc/redhat-release ，查看你本机的系统版本信息。\n仓库添加完毕后，更新包，然后开始安装 NGINX。\nyum update yum install nginx 详细信息，请参阅 http://nginx.org/en/linux_packages.html#mainline 上的官方文档。\n通过编译安装 首先我们需要安装包构建工具和额外的 Extra Packages For Enterprise Linux（EPEL）仓库：\nsudo yum install yum-utils epel-release mock 然后更新/etc/yum.repos.d/nginx.repo，添加额外的仓库源：\n[nginx-source] name=nginx source repo baseurl=http://nginx.org/packages/mainline/centos/7/SRPMS/ gpgcheck=0 enabled=1 在这个例子中，我们使用CentOS 7作为演示。如何修改为其他版本的CentOS，参阅上一节用包安装中的相关说明。\n更新仓库后，我们创建一个目录用于编译， 然后下载源代码包（SRPM）：\nmkdir ~/nginxbuild cd ~/nginxbuild yumdownloader --source nginx 接下来，下载所需的包以完成编译：\nyum-builddep nginx 一旦下载了所有开发包，我们现在可以从SRPM中提取文件：\nrpm2cpio nginx-1.9.10-1.el7.ngx.src.rpm | cpio -idmv 请注意，目录名称可能因您安装的NGINX版本而异。例如，这里是nginx-1.9.10，因为我安装了NGINX 1.9.10。\n您应该看到源文件的输出类似于： 如果我们想要更新配置并应用补丁或更改其中一个默认值，那么可以通过编辑文件来完成。\n我们现在可以使用 mock 从源代码重建这些文件，这是一个用于构建包的工具。 mock 的优点是所有开发依赖项都包含在 chrooted 环境中，因此它不会使主安装变得混乱。可以清理和删除这个 chrooted 环境，而不会对主机系统产生任何影响，如果您需要可重复的构建，这是很好的。\n要编译，只需要运行如下命令：\nmock --buildsrpm --spec ~/nginxbuild/nginx.spec --sources ~/nginxbuild 这将生成SRPM，它们将与相关的日志文件一起位于 /var/lib/moc/epel-7-x86_64/result目录中。现在我们已经重建了SRPM，我们可以编译它了。同样，我们将使用mock，以便整齐地包含所有内容：\nmock --no-clean --rebuild var/lib/mock/epel-7-x86_64/result/nginx-1.9.11-1.el7.ngx.src.rpm 根据你机器的处理能力，这可能需要五分钟或更长时间才能完成。编译完成后，你应该在 /var/lib/mock/epel-7-x86_64 目录中看到生成的二进制 RPM 以及调试用的 RPM 。这是一个例子：\n-rw-rw-r-- 1 demo mock 159K Feb 10 20:59 build.log -rw-r--r-- 1 demo mock 889K Feb 10 20:57 nginx-1.9.11-1.el7.ngx.src.rpm -rw-r--r-- 1 demo mock 803K Feb 10 20:59 nginx-1.9.11-1.el7.ngx.x86_64.rpm -rw-r--r-- 1 demo mock 3.1M Feb 10 20:59 nginx-debuginfo-1.9.11-1.el7.ngx.x86_64.rpm -rw-rw-r-- 1 demo mock 45K Feb 10 20:59 root.log -rw-rw-r-- 1 demo mock 1000 Feb 10 20:59 state.log 现在我们有了新的二进制文件，我们可以通过 yum 安装它：\nsudo yum install /var/lib/mock/epel-7-x86_64/result/nginx-1.9.11-1. ngx.x86_64.rpm 最好使用 yum 来安装软件包，因为它也可以安装任何依赖项。\n测试 无论你的安装方法如何，一旦启动并运行 NGINX ，你应该能够通过IP地址加 / 或完全限定域名（FQDN）浏览它，并查看与此处显示的内容非常相似的内容： 要启动，停止和重新启动 NGINX（如果使用官方二进制文件安装），你可以使用标准的 Linux init 系统。不同的OS版本之间存在非常小的差异，因此确保正确使用正确的变量命令非常重要。\n当Ubuntu从15.04切换到 systemd 作为默认的 init 系统时，请确保仔细检查您正在使用的版本。\n各版本的操作可参考以下表\nActivity/OS CentOS / RedHat 6 CentOS / RedHat 7 Ubuntu 14.04 / Debian 8 Start NGINX service nginx start systemctl start nginx service nginx start Stop NGINX service nginx stop systemctl stop nginx service nginx stop Restart NGINX service nginx restart systemctl restart nginx service nginx restart Reload NGINX service nginx reload N/A N/A NGINX 的某些配置修改将需要完全重启 NGINX，而其他修改只需要重新加载配置。在大多数已修改配置文件的情况下，只需重新加载即可。 NGINX 将 fork 一组新的 worker 进程，并允许现有 workers 进程完成处理并干净地退出，这样就可以避免停机。\n我们可以在进行配置更改后检查 NGINX 配置文件，以确保语法正确。为此，我们运行以下命令：\n/usr/sbin/nginx -t 如果一切正确，你应该看到以下内容：\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 如果有任何错误，请在错误提示对应的配置行检查是否存在语法错误。\n","id":75,"section":"posts","summary":"\u003cp\u003e主要内容：通过包安装和编译安装的方式对 NGINX 进行安装。\u003c/p\u003e","tags":["nginx"],"title":"NGINX 安装","uri":"https://www.ganymedenil.com/2018/08/14/nginx-install.html","year":"2018"},{"content":"围绕容器的重要操作，包括创建一个容器、启动容器、终止一个容器、进入容器内执行操作、删除容器和通过导入导出容器来实现容器迁移等。\n操作 Docker 容器 容器是镜像的一个运行实例。所不同的是，镜像是静态的只读文件，而容器带有运行时需要的可写文件层。如果认为虚拟机是模拟运行的一整套操作系统（包括内核、应用运行态环境和其他系统环境）和跑在上面的应用，那么Docker容器就是独立运行的一个（或一组）应用，以及它们必需的运行环境。\n1. 新建容器 docker create [OPTIONS] IMAGE [COMMAND] [ARG...]\n例子：\n$ docker create -it ubuntu:latest af8f4f922dafee22c8fe6cd2ae11d16e25087d61f1b1fa55b36e94db7ef45178 $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES af8f4f922daf ubuntu:latest \u0026quot;/bin/bash\u0026quot; 17 seconds ago Created silly_euler 使用docker create 命令新建的容器处于停止状态，可以使用docker start命令来启动它。\nCreate命令和后续的run命令支持的选项都十分复杂，主要包括如下几大类：与容器运行模式相关、与容器和环境配置相关、与容器资源限制和安全保护相关。 具体详情可以通过命令 docker create --help 获得。\n2. 启动容器 docker start [OPTIONS] CONTAINER [CONTAINER...]\n3. 新建并启动容器 docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n当利用docker run来创建并启动容器时，Docker在后台运行的标准操作包括：\n·检查本地是否存在指定的镜像，不存在就从公有仓库下载；\n·利用镜像创建一个容器，并启动该容器；\n·分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层；\n·从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中；\n·从网桥的地址池配置一个IP地址给容器；\n·执行用户指定的应用程序；\n·执行完毕后容器被自动终止。\n对于所创建的bash容器，当使用exit命令退出之后，容器就自动处于退出（Exited）状态了。这是因为对Docker容器来说，当运行的应用退出后，容器也就没有继续运行的必要了。\n某些时候，执行docker run会出错，因为命令无法正常执行容器会直接退出，此时可以查看退出的错误代码。\n默认情况下，常见错误代码包括： ·125：Docker daemon执行出错，例如指定了不支持的Docker命令参数； ·126：所指定命令无法执行，例如权限出错； ·127：容器内命令无法找到。\n命令执行后出错，会默认返回错误码。\n4. 守护态运行 让Docker容器在后台以守护态（Daemonized）形式运行。此时，可以通过添加-d参数来实现。\n$ docker run -d ubuntu /bin/sh \\ -c \u0026quot;while true; do echo hello world; sleep 1; done\u0026quot; ce554267d7a4c34eefc92c5517051dc37b918b588736d0823e4c846596b04d83 终止容器 docker stop [OPTIONS] CONTAINER [CONTAINER...]\n首先向容器发送SIGTERM信号，等待一段超时时间（默认为10秒）后，再发送SIGKILL信号来终止容器\n注意：docker kill命令会直接发送SIGKILL信号来强行终止容器。 此外，当Docker容器中指定的应用终结时，容器也会自动终止。例如对于上一节中只启动了一个终端的容器，用户通过exit命令或Ctrl+d来退出终端时，所创建的容器立刻终止，处于stopped状态。\n进入容器 1. attach 命令 docker attach [OPTIONS] CONTAINER\n支持三个主要选项：\n--detach-keys[=[]] 指定退出attach模式的快捷键序列，默认是CTRL-p CTRL-q\n--no-stdin=true|false 是否关闭标准输入，默认是保持打开\n--sig-proxy=true|false 是否代理收到的系统信号给应用进程，默认为true\n但是使用attach命令有时候并不方便。当多个窗口同时用attach命令连到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时，其他窗口也无法执行操作了。\n2. exec 命令 docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n-i，--interactive=true|false 打开标准输入接受用户输入命令，默认为false\n--privileged=true|false 是否给执行命令以高权限，默认为false\n-t，--tty=true|false 分配伪终端，默认为false\n-u，--user=\u0026quot;\u0026quot; 执行命令的用户名或ID\n通过指定-it参数来保持标准输入打开，并且分配一个伪终端。通过exec命令对容器执行操作是最为推荐的方式。\n删除容器 docker rm [OPTIONS] CONTAINER [CONTAINER...]\n主要支持的选项包括：\n-f，--force=false 是否强行终止并删除一个运行中的容器\n-l，--link=false 删除容器的连接，但保留容器\n-v，--volumes=false 删除容器挂载的数据卷\n默认情况下，docker rm命令只能删除处于终止或退出状态的容器，并不能删除还处于运行状态的容器。\n如果要直接删除一个运行中的容器，可以添加-f参数。Docker会先发送SIGKILL信号给容器，终止其中的应用，之后强行删除。\n导入和导出容器 1. 导出容器 docker export [OPTIONS] CONTAINER\n例子：\n$ docker export -o test_for_run.tar ce5 $ ls test_for_run.tar $ docker export e81 \u0026gt;test_for_stop.tar $ ls test_for_run.tar test_for_stop.tar 2.导入容器 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]\n用户可以通过-c，\u0026ndash;change=[]选项在导入的同时执行对容器进行修改的Dockerfile指令\n$ docker import test_for_run.tar - test/ubuntu:v1.0 $ docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE test/ubuntu v1.0 9d37a6082e97 About a minute ago 171.3 MB ","id":76,"section":"posts","summary":"\u003cp\u003e围绕容器的重要操作，包括创建一个容器、启动容器、终止一个容器、进入容器内执行操作、删除容器和通过导入导出容器来实现容器迁移等。\u003c/p\u003e","tags":["docker"],"title":"操作 Docker 容器","uri":"https://www.ganymedenil.com/2018/07/10/use-docker-container.html","year":"2018"},{"content":"围绕Docker镜像的一系列重要命令操作，包括获取、查看、搜索、删除、创建、存出和载入、上传等。\nDocker 运行容器前需要本地存在对应的镜像，如果镜像没保存在本地，Docker 会尝试先从默认镜像仓库下载（默认使用 Docker Hub 公共注册服务器中的仓库），用户也可以通过配置，使用自定义的镜像仓库。\n1. 获取镜像 docker pull NAME [:TAG]\nNAME 是镜像仓库的名称（用来区分镜像），TAG 是镜像的标签（往往用来表示版本信息）。通常情况下，描述一个镜像需要包括“名称+标签”信息。 例如，获取一个 Ubuntu 14.04 系统的基础镜像可以使用如下的命令： docker pull ubuntu:14.04 对于 Docker 镜像来说，如果不显式指定 TAG，则默认会选择 latest 标签，这会下载仓库中最新版本的镜像。 例如： docker pull ubuntu 下载最新的 Ubuntu 系统镜像，与 docker pull ubuntu:latest 一致。\n一般来说，镜像的latest标签意味着该镜像的内容会跟踪最新的非稳定版本而发布，内容是不稳定的。当前Ubuntu最新的发行版本为16.04，latest镜像实际上就是16.04镜像，用户可以下载ubuntu：16.04镜像并查看，两者的数字摘要值是一致的。从稳定性上考虑，不要在生产环境中忽略镜像的标签信息或使用默认的latest标记的镜像。\n严格地讲，镜像的仓库名称中还应该添加仓库地址（即registry，注册服务器）作为前缀，只是我们默认使用的是Docker Hub服务，该前缀可以忽略。 例如，docker pull ubuntu:14.04 命令相当于docker pull registry.hub.docker.com/ubuntu:14.04 命令，即从默认的注册服务器Docker Hub Registry 中的 ubuntu 仓库来下载标记为14.04的镜像。\n子命令： -a,--all-tag=true|false 是否获取仓库中的所有镜像，默认为否。\n2. 查看镜像信息 使用 images 命令列出镜像 docker images [OPTIONS] [REPOSITORY[:TAG]]\n在列出的信息中，可以看到以下几个字段信息 REPOSITORY:来自于哪个仓库，比如ubuntu仓库用来保存ubuntu系列的基础镜像。\nTAG:镜像的标签信息，比如14.04、latest用来标注不同的版本信息。标签只是标记，并不能标识镜像内容。\nIMAGE ID:镜像的ID（唯一标识镜像），如ubuntu：latest和ubuntu：16.04镜像的ID都是2fa927b5cdd3，说明它们目前实际上指向同一个镜像。\nCREATED:创建时间，说明镜像最后的更新时间。\nSIZE:镜像大小，优秀的镜像往往体积都较小。\n子命令： -a，--all=true|false 列出所有的镜像文件（包括临时文件），默认为否 -digests=true|false 列出镜像的数字摘要值，默认为否 -f，--filter=[] 过滤列出的镜像，如dangling=true只显示没有被使用的镜像；也可指定带有特定标注的镜像等。\n--format=\u0026quot;TEMPLATE\u0026quot; 控制输出格式，如.ID代表ID信息，.Repository代表仓库信息等\n--no-trunc=true|false 对输出结果中太长的部分是否进行截断，如镜像的ID信息，默认为是\n-q，--quiet=true|false 仅输出ID信息，默认为否。\n其中，对输出结果进行控制的选项如 -f，\u0026ndash;filter=[]、\u0026ndash;no-trunc=true|false、-q，\u0026ndash;quiet=true|false等，大部分子命令都支持。\n使用tag命令添加镜像标签 docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]\n例如添加一个新的myubuntu：latest镜像标签： docker tag ubuntu:latest myubuntu:latest\n之后，用户就可以直接使用myubuntu:latest来表示这个镜像了。 docker tag命令添加的标签实际上起到了类似链接的作用。\n使用inspect命令查看详细信息 docker inspect OPTIONS] NAME|ID [NAME|ID...]\n使用 docker inspect 命令可以获取该镜像的详细信息，包括制作者、适应架构、各层的数字摘要等。 例如： docker inspect ubuntu:14.04\n返回的是一个JSON格式的消息，如果我们只要其中一项内容时，可以使用参数-f来指定，例如，获取镜像的Architecture：\ndocker inspect -f {{\u0026quot;.Architecture\u0026quot;}} amd64\n使用history命令查看镜像历史 docker history [OPTIONS] IMAGE\n该命令将列出各层的创建信息。\n例如查看 ubuntu:14.04 镜像的创建过程\ndocker history ubuntu:14.04\n3. 搜索镜像 docker search [OPTIONS] TERM\n搜索远端仓库中共享的镜像，默认搜索官方仓库中的镜像。\n支持的参数：\n--automated=true|false 仅显示自动创建的镜像，默认为否\n--no-trunc=true|false 输出信息不截断显示，默认为否\n-s，--stars=X 指定仅显示评价为指定星级以上的镜像，默认为0，即输出所有镜像\n注:最新的 docker 18 版本中，automated 与 starts 都已经归并到 filter 中，--filter=stars、--filter=is-automated。\n例如，搜索所有自动创建的评价为1+的带nginx关键字的镜像，如下所示：\n$ docker search --automated -s 3 nginx (version 18) $ docker search --filter=stars=3 --filter=is-automated=true nginx NAME DESCRIPTION STARS OFFICIAL AUTOMATED jwilder/nginx-proxy Automated Nginx reverse proxy for docker con… 1357 [OK] richarvey/nginx-php-fpm Container running Nginx + PHP-FPM capable of… 586 [OK] jrcs/letsencrypt-nginx-proxy-companion LetsEncrypt container to use with nginx as p… 385 [OK] webdevops/php-nginx Nginx with PHP-FPM 106 [OK] zabbix/zabbix-web-nginx-mysql Zabbix frontend based on Nginx web-server wi… 58 [OK] bitnami/nginx Bitnami nginx Docker Image 54 [OK] 1and1internet/ubuntu-16-nginx-php-phpmyadmin-mysql-5 ubuntu-16-nginx-php-phpmyadmin-mysql-5 36 [OK] tobi312/rpi-nginx NGINX on Raspberry Pi / armhf 20 [OK] wodby/drupal-nginx Nginx for Drupal container image 9 [OK] blacklabelops/nginx Dockerized Nginx Reverse Proxy Server. 9 [OK] webdevops/nginx Nginx container 8 [OK] nginxdemos/hello NGINX webserver that serves a simple page co… 7 [OK] 1science/nginx Nginx Docker images that include Consul Temp… 4 [OK] 返回信息包含关键字的镜像，其中包括镜像名字、描述、星级（表示该镜像的受欢迎程度）、是否官方创建、是否自动创建等。\n默认的输出结果将按照星级评价进行排序。\n4. 删除镜像 使用标签删除镜像 docker rmi [OPTIONS] IMAGE [IMAGE...]\n例如，要删除掉myubuntu:latest镜像，可以使用如下命令： docker rmi myubuntu:latest\n当同一个镜像拥有多个标签的时候，docker rmi 命令只是删除该镜像多个标签中的指定标签而已，并不影响镜像文件。但当镜像只剩下一个标签的时候就要小心了，此时再使用docker rmi命令会彻底删除镜像。\n使用镜像 ID 删除镜像 当使用 docker rmi 命令，并且后面跟上镜像的ID（也可以是能进行区分的部分ID串前缀）时，会先尝试删除所有指向该镜像的标签，然后删除该镜像文件本身。\n注意，当有该镜像创建的容器存在时，镜像文件默认是无法被删除的。\n如果要想强行删除镜像，可以使用-f参数。\n注意，通常并不推荐使用-f参数来强制删除一个存在容器依赖的镜像。正确的做法是，先删除依赖该镜像的所有容器，再来删除镜像。\n5. 创建镜像 创建镜像的方法主要有三种：基于已有镜像的容器创建、基于本地模板导入、基于Dockerfile创建。\n基于已有镜像的容器创建 docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n-a，--author=\u0026quot;\u0026quot; 作者信息\n-c，--change=[] 提交的时候执行Dockerfile指令，包括CMD|ENTRYPOINT|ENV|EXPOSE|LABEL|ONBUILD|USER|VOLUME|WORKDIR等\n-m，--message=\u0026quot;\u0026quot; 提交消息\n-p，--pause=true 提交时暂停容器运行\n例子： 先进入容器，进行一些变更\n$ docker run -it ubuntu:14.04 /bin/bash root@a925cb40b3f0:/# touch test root@a925cb40b3f0:/# exit 提交改变生成一个新的镜像\n$ docker commit -m \u0026quot;Added a new file\u0026quot; -a \u0026quot;Docker Newbee\u0026quot; a925cb40b3f0 test:0.1 9e9c814023bcffc3e67e892a235afe61b02f66a947d2747f724bd317dda02f27 基于本地模板导入 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]\n例如，下载了ubuntu-14.04的模板压缩包，之后使用以下命令导入：\n$ cat ubuntu-14.04-x86_64-minimal.tar.gz | docker import - ubuntu:14.04\n6. 导出和导入镜像 导出镜像 docker save [OPTIONS] IMAGE [IMAGE...]\n例子： $ docker save -o ubuntu_14.04.tar ubuntu:14.04\n导入镜像 docker load [OPTIONS]\n例子： $ docker load --input ubuntu_14.04.tar 或 $ docker load \u0026lt; ubuntu_14.04.tar\n7. 上传镜像 docker push [OPTIONS] NAME[:TAG]\n可以使用docker push命令上传镜像到仓库，默认上传到Docker Hub官方仓库\n$ docker tag test:latest user/test:latest $ docker push user/test:latest The push refers to a repository [docker.io/user/test] Sending image list Please login prior to push: Username: Password: Email: ","id":77,"section":"posts","summary":"\u003cp\u003e围绕Docker镜像的一系列重要命令操作，包括获取、查看、搜索、删除、创建、存出和载入、上传等。\u003c/p\u003e","tags":["docker"],"title":"使用 Docker 镜像","uri":"https://www.ganymedenil.com/2018/07/10/use-docker-images.html","year":"2018"},{"content":"核心概念包括镜像、容器、仓库\n镜像 （Image） 类似于虚拟机镜像，可以将它理解为一个只读的模板，是创建容器的基础。 ##容器 （Container）\n类似于一个轻量级的沙箱，Docker利用容器来运行和隔离应用。容器是从镜像创建的应用运行实例。可以将其启动、开始、停止、删除，而这些容器都是彼此相互隔离的、互不可见的。\n镜像自身是只读的。容器从镜像启动的时候，会在镜像的最上层创建一个可写层。\n仓库 （Repository） 类似于代码仓库，它是Docker集中存放镜像文件的场所。根据所存储的镜像公开分享与否，Docker仓库可以分为公开仓库（Public）和私有仓库（Private）两种形式。\n","id":78,"section":"posts","summary":"\u003cp\u003e核心概念包括镜像、容器、仓库\u003c/p\u003e","tags":["docker"],"title":"Docker 核心概念","uri":"https://www.ganymedenil.com/2018/07/10/docker-key-conception.html","year":"2018"},{"content":"swoole 的安装与使用\n环境要求 系统: Linux, FreeBSD or MacOS\nLinux 内核版本 \u0026gt;= 2.3.32\nPHP 版本 \u0026gt;= 5.3.10\nGCC 版本 \u0026gt;= 4.4 or Clang\nCmake 版本 \u0026gt;= 2.4 (Cmake需要将libswoole编译为C / C ++库)\n推荐Linux版本：Ubuntu 14，CentOS 7或更高版本\nPHP版本依赖 Swoole仅支持PHP版本\u0026gt; = 5.3.10，推荐使用PHP 5.4+ Swoole不依赖于stream，sockets，pcntl，posix，sysvmsg等扩展。只需安装PHP的基本扩展。 安装 源码安装 下载 swoole 最新稳定版本\nhttps://github.com/swoole/swoole-src/releases\ncd swoole # 进入 swoole 源码目录 phpize # 为PHP扩展准备编译环境 ./configure # 根据需要添加配置参数 make # 编译 sudo make install # 安装 swoole 到 php 扩展目录 我的测试环境编译参数 ./configure --with-php-config=PATH --enable-swoole-debug --enable-trace-log --enable-sockets --enable-openssl --enable-swoole --with-swoole --enable-coroutine --enable-thread --enable-debug 编译可选参数\n--disable-option-checking ignore unrecognized --enable/--with options --disable-FEATURE do not include FEATURE (same as --enable-FEATURE=no) --enable-FEATURE[=ARG] include FEATURE [ARG=yes] --with-PACKAGE[=ARG] use PACKAGE [ARG=yes] --without-PACKAGE do not use PACKAGE (same as --with-PACKAGE=no) --with-libdir=NAME Look for libraries in .../NAME rather than .../lib --with-php-config=PATH Path to php-config php-config --enable-swoole-debug Enable swoole debug 启用swoole的调试日志。不要在生产环境中启用此配置。 --enable-trace-log Enable swoole trace log --enable-sockets Do you have sockets extension? 启用对 sockets 的支持。依赖 sockets --enable-async-redis Do you have hiredis? 启用对异步Redis客户端的支持。依赖 hiredis --enable-coroutine-postgresql Do you install postgresql? 启用协程 Postgresql 客户端，依赖 libpq --enable-openssl Use openssl? 启用openssl支持。依赖 libssl.so --enable-http2 Use http2.0? 启用HTTP2的支持。依赖 nghttp2 --enable-thread Experimental: Use thread? 启用线程支持 //实验性功能。请勿在生产环境中使用此功能 --enable-hugepage Experimental: Use hugepage? 启用 hugepage //使用大内存页优化性能，具体鸟哥在他的博客中讲到。 如果已经开启了 jemalloc，再开启hugepage 印象性能 https://blog.digitalocean.com/transparent-huge-pages-and-alternative-memory-allocators/ 实验性功能。请勿在生产环境中使用此功能 --enable-swoole Enable swoole support --enable-swoole-static Enable swoole static compile support --with-swoole With swoole support --with-libpq-dir=DIR Include libpq support (requires libpq \u0026gt;= 9.5) --with-openssl-dir=DIR Include OpenSSL support (requires OpenSSL \u0026gt;= 0.9.6) 设置openssl库的路径，例如：--with-openssl-dir=/opt/openssl/. --with-jemalloc-dir=DIR Include jemalloc support 使用 jemalloc 进行内存优化支持 --enable-mysqlnd Do you have mysqlnd? 启用对 mysqlnd 的支持，依赖 mysqlnd --enable-coroutine Enable coroutine (requires PHP \u0026gt;= 5.5) 启用协程 --enable-asan Enable asan 启用 Address-Sanitizier 内存检测工具 //只有开启debug才有效 --enable-picohttpparser Experimental: Do you have picohttpparser? 启用 picohttpparser 支持 //这是一个超高性能的http解析器，实验性功能。请勿在生产环境中使用此功能 --enable-timewheel Experimental: Enable timewheel heartbeat? 启用时间轮算法并优化心跳算法 //实验性功能。请勿在生产环境中使用此功能 --enable-debug, compile with debug symbols 编译时加入符号表 //使用gdb调试时有用 --enable-shared=PKGS Build shared libraries default=yes --enable-static=PKGS Build static libraries default=yes --enable-fast-install=PKGS Optimize for fast installation default=yes --with-gnu-ld Assume the C compiler uses GNU ld default=no --disable-libtool-lock Avoid locking (might break parallel builds) --with-pic Try to use only PIC/non-PIC objects default=use both --with-tags=TAGS Include additional configurations automatic 二进制版本安装 Linux用户 pecl install swoole\n安装可选参数默认 NO\nenable debug/trace log support? enable sockets supports? enable openssl support? enable http2 support? enable async-redis support? enable mysqlnd support? enable postgresql coroutine client support? MacOS X（macOS）用户 推荐使用 homebrew 安装\nbrew install swoole\n使用 安装完成后需要在 php.ini 中加入扩展 extension=swoole.so，才能使用\nphp -i | grep php.ini # 检查 php.ini 所在目录 sudo echo \u0026quot;extension=swoole.so\u0026quot; \u0026gt; php.ini # 添加 extension=swoole.so 到 php.ini 到最后一行 php -m | grep swoole # 检查 swoole 扩展是否已经被激活 使用 PhpStorm 开发swoole\n默认 PhpStorm 不支持对于 swoole 的代码提示，需要下载对应的代码提示库\nhttps://github.com/eaglewu/swoole-ide-helper\n然后在 Preferences -\u0026gt; Languages \u0026amp; Frameworks -\u0026gt; PHP 的 Include Path 中引入代码提示库\n现在就可以正常使用自动补全提示了\n","id":79,"section":"posts","summary":"\u003cp\u003eswoole 的安装与使用\u003c/p\u003e","tags":["swoole"],"title":"swoole 学习（一）安装","uri":"https://www.ganymedenil.com/2018/04/22/learn-swoole-install.html","year":"2018"},{"content":"go 语言 系统信号捕捉\n信号类型 不同平台信号定义有所不同，通过命令 man signal 可获取各平台详细的信号介绍。\nGo 中的 Signal 发送和处理 golang中对信号的处理主要使用os/signal包中的两个方法： notify方法用来监听收到的信号 stop方法用来取消监听 监听全部信号 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/signal\u0026quot; ) // 监听全部信号 func main() { //合建chan c := make(chan os.Signal) //监听所有信号 signal.Notify(c) //阻塞直到有信号传入 fmt.Println(\u0026quot;启动\u0026quot;) s := \u0026lt;-c fmt.Println(\u0026quot;退出信号\u0026quot;, s) } 编译 go build example-1.go\n启动 ./example-1\nctrl+c退出,输出 退出信号 interrupt\nkill pid 输出 退出信号 terminated\n监听指定信号 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/signal\u0026quot; \u0026quot;syscall\u0026quot; ) // 监听指定信号 func main() { //合建chan c := make(chan os.Signal) //监听指定信号 ctrl+c kill signal.Notify(c, os.Interrupt, os.Kill, syscall.SIGUSR1, syscall.SIGUSR2) //阻塞直到有信号传入 fmt.Println(\u0026quot;启动\u0026quot;) //阻塞直至有信号传入 s := \u0026lt;-c fmt.Println(\u0026quot;退出信号\u0026quot;, s) } 编译 go build example-2.go\n启动 ./example-2\nctrl+c退出,输出 退出信号 interrupt\nkill pid 输出 退出信号 terminated\nkill -USR1 pid 输出 退出信号 user defined signal 1\nkill -USR2 pid 输出 退出信号 user defined signal 2\n优雅退出 go 守护进程 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;os/signal\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;time\u0026quot; ) // 优雅退出go守护进程 func main() { //创建监听退出chan c := make(chan os.Signal) //监听指定信号 ctrl+c kill signal.Notify(c, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGUSR1, syscall.SIGUSR2) go func() { for s := range c { switch s { case syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT: fmt.Println(\u0026quot;退出\u0026quot;, s) ExitFunc() case syscall.SIGUSR1: fmt.Println(\u0026quot;usr1\u0026quot;, s) case syscall.SIGUSR2: fmt.Println(\u0026quot;usr2\u0026quot;, s) default: fmt.Println(\u0026quot;other\u0026quot;, s) } } }() fmt.Println(\u0026quot;进程启动...\u0026quot;) sum := 0 for { sum++ fmt.Println(\u0026quot;sum:\u0026quot;, sum) time.Sleep(time.Second) } } func ExitFunc() { fmt.Println(\u0026quot;开始退出...\u0026quot;) fmt.Println(\u0026quot;执行清理...\u0026quot;) fmt.Println(\u0026quot;结束退出...\u0026quot;) os.Exit(0) } kill -USR1 pid 输出 usr1 user defined signal 1\nkill -USR2 pid usr2 user defined signal 2\nkill pid 退出 terminated 开始退出\u0026hellip; 执行清理\u0026hellip; 结束退出\u0026hellip;\n执行输出 go build example-3.go ./example-3\n进程启动\u0026hellip; sum: 1 sum: 2 sum: 3 sum: 4 sum: 5 sum: 6 sum: 7 sum: 8 sum: 9 usr1 user defined signal 1 sum: 10 sum: 11 sum: 12 sum: 13 sum: 14 usr2 user defined signal 2 sum: 15 sum: 16 sum: 17 退出 terminated 开始退出\u0026hellip; 执行清理\u0026hellip; 结束退出\u0026hellip;\n","id":80,"section":"posts","summary":"\u003cp\u003ego 语言 系统信号捕捉\u003c/p\u003e","tags":["linux","go"],"title":"go 语言 系统信号捕捉","uri":"https://www.ganymedenil.com/2018/02/19/golang-signal.html","year":"2018"},{"content":"修复雪球 RDR: redis data reveal 支持 Redis v4\n问题 首先雪球的 redis data reveal （以下简称RDR）核心依赖是 cupcake/rdb,而无法解析Redis v4 也是因为 cupcake/rdb 不支持 rdb v8 的结构支持。\n解决 直接修复 cupcake/rdb 支持 rdb v8 版本支持即可（ Redis RDB File Format）。解决可直接看这个pach 。\n目前 cupcake/rdb 已经修复支持，可直接在我的代码仓库下载使用。\nRDR 因为使用 go v1.7 开发，正在进行升级以支持 go v1.9 的支持。\n","id":81,"section":"posts","summary":"\u003cp\u003e修复雪球 RDR: redis data reveal 支持 Redis v4\u003c/p\u003e","tags":["redis","go"],"title":"修复rdr 支持 Redis v4","uri":"https://www.ganymedenil.com/2018/01/30/fix-rdr-support-for-redis-v4.html","year":"2018"},{"content":"多站点使用 laravel 导致 CSRF 在cookies中的键值冲突,然后爆 Illuminate\\Session\\TokenMismatchException 错误\n问题 这个问题一直间歇性出现，也是最近才意识到因为公司内部各个子站开始推行 laravel 。\n于是重新看了文档找到以下关键\nLaravel stores the current CSRF token in a XSRF-TOKEN cookie that is included with each response generated by the framework.\n从此可知 laravel 会向 cookies 写入一个键名为 XSRF-TOKEN 的 验证字段，而我们的各站点如果默认都使用此字段就会出现，在A站生成此字段值，在B站使用，然后CSRF报错。\n解决 重写 Illuminate\\Foundation\\Http\\Middleware\\VerifyCsrfToken 中的 addCookieToResponse 这个方法即可\n具体做法 我们只要在 \\app\\Http\\Middleware\\VerifyCsrfToken.php 这个文件中，重写此方法即可：\n\u0026lt;?php namespace App\\Http\\Middleware; use Symfony\\Component\\HttpFoundation\\Cookie; use Illuminate\\Foundation\\Http\\Middleware\\VerifyCsrfToken as BaseVerifier; class VerifyCsrfToken extends BaseVerifier { /** * The URIs that should be excluded from CSRF verification. * * @var array */ protected $except = [ ]; /** * Add the CSRF token to the response cookies. * * @param \\Illuminate\\Http\\Request $request * @param \\Illuminate\\Http\\Response $response * @return \\Illuminate\\Http\\Response */ protected function addCookieToResponse($request, $response) { $config = config('session'); $response-\u0026gt;headers-\u0026gt;setCookie( new Cookie( //在这改成 cookies 中唯一的键即可如 ‘GN_XSRF-TOKEN’ 'XSRF-TOKEN', $request-\u0026gt;session()-\u0026gt;token(), time() + 60 * $config['lifetime'], $config['path'], $config['domain'], $config['secure'], false ) ); return $response; } } ","id":82,"section":"posts","summary":"\u003cp\u003e多站点使用 \u003ccode\u003elaravel\u003c/code\u003e 导致 \u003ccode\u003eCSRF\u003c/code\u003e  在cookies中的键值冲突,然后爆 \u003ccode\u003eIlluminate\\Session\\TokenMismatchException\u003c/code\u003e 错误\u003c/p\u003e","tags":["laravel"],"title":"记laravel的CSRF这个坑","uri":"https://www.ganymedenil.com/2017/09/21/laravel-csrf.html","year":"2017"},{"content":"远程xdebug调试配置\n1.安装配置xdebug 直接使用pecl安装即可\npecl install xdebug 然后写xdebug配置，下面是我的设置(具体扩展路径以你安装完后提示的路径为准)\n[xdebug] zend_extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20160303/xdebug.so xdebug.remote_enable = 1 xdebug.remote_host=192.168.220.128(你运行xdebug服务器的外网ip，这里是我在虚拟机测试的地址) xdebug.remote_connect_back = 1 xdebug.remote_port = 9000 保存重启php\n2.配置运行DBGp proxy 首先下载，下载地址，我在这选择的是Komodo IDE 10 (version 10.1.2)然后是Python Remote Debugging Client Linux (x86_64) ，可以按照你的系统需求选择下载，但推荐选择python版本而不是其他的，因为这篇文章是按python版写的╭(′▽`)╯下载完解包进入目录，别着急运行，先测试一下包是否已经导入\npython -c \u0026quot;import dbgp.client; print 'ok'\u0026quot; 如果没显示ok而是显示错误就代表没导入\n编辑/etc/profile(具体目录按照你解压目录为准，我这是root下的PythonRemoteDebugging目录，因为我的centos 7 的默认python 版本是2.7所以我导入的包目录是pythonlib，如果你是3的改成python3lib)\nexport PYTHONPATH=/root/PythonRemoteDebugging/pythonlib 继续上一步测试是否显示ok\n好了现在可以运行了\n./pydbgpproxy -d 127.0.0.1:9000 -i 192.168.220.128:9001 如果显示类似的信息代表运行成功，如果错误一般提醒端口已被占用换个端口即可\nINFO: dbgp.proxy: starting proxy listeners. appid: 3583 INFO: dbgp.proxy: dbgp listener on 127.0.0.1:9000 INFO: dbgp.proxy: IDE listener on 192.168.220.128:9001 好了最后一步，开放9001端口 编辑/etc/sysconfig/iptables 加一条规则\n-A INPUT -p tcp -m state --state NEW -m tcp --dport 9001 -j ACCEPT 重启iptables 让规则生效 然后运行pydbgpproxy\n3.设置PhpStorm 打开 Tools-\u0026gt;DBGp proxy-\u0026gt;configuration IDE key 是用来区分不同用户的 只要每个人的不重复就可以了 Host 这个就是pydbgpproxy中指定的外网ip，我这是192.168.220.128 Port pydbgpproxy中指定的端口，我这是9001 保存后，我们还得注册一下 点击Tools-\u0026gt;DBGp proxy-\u0026gt;register IDE 显示以下内容，表示注册成功\nIDE successfully registered with ide key 'PHPSTORM' 好了 现在可以跟小伙伴们愉快的在远程开发机上享受xdebug了(^o^)/\n参考网站： https://xdebug.org/docs/install http://docs.komodoide.com/Manual/debugpython https://confluence.jetbrains.com/display/PhpStorm/Multi-user+debugging+in+PhpStorm+with+Xdebug+and+DBGp+proxy\n","id":83,"section":"posts","summary":"\u003cp\u003e远程xdebug调试配置\u003c/p\u003e","tags":["xdebug","Php Storm"],"title":"开发机多用户 xdebug 远程调试 PhpStorm","uri":"https://www.ganymedenil.com/2017/01/01/2.html","year":"2017"},{"content":"Laravel说明文档中的 Redis 发布与订阅案例，命令行运行PHP artisan redis:subscribe 到60s自动断开并报错\n[Predis\\Connection\\ConnectionException] Error while reading line from the server. [tcp://127.0.0.1:6379] 问题 Laravel说明文档中的 Redis 发布与订阅案例，命令行运行PHP artisan redis:subscribe 到60s自动断开并报错\n[Predis\\Connection\\ConnectionException] Error while reading line from the server. [tcp://127.0.0.1:6379] 解决 在config/database.php配置文件中，找到redis配置项，添加一行如下\n'redis' =\u0026gt; [ 'cluster' =\u0026gt; false, 'default' =\u0026gt; [ 'host' =\u0026gt; env('REDIS_HOST', '127.0.0.1'), 'password' =\u0026gt; env('REDIS_PASSWORD', null), 'port' =\u0026gt; env('REDIS_PORT', 6379), 'database' =\u0026gt; 0, 'read_write_timeout' =\u0026gt; 0,//new ], ] 原因 据Predis作者在配置文件中说明，因为在底层网络资源上执行读取或写入操作时使用了超时，默认设置了timeout 为60s。\n参考\nhttps://github.com/nrk/predis/wiki/Connection-Parameters\n","id":84,"section":"posts","summary":"\u003cp\u003eLaravel说明文档中的 Redis 发布与订阅案例，命令行运行PHP artisan redis:subscribe 到60s自动断开并报错\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-cmd\"\u003e[Predis\\Connection\\ConnectionException]\n Error while reading line from the server. [tcp://127.0.0.1:6379]\n\u003c/code\u003e\u003c/pre\u003e","tags":["Predis"],"title":"Laravel Predis Error while reading line from the server.","uri":"https://www.ganymedenil.com/2017/01/01/1.html","year":"2017"},{"content":"","id":85,"section":"","summary":"","tags":null,"title":"友情链接","uri":"https://www.ganymedenil.com/links/","year":"0001"}],"tags":[{"title":"Hardhat","uri":"https://www.ganymedenil.com/tags/Hardhat/"},{"title":"JAX","uri":"https://www.ganymedenil.com/tags/JAX/"},{"title":"LLM","uri":"https://www.ganymedenil.com/tags/LLM/"},{"title":"NFT","uri":"https://www.ganymedenil.com/tags/NFT/"},{"title":"Php Storm","uri":"https://www.ganymedenil.com/tags/Php-Storm/"},{"title":"Predis","uri":"https://www.ganymedenil.com/tags/Predis/"},{"title":"SOL","uri":"https://www.ganymedenil.com/tags/SOL/"},{"title":"Solana","uri":"https://www.ganymedenil.com/tags/Solana/"},{"title":"Solidity","uri":"https://www.ganymedenil.com/tags/Solidity/"},{"title":"ddd","uri":"https://www.ganymedenil.com/tags/ddd/"},{"title":"docker","uri":"https://www.ganymedenil.com/tags/docker/"},{"title":"gemma","uri":"https://www.ganymedenil.com/tags/gemma/"},{"title":"go","uri":"https://www.ganymedenil.com/tags/go/"},{"title":"hexo","uri":"https://www.ganymedenil.com/tags/hexo/"},{"title":"kerasNLP","uri":"https://www.ganymedenil.com/tags/kerasNLP/"},{"title":"laravel","uri":"https://www.ganymedenil.com/tags/laravel/"},{"title":"linux","uri":"https://www.ganymedenil.com/tags/linux/"},{"title":"nginx","uri":"https://www.ganymedenil.com/tags/nginx/"},{"title":"nuxt","uri":"https://www.ganymedenil.com/tags/nuxt/"},{"title":"php","uri":"https://www.ganymedenil.com/tags/php/"},{"title":"redis","uri":"https://www.ganymedenil.com/tags/redis/"},{"title":"rust","uri":"https://www.ganymedenil.com/tags/rust/"},{"title":"swoole","uri":"https://www.ganymedenil.com/tags/swoole/"},{"title":"web3","uri":"https://www.ganymedenil.com/tags/web3/"},{"title":"xdebug","uri":"https://www.ganymedenil.com/tags/xdebug/"},{"title":"以太坊","uri":"https://www.ganymedenil.com/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"},{"title":"总结","uri":"https://www.ganymedenil.com/tags/%E6%80%BB%E7%BB%93/"},{"title":"智能合约","uri":"https://www.ganymedenil.com/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"}]}